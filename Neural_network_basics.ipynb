{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:23.297427Z",
     "start_time": "2020-09-15T00:38:13.716029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "# Cheking the version of the tesorflow and keras and other libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__, keras.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Image Classifier Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:25.430068Z",
     "start_time": "2020-09-15T00:38:24.972359Z"
    }
   },
   "outputs": [],
   "source": [
    "# using the digits mnist dataset from keras\n",
    "digits_mnist = keras.datasets.mnist\n",
    "(X_train , y_train ) , (X_test, y_test) = digits_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:26.200777Z",
     "start_time": "2020-09-15T00:38:26.192116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the dataset and its type\n",
    "X_train.shape , X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:27.828750Z",
     "start_time": "2020-09-15T00:38:27.816101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now a single image is consists of an 28x28 array where each pixel is either represented with an \n",
    "# pixel density of 0 as black and 255 as white.. since we are going to use gradient descent we have \n",
    "# to scale the input feautures by diving them by 255\n",
    "len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:30.716825Z",
     "start_time": "2020-09-15T00:38:30.339420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling the data to of 0 to 255 to 0 to 1 by dividing it by 255\n",
    "X_train ,  X_test = X_train/255 ,  X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:35.251099Z",
     "start_time": "2020-09-15T00:38:35.243563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zero',\n",
       " 'one',\n",
       " 'two',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Writing the class_name for each output\n",
    "class_names = ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:36.551360Z",
     "start_time": "2020-09-15T00:38:36.544731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('five', 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the values of target variables as index for \n",
    "class_names[y_train[0]], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:41.086487Z",
     "start_time": "2020-09-15T00:38:37.976190Z"
    }
   },
   "outputs": [],
   "source": [
    "# BUilding an sequential API model (A Classification MLP with tow hidden layers)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28])) # adding the input layer\n",
    "model.add(keras.layers.Dense(300, activation='relu')) # Adding the first hidden layer\n",
    "model.add(keras.layers.Dense(100, activation='relu')) # Adding the second hidden layer\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) # Adding the final output layer having the softmax as the activation system for the classification problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "* Sequential model is the simplest model in keras for neural networks , just composed of single stack of layers connected squentially called Sequential API\n",
    "* Flatten is used to convert the each input pixel in the 28x28 to one single array (i.e X.reshape(-1,1)\n",
    "* Dense is the hidden layer with 300 neurons \n",
    "#### Note : You can even pass them on as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:42.409859Z",
     "start_time": "2020-09-15T00:38:42.402157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:44.778614Z",
     "start_time": "2020-09-15T00:38:44.766703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.01066726,  0.03337234,  0.04074413, ...,  0.01031884,\n",
       "          0.00078474,  0.00863229],\n",
       "        [-0.00483905,  0.06965329,  0.05934672, ..., -0.04837134,\n",
       "          0.02393696,  0.03967855],\n",
       "        [ 0.07332075,  0.04683173, -0.0599371 , ..., -0.00299703,\n",
       "         -0.01253302,  0.06457785],\n",
       "        ...,\n",
       "        [ 0.06573886, -0.01470464,  0.00056303, ...,  0.07244097,\n",
       "          0.03023527, -0.06934246],\n",
       "        [ 0.03579719,  0.00389159, -0.02827678, ..., -0.04895887,\n",
       "          0.06642489,  0.07251404],\n",
       "        [-0.05407833, -0.02319343,  0.02508876, ..., -0.05169282,\n",
       "         -0.0061086 , -0.02059001]], dtype=float32),\n",
       " (784, 300))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Extracting the weigths and biases of the hidden layers\n",
    "hidden1 = model.layers[1] # Extracting info about the first layer\n",
    "weights , biases = hidden1.get_weights()\n",
    "# Notice at first the weights are assigned randomly to each neuron to break the symmetry\n",
    "weights , weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:45.639009Z",
     "start_time": "2020-09-15T00:38:45.627876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " (300,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the biases are initialized to zero\n",
    "biases, biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T06:40:52.684037Z",
     "start_time": "2020-09-12T06:40:52.671999Z"
    }
   },
   "source": [
    "### Compiling the model\n",
    "* After the model is created , you must call compile() . to spcify the loss function ans the optimizer to use. and other metrics to compute during the training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:48.113809Z",
     "start_time": "2020-09-15T00:38:48.032230Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer = 'sgd',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "* `sparse_categorical_crossentropy` - loss is used coz we have sparse labels , for each instance there is just one target index from 0 to 9 in this case . and the classes are exclusive.\n",
    "* IF we had one hot encoded vectors ex.[0,0,0,1,0,...] to represent class 3 then we had to use  `\"categorical_crossentropy\"` loss instead\n",
    "* For binary classification with more than one binary labels . we use `sigmoid` i.e logistic activation in the output intead of the \"softmax\" activitation function , `binary_crossentropy` loss instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:50.100488Z",
     "start_time": "2020-09-15T00:38:50.096804Z"
    }
   },
   "outputs": [],
   "source": [
    "### `sgd` -> Stochastic Gradient Descent and the learning rate is defaulted to lr=0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:38:50.693255Z",
     "start_time": "2020-09-15T00:38:50.686468Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss_analysis(history):\n",
    "    plt.style.use('ggplot')\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,6))\n",
    "    plt.title('The mean training loss and accuracy at each epoch')\n",
    "    plt.xlabel('EPOCH(Iteration)')\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1) # Set the vertical range to [0-1]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T01:36:23.545232Z",
     "start_time": "2020-09-15T01:36:23.399201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Training and evaluating the model\n",
    "# Call back for saving the best model \n",
    "checkpoint_cb_best_model = keras.callbacks.ModelCheckpoint('Digits_Sequantial_API.h5',\n",
    "                                                              save_best_only=True)\n",
    "\n",
    "# Early stopping the model , if validation accuracy does not see any improvement \n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5,\n",
    "                                                 restore_best_weights=True)\n",
    "\n",
    "# This stops the algorithm if its accuracy does not increase at a patience threhold of 10 \n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                   validation_split=0.2,\n",
    "                   callbacks=[checkpoint_cb_best_model, early_stopping_cb],\n",
    "                   batch_size=32)\n",
    "\n",
    "#  Instead of creating a validation data and passing it other wise we could also set the \n",
    "# validation_split=0.1 (10%) tell keras to use 10% of the data for validation\n",
    "# class_weight gives more weight to underpresent clasees and vice versa\n",
    "# Use batch_size to change the number of samples per gradient descent default = 32\n",
    "# Using history parameter\n",
    "plot_loss_analysis(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T00:49:18.162296Z",
     "start_time": "2020-09-15T00:49:16.499318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 161us/sample - loss: 0.1239 - accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1239378461457789, 0.9636]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Evaluating the model on the test data\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning\n",
    "Using sklearn wrapper in keras module to use randomizedSearchCV to find the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T01:25:05.839249Z",
     "start_time": "2020-09-15T01:25:05.831290Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a build model fucntion to create the base for the sklearn wrapper \n",
    "def build_model(n_layers = 2, n_neurons=100 , \n",
    "                learning_rate = 3e-3 , input_shape=[28,28]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "    for layer in range(n_layers):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T01:27:11.666874Z",
     "start_time": "2020-09-15T01:27:01.848872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 43us/sample - loss: 1.9669 - accuracy: 0.3900 - val_loss: 1.5567 - val_accuracy: 0.7002\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 2s 36us/sample - loss: 1.2180 - accuracy: 0.7570 - val_loss: 0.9042 - val_accuracy: 0.8127\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.7884 - accuracy: 0.8183 - val_loss: 0.6443 - val_accuracy: 0.8502\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.6141 - accuracy: 0.8474 - val_loss: 0.5288 - val_accuracy: 0.8664\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 2s 34us/sample - loss: 0.5259 - accuracy: 0.8647 - val_loss: 0.4638 - val_accuracy: 0.8809\n",
      "10000/10000 [==============================] - 1s 91us/sample - loss: 0.4655 - accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8796"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a keras classifier using build_model function\n",
    "keras_classfier = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "\n",
    "# Now this can be used like a normal sklearn object\n",
    "# Testing the created object\n",
    "keras_classfier.fit(X_train, y_train,\n",
    "                   epochs=5,\n",
    "                   callbacks=[checkpoint_cb_best_model, early_stopping_cb],\n",
    "                   validation_split=0.2,\n",
    "                   batch_size=100)\n",
    "classfier_test = keras_classfier.score(X_test, y_test)\n",
    "classfier_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T02:27:38.933408Z",
     "start_time": "2020-09-15T01:36:42.886542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 2.1530 - accuracy: 0.3081 - val_loss: 1.8730 - val_accuracy: 0.5546\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.4319 - accuracy: 0.6822 - val_loss: 0.9638 - val_accuracy: 0.8050\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7941 - accuracy: 0.8051 - val_loss: 0.5902 - val_accuracy: 0.8614\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5739 - accuracy: 0.8489 - val_loss: 0.4589 - val_accuracy: 0.8814\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4804 - accuracy: 0.8685 - val_loss: 0.3971 - val_accuracy: 0.8930\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4290 - accuracy: 0.8806 - val_loss: 0.3608 - val_accuracy: 0.9019\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3966 - accuracy: 0.8878 - val_loss: 0.3360 - val_accuracy: 0.9056\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3731 - accuracy: 0.8937 - val_loss: 0.3208 - val_accuracy: 0.9115\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3552 - accuracy: 0.8982 - val_loss: 0.3071 - val_accuracy: 0.9128\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3408 - accuracy: 0.9014 - val_loss: 0.2971 - val_accuracy: 0.9145\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3284 - accuracy: 0.9056 - val_loss: 0.2865 - val_accuracy: 0.9174\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3180 - accuracy: 0.9082 - val_loss: 0.2771 - val_accuracy: 0.9210\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3083 - accuracy: 0.9107 - val_loss: 0.2702 - val_accuracy: 0.9225\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2999 - accuracy: 0.9141 - val_loss: 0.2644 - val_accuracy: 0.9227\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2918 - accuracy: 0.9160 - val_loss: 0.2578 - val_accuracy: 0.9252\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2843 - accuracy: 0.9186 - val_loss: 0.2537 - val_accuracy: 0.9280\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2776 - accuracy: 0.9199 - val_loss: 0.2489 - val_accuracy: 0.9284\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2711 - accuracy: 0.9226 - val_loss: 0.2433 - val_accuracy: 0.9300\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2653 - accuracy: 0.9243 - val_loss: 0.2379 - val_accuracy: 0.9324\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2595 - accuracy: 0.9254 - val_loss: 0.2330 - val_accuracy: 0.9336\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2540 - accuracy: 0.9277 - val_loss: 0.2296 - val_accuracy: 0.9333\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2486 - accuracy: 0.9283 - val_loss: 0.2258 - val_accuracy: 0.9371\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2438 - accuracy: 0.9307 - val_loss: 0.2217 - val_accuracy: 0.9355\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2389 - accuracy: 0.9319 - val_loss: 0.2175 - val_accuracy: 0.9380\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2345 - accuracy: 0.9324 - val_loss: 0.2140 - val_accuracy: 0.9392\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2302 - accuracy: 0.9340 - val_loss: 0.2111 - val_accuracy: 0.9396\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2258 - accuracy: 0.9355 - val_loss: 0.2090 - val_accuracy: 0.9389\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2221 - accuracy: 0.9358 - val_loss: 0.2040 - val_accuracy: 0.9410\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2179 - accuracy: 0.9370 - val_loss: 0.2025 - val_accuracy: 0.9417\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2141 - accuracy: 0.9376 - val_loss: 0.1983 - val_accuracy: 0.9435\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2103 - accuracy: 0.9398 - val_loss: 0.1955 - val_accuracy: 0.9450\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2066 - accuracy: 0.9399 - val_loss: 0.1954 - val_accuracy: 0.9463\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2032 - accuracy: 0.9406 - val_loss: 0.1912 - val_accuracy: 0.9457\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1998 - accuracy: 0.9419 - val_loss: 0.1880 - val_accuracy: 0.9473\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1965 - accuracy: 0.9423 - val_loss: 0.1863 - val_accuracy: 0.9481\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1934 - accuracy: 0.9439 - val_loss: 0.1835 - val_accuracy: 0.9480\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1906 - accuracy: 0.9453 - val_loss: 0.1828 - val_accuracy: 0.9473\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1873 - accuracy: 0.9460 - val_loss: 0.1792 - val_accuracy: 0.9501\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1842 - accuracy: 0.9463 - val_loss: 0.1798 - val_accuracy: 0.9492\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.1814 - accuracy: 0.9481 - val_loss: 0.1773 - val_accuracy: 0.9509\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1787 - accuracy: 0.9487 - val_loss: 0.1744 - val_accuracy: 0.9504\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1759 - accuracy: 0.9497 - val_loss: 0.1727 - val_accuracy: 0.9517\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1733 - accuracy: 0.9502 - val_loss: 0.1700 - val_accuracy: 0.9519\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1706 - accuracy: 0.9503 - val_loss: 0.1684 - val_accuracy: 0.9521\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1682 - accuracy: 0.9514 - val_loss: 0.1670 - val_accuracy: 0.9525\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1659 - accuracy: 0.9521 - val_loss: 0.1655 - val_accuracy: 0.9526\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1635 - accuracy: 0.9526 - val_loss: 0.1641 - val_accuracy: 0.9540\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1613 - accuracy: 0.9529 - val_loss: 0.1619 - val_accuracy: 0.9535\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1586 - accuracy: 0.9546 - val_loss: 0.1594 - val_accuracy: 0.9548\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1568 - accuracy: 0.9551 - val_loss: 0.1585 - val_accuracy: 0.9539\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1545 - accuracy: 0.9552 - val_loss: 0.1585 - val_accuracy: 0.9540\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1522 - accuracy: 0.9565 - val_loss: 0.1560 - val_accuracy: 0.9549\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1501 - accuracy: 0.9564 - val_loss: 0.1547 - val_accuracy: 0.9570\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1479 - accuracy: 0.9576 - val_loss: 0.1546 - val_accuracy: 0.9564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1461 - accuracy: 0.9575 - val_loss: 0.1532 - val_accuracy: 0.9550\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1438 - accuracy: 0.9582 - val_loss: 0.1561 - val_accuracy: 0.9546\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1421 - accuracy: 0.9592 - val_loss: 0.1499 - val_accuracy: 0.9572\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1402 - accuracy: 0.9592 - val_loss: 0.1479 - val_accuracy: 0.9570\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1383 - accuracy: 0.9597 - val_loss: 0.1467 - val_accuracy: 0.9576\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1363 - accuracy: 0.9608 - val_loss: 0.1462 - val_accuracy: 0.9580\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1346 - accuracy: 0.9613 - val_loss: 0.1450 - val_accuracy: 0.9588\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1325 - accuracy: 0.9616 - val_loss: 0.1443 - val_accuracy: 0.9585\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1309 - accuracy: 0.9622 - val_loss: 0.1431 - val_accuracy: 0.9580\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1294 - accuracy: 0.9626 - val_loss: 0.1422 - val_accuracy: 0.9591\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1276 - accuracy: 0.9626 - val_loss: 0.1410 - val_accuracy: 0.9605\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1257 - accuracy: 0.9638 - val_loss: 0.1401 - val_accuracy: 0.9599\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1242 - accuracy: 0.9641 - val_loss: 0.1389 - val_accuracy: 0.9607\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1227 - accuracy: 0.9645 - val_loss: 0.1378 - val_accuracy: 0.9604\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1210 - accuracy: 0.9652 - val_loss: 0.1372 - val_accuracy: 0.9605\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1193 - accuracy: 0.9653 - val_loss: 0.1360 - val_accuracy: 0.9616\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1178 - accuracy: 0.9657 - val_loss: 0.1353 - val_accuracy: 0.9620\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1161 - accuracy: 0.9664 - val_loss: 0.1351 - val_accuracy: 0.9625\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1147 - accuracy: 0.9667 - val_loss: 0.1339 - val_accuracy: 0.9626\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.1132 - accuracy: 0.9669 - val_loss: 0.1324 - val_accuracy: 0.9622\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.1119 - accuracy: 0.9677 - val_loss: 0.1329 - val_accuracy: 0.9622\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.1101 - accuracy: 0.9679 - val_loss: 0.1315 - val_accuracy: 0.9632\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1088 - accuracy: 0.9688 - val_loss: 0.1314 - val_accuracy: 0.9617\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1075 - accuracy: 0.9686 - val_loss: 0.1302 - val_accuracy: 0.9635\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1062 - accuracy: 0.9693 - val_loss: 0.1287 - val_accuracy: 0.9631\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1049 - accuracy: 0.9697 - val_loss: 0.1288 - val_accuracy: 0.9640\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1033 - accuracy: 0.9702 - val_loss: 0.1283 - val_accuracy: 0.9632\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1021 - accuracy: 0.9708 - val_loss: 0.1283 - val_accuracy: 0.9632\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.1008 - accuracy: 0.9708 - val_loss: 0.1264 - val_accuracy: 0.9631\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0996 - accuracy: 0.9713 - val_loss: 0.1260 - val_accuracy: 0.9630\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.0982 - accuracy: 0.9717 - val_loss: 0.1248 - val_accuracy: 0.9644\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.0969 - accuracy: 0.9719 - val_loss: 0.1238 - val_accuracy: 0.9635\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.0961 - accuracy: 0.9720 - val_loss: 0.1234 - val_accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.0947 - accuracy: 0.9726 - val_loss: 0.1236 - val_accuracy: 0.9651\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.0936 - accuracy: 0.9733 - val_loss: 0.1233 - val_accuracy: 0.9639\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0922 - accuracy: 0.9733 - val_loss: 0.1237 - val_accuracy: 0.9650\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0914 - accuracy: 0.9743 - val_loss: 0.1210 - val_accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.0901 - accuracy: 0.9742 - val_loss: 0.1206 - val_accuracy: 0.9656\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.0892 - accuracy: 0.9746 - val_loss: 0.1200 - val_accuracy: 0.9655\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.0881 - accuracy: 0.9753 - val_loss: 0.1202 - val_accuracy: 0.9661\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.0870 - accuracy: 0.9753 - val_loss: 0.1201 - val_accuracy: 0.9659\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0859 - accuracy: 0.9757 - val_loss: 0.1194 - val_accuracy: 0.9647\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.0848 - accuracy: 0.9761 - val_loss: 0.1206 - val_accuracy: 0.9646\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0840 - accuracy: 0.9757 - val_loss: 0.1184 - val_accuracy: 0.9659\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0830 - accuracy: 0.9763 - val_loss: 0.1188 - val_accuracy: 0.9668\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0819 - accuracy: 0.9765 - val_loss: 0.1188 - val_accuracy: 0.9660\n",
      "20000/20000 [==============================] - 1s 70us/sample - loss: 0.1347 - accuracy: 0.9595\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 47us/sample - loss: 2.0675 - accuracy: 0.3343 - val_loss: 1.7379 - val_accuracy: 0.4922\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 1.3437 - accuracy: 0.6356 - val_loss: 0.9669 - val_accuracy: 0.7508\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.8234 - accuracy: 0.7758 - val_loss: 0.6501 - val_accuracy: 0.8328\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.6179 - accuracy: 0.8305 - val_loss: 0.5097 - val_accuracy: 0.8660\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.5149 - accuracy: 0.8580 - val_loss: 0.4365 - val_accuracy: 0.8852\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4551 - accuracy: 0.8726 - val_loss: 0.3899 - val_accuracy: 0.8970\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4154 - accuracy: 0.8838 - val_loss: 0.3593 - val_accuracy: 0.9036\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3873 - accuracy: 0.8924 - val_loss: 0.3391 - val_accuracy: 0.9069\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3657 - accuracy: 0.8974 - val_loss: 0.3239 - val_accuracy: 0.9118\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3484 - accuracy: 0.9017 - val_loss: 0.3096 - val_accuracy: 0.9139\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3334 - accuracy: 0.9053 - val_loss: 0.2986 - val_accuracy: 0.9156\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3215 - accuracy: 0.9085 - val_loss: 0.2892 - val_accuracy: 0.9189\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3106 - accuracy: 0.9118 - val_loss: 0.2807 - val_accuracy: 0.9201\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.3008 - accuracy: 0.9145 - val_loss: 0.2747 - val_accuracy: 0.9222\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2923 - accuracy: 0.9159 - val_loss: 0.2673 - val_accuracy: 0.9256\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2838 - accuracy: 0.9189 - val_loss: 0.2599 - val_accuracy: 0.9261\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2764 - accuracy: 0.9213 - val_loss: 0.2539 - val_accuracy: 0.9280\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2690 - accuracy: 0.9232 - val_loss: 0.2482 - val_accuracy: 0.9281\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2621 - accuracy: 0.9247 - val_loss: 0.2436 - val_accuracy: 0.9305\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2556 - accuracy: 0.9265 - val_loss: 0.2386 - val_accuracy: 0.9319\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2497 - accuracy: 0.9282 - val_loss: 0.2340 - val_accuracy: 0.9325\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2439 - accuracy: 0.9293 - val_loss: 0.2303 - val_accuracy: 0.9333\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2383 - accuracy: 0.9311 - val_loss: 0.2281 - val_accuracy: 0.9330\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2334 - accuracy: 0.9326 - val_loss: 0.2211 - val_accuracy: 0.9342\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2283 - accuracy: 0.9348 - val_loss: 0.2213 - val_accuracy: 0.9366\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2233 - accuracy: 0.9362 - val_loss: 0.2146 - val_accuracy: 0.9355\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2191 - accuracy: 0.9367 - val_loss: 0.2113 - val_accuracy: 0.9386\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2146 - accuracy: 0.9382 - val_loss: 0.2098 - val_accuracy: 0.9379\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2104 - accuracy: 0.9392 - val_loss: 0.2049 - val_accuracy: 0.9414\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2064 - accuracy: 0.9407 - val_loss: 0.2030 - val_accuracy: 0.9409\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2025 - accuracy: 0.9421 - val_loss: 0.1980 - val_accuracy: 0.9417\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1986 - accuracy: 0.9426 - val_loss: 0.1976 - val_accuracy: 0.9416\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1949 - accuracy: 0.9446 - val_loss: 0.1932 - val_accuracy: 0.9429\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1917 - accuracy: 0.9447 - val_loss: 0.1894 - val_accuracy: 0.9449\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1877 - accuracy: 0.9457 - val_loss: 0.1889 - val_accuracy: 0.9449\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1845 - accuracy: 0.9471 - val_loss: 0.1845 - val_accuracy: 0.9461\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1816 - accuracy: 0.9476 - val_loss: 0.1829 - val_accuracy: 0.9470\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1781 - accuracy: 0.9488 - val_loss: 0.1803 - val_accuracy: 0.9486\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1751 - accuracy: 0.9494 - val_loss: 0.1788 - val_accuracy: 0.9474\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1723 - accuracy: 0.9508 - val_loss: 0.1774 - val_accuracy: 0.9492\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1694 - accuracy: 0.9524 - val_loss: 0.1759 - val_accuracy: 0.9492\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1665 - accuracy: 0.9524 - val_loss: 0.1726 - val_accuracy: 0.9510\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1639 - accuracy: 0.9532 - val_loss: 0.1725 - val_accuracy: 0.9516\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1614 - accuracy: 0.9544 - val_loss: 0.1687 - val_accuracy: 0.9529\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1589 - accuracy: 0.9547 - val_loss: 0.1678 - val_accuracy: 0.9506\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1564 - accuracy: 0.9555 - val_loss: 0.1649 - val_accuracy: 0.9532\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1537 - accuracy: 0.9554 - val_loss: 0.1632 - val_accuracy: 0.9531\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1515 - accuracy: 0.9568 - val_loss: 0.1640 - val_accuracy: 0.9517\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1492 - accuracy: 0.9574 - val_loss: 0.1612 - val_accuracy: 0.9532\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1471 - accuracy: 0.9580 - val_loss: 0.1594 - val_accuracy: 0.9538\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1450 - accuracy: 0.9587 - val_loss: 0.1588 - val_accuracy: 0.9548\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1426 - accuracy: 0.9597 - val_loss: 0.1576 - val_accuracy: 0.9548\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1402 - accuracy: 0.9602 - val_loss: 0.1555 - val_accuracy: 0.9551\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1386 - accuracy: 0.9604 - val_loss: 0.1551 - val_accuracy: 0.9549\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1363 - accuracy: 0.9610 - val_loss: 0.1550 - val_accuracy: 0.9557\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1345 - accuracy: 0.9611 - val_loss: 0.1523 - val_accuracy: 0.9565\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1327 - accuracy: 0.9623 - val_loss: 0.1505 - val_accuracy: 0.9566\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1304 - accuracy: 0.9631 - val_loss: 0.1514 - val_accuracy: 0.9561\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1285 - accuracy: 0.9634 - val_loss: 0.1477 - val_accuracy: 0.9569\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1268 - accuracy: 0.9642 - val_loss: 0.1495 - val_accuracy: 0.9555\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1250 - accuracy: 0.9645 - val_loss: 0.1484 - val_accuracy: 0.9576\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1234 - accuracy: 0.9645 - val_loss: 0.1472 - val_accuracy: 0.9569\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1218 - accuracy: 0.9654 - val_loss: 0.1438 - val_accuracy: 0.9580\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1198 - accuracy: 0.9661 - val_loss: 0.1446 - val_accuracy: 0.9578\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1184 - accuracy: 0.9665 - val_loss: 0.1445 - val_accuracy: 0.9592\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1169 - accuracy: 0.9671 - val_loss: 0.1420 - val_accuracy: 0.9597\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1151 - accuracy: 0.9669 - val_loss: 0.1426 - val_accuracy: 0.9574\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1138 - accuracy: 0.9680 - val_loss: 0.1408 - val_accuracy: 0.9590\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1122 - accuracy: 0.9677 - val_loss: 0.1396 - val_accuracy: 0.9592\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1106 - accuracy: 0.9686 - val_loss: 0.1398 - val_accuracy: 0.9592\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1094 - accuracy: 0.9690 - val_loss: 0.1386 - val_accuracy: 0.9596\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1077 - accuracy: 0.9694 - val_loss: 0.1393 - val_accuracy: 0.9590\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1062 - accuracy: 0.9706 - val_loss: 0.1390 - val_accuracy: 0.9599\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1049 - accuracy: 0.9707 - val_loss: 0.1360 - val_accuracy: 0.9609\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1036 - accuracy: 0.9710 - val_loss: 0.1349 - val_accuracy: 0.9607\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1021 - accuracy: 0.9715 - val_loss: 0.1369 - val_accuracy: 0.9605\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1010 - accuracy: 0.9722 - val_loss: 0.1343 - val_accuracy: 0.9599\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0998 - accuracy: 0.9721 - val_loss: 0.1339 - val_accuracy: 0.9615\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0984 - accuracy: 0.9723 - val_loss: 0.1346 - val_accuracy: 0.9617\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0970 - accuracy: 0.9727 - val_loss: 0.1329 - val_accuracy: 0.9606\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.1343 - val_accuracy: 0.9594\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.0948 - accuracy: 0.9734 - val_loss: 0.1310 - val_accuracy: 0.9617\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0935 - accuracy: 0.9735 - val_loss: 0.1316 - val_accuracy: 0.9599\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0924 - accuracy: 0.9744 - val_loss: 0.1307 - val_accuracy: 0.9615\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0913 - accuracy: 0.9743 - val_loss: 0.1303 - val_accuracy: 0.9615\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0899 - accuracy: 0.9752 - val_loss: 0.1281 - val_accuracy: 0.9620\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.0888 - accuracy: 0.9752 - val_loss: 0.1291 - val_accuracy: 0.9616\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.0876 - accuracy: 0.9758 - val_loss: 0.1281 - val_accuracy: 0.9616\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.0869 - accuracy: 0.9760 - val_loss: 0.1276 - val_accuracy: 0.9635\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0855 - accuracy: 0.9761 - val_loss: 0.1280 - val_accuracy: 0.9632\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0847 - accuracy: 0.9768 - val_loss: 0.1276 - val_accuracy: 0.9625\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0835 - accuracy: 0.9765 - val_loss: 0.1252 - val_accuracy: 0.9626\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0827 - accuracy: 0.9772 - val_loss: 0.1257 - val_accuracy: 0.9635\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0815 - accuracy: 0.9772 - val_loss: 0.1256 - val_accuracy: 0.9624\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0808 - accuracy: 0.9775 - val_loss: 0.1252 - val_accuracy: 0.9630\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0795 - accuracy: 0.9782 - val_loss: 0.1256 - val_accuracy: 0.9636\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0785 - accuracy: 0.9783 - val_loss: 0.1256 - val_accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.0777 - accuracy: 0.9786 - val_loss: 0.1245 - val_accuracy: 0.9628\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0768 - accuracy: 0.9787 - val_loss: 0.1258 - val_accuracy: 0.9636\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.0760 - accuracy: 0.9789 - val_loss: 0.1238 - val_accuracy: 0.9641\n",
      "20000/20000 [==============================] - 1s 52us/sample - loss: 0.1451 - accuracy: 0.9574\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 49us/sample - loss: 2.1759 - accuracy: 0.2619 - val_loss: 1.9676 - val_accuracy: 0.4795\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.5656 - accuracy: 0.6414 - val_loss: 1.1621 - val_accuracy: 0.7452\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.8936 - accuracy: 0.7878 - val_loss: 0.7324 - val_accuracy: 0.8229\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.6259 - accuracy: 0.8370 - val_loss: 0.5696 - val_accuracy: 0.8485\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.5104 - accuracy: 0.8622 - val_loss: 0.4849 - val_accuracy: 0.8680\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4470 - accuracy: 0.8767 - val_loss: 0.4376 - val_accuracy: 0.8788\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4076 - accuracy: 0.8871 - val_loss: 0.4038 - val_accuracy: 0.8873\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.3804 - accuracy: 0.8942 - val_loss: 0.3814 - val_accuracy: 0.8932\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3594 - accuracy: 0.8991 - val_loss: 0.3601 - val_accuracy: 0.8971\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.3430 - accuracy: 0.9026 - val_loss: 0.3509 - val_accuracy: 0.9013\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3287 - accuracy: 0.9062 - val_loss: 0.3346 - val_accuracy: 0.9041\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3169 - accuracy: 0.9093 - val_loss: 0.3281 - val_accuracy: 0.9039\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3065 - accuracy: 0.9124 - val_loss: 0.3152 - val_accuracy: 0.9104\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2970 - accuracy: 0.9141 - val_loss: 0.3113 - val_accuracy: 0.9090\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2888 - accuracy: 0.9177 - val_loss: 0.2999 - val_accuracy: 0.9131\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2807 - accuracy: 0.9201 - val_loss: 0.2937 - val_accuracy: 0.9144\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2735 - accuracy: 0.9220 - val_loss: 0.2860 - val_accuracy: 0.9181\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2665 - accuracy: 0.9239 - val_loss: 0.2787 - val_accuracy: 0.9196\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2601 - accuracy: 0.9259 - val_loss: 0.2734 - val_accuracy: 0.9200\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2540 - accuracy: 0.9269 - val_loss: 0.2674 - val_accuracy: 0.9220\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2477 - accuracy: 0.9293 - val_loss: 0.2643 - val_accuracy: 0.9224\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2422 - accuracy: 0.9305 - val_loss: 0.2578 - val_accuracy: 0.9226\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2365 - accuracy: 0.9317 - val_loss: 0.2558 - val_accuracy: 0.9239\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2316 - accuracy: 0.9329 - val_loss: 0.2497 - val_accuracy: 0.9268\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2265 - accuracy: 0.9345 - val_loss: 0.2438 - val_accuracy: 0.9280\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2218 - accuracy: 0.9365 - val_loss: 0.2402 - val_accuracy: 0.9287\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2172 - accuracy: 0.9369 - val_loss: 0.2387 - val_accuracy: 0.9300\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2129 - accuracy: 0.9385 - val_loss: 0.2337 - val_accuracy: 0.9305\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2088 - accuracy: 0.9399 - val_loss: 0.2290 - val_accuracy: 0.9327\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2047 - accuracy: 0.9414 - val_loss: 0.2265 - val_accuracy: 0.9330\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2007 - accuracy: 0.9421 - val_loss: 0.2222 - val_accuracy: 0.9354\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1964 - accuracy: 0.9431 - val_loss: 0.2214 - val_accuracy: 0.9350\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1933 - accuracy: 0.9443 - val_loss: 0.2178 - val_accuracy: 0.9350\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1896 - accuracy: 0.9446 - val_loss: 0.2148 - val_accuracy: 0.9362\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1864 - accuracy: 0.9457 - val_loss: 0.2102 - val_accuracy: 0.9376\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1825 - accuracy: 0.9470 - val_loss: 0.2074 - val_accuracy: 0.9394\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1792 - accuracy: 0.9478 - val_loss: 0.2057 - val_accuracy: 0.9391\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1763 - accuracy: 0.9482 - val_loss: 0.2029 - val_accuracy: 0.9409\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1732 - accuracy: 0.9496 - val_loss: 0.2006 - val_accuracy: 0.9421\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1699 - accuracy: 0.9502 - val_loss: 0.1993 - val_accuracy: 0.9410\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1674 - accuracy: 0.9507 - val_loss: 0.1966 - val_accuracy: 0.9415\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1643 - accuracy: 0.9516 - val_loss: 0.1953 - val_accuracy: 0.9409\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1616 - accuracy: 0.9526 - val_loss: 0.1912 - val_accuracy: 0.9444\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1589 - accuracy: 0.9530 - val_loss: 0.1896 - val_accuracy: 0.9421\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1562 - accuracy: 0.9544 - val_loss: 0.1877 - val_accuracy: 0.9445\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1535 - accuracy: 0.9546 - val_loss: 0.1877 - val_accuracy: 0.9435\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1514 - accuracy: 0.9555 - val_loss: 0.1835 - val_accuracy: 0.9454\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1489 - accuracy: 0.9558 - val_loss: 0.1813 - val_accuracy: 0.9464\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1465 - accuracy: 0.9572 - val_loss: 0.1798 - val_accuracy: 0.9461\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1439 - accuracy: 0.9580 - val_loss: 0.1779 - val_accuracy: 0.9461\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1419 - accuracy: 0.9589 - val_loss: 0.1761 - val_accuracy: 0.9460\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1398 - accuracy: 0.9598 - val_loss: 0.1749 - val_accuracy: 0.9470\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1378 - accuracy: 0.9603 - val_loss: 0.1743 - val_accuracy: 0.9479\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1356 - accuracy: 0.9608 - val_loss: 0.1727 - val_accuracy: 0.9473\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1334 - accuracy: 0.9612 - val_loss: 0.1706 - val_accuracy: 0.9484\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1317 - accuracy: 0.9627 - val_loss: 0.1687 - val_accuracy: 0.9484\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1296 - accuracy: 0.9631 - val_loss: 0.1670 - val_accuracy: 0.9496\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1277 - accuracy: 0.9630 - val_loss: 0.1660 - val_accuracy: 0.9499\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1256 - accuracy: 0.9635 - val_loss: 0.1637 - val_accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1242 - accuracy: 0.9643 - val_loss: 0.1651 - val_accuracy: 0.9511\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1222 - accuracy: 0.9653 - val_loss: 0.1631 - val_accuracy: 0.9524\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1205 - accuracy: 0.9658 - val_loss: 0.1615 - val_accuracy: 0.9516\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1188 - accuracy: 0.9657 - val_loss: 0.1601 - val_accuracy: 0.9515\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1172 - accuracy: 0.9665 - val_loss: 0.1580 - val_accuracy: 0.9521\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1155 - accuracy: 0.9670 - val_loss: 0.1572 - val_accuracy: 0.9526\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1139 - accuracy: 0.9673 - val_loss: 0.1561 - val_accuracy: 0.9532\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1124 - accuracy: 0.9680 - val_loss: 0.1552 - val_accuracy: 0.9526\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1107 - accuracy: 0.9686 - val_loss: 0.1552 - val_accuracy: 0.9535\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1094 - accuracy: 0.9687 - val_loss: 0.1538 - val_accuracy: 0.9535\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1080 - accuracy: 0.9692 - val_loss: 0.1533 - val_accuracy: 0.9544\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1063 - accuracy: 0.9699 - val_loss: 0.1524 - val_accuracy: 0.9531\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1048 - accuracy: 0.9705 - val_loss: 0.1519 - val_accuracy: 0.9544\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1035 - accuracy: 0.9707 - val_loss: 0.1515 - val_accuracy: 0.9546\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1021 - accuracy: 0.9712 - val_loss: 0.1492 - val_accuracy: 0.9553\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.1012 - accuracy: 0.9714 - val_loss: 0.1485 - val_accuracy: 0.9556\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0997 - accuracy: 0.9716 - val_loss: 0.1480 - val_accuracy: 0.9554\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0983 - accuracy: 0.9727 - val_loss: 0.1462 - val_accuracy: 0.9559\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0971 - accuracy: 0.9732 - val_loss: 0.1468 - val_accuracy: 0.9554\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0959 - accuracy: 0.9730 - val_loss: 0.1452 - val_accuracy: 0.9569\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0946 - accuracy: 0.9735 - val_loss: 0.1452 - val_accuracy: 0.9567\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0936 - accuracy: 0.9743 - val_loss: 0.1445 - val_accuracy: 0.9560\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.97 - 1s 30us/sample - loss: 0.0922 - accuracy: 0.9746 - val_loss: 0.1434 - val_accuracy: 0.9569\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0909 - accuracy: 0.9751 - val_loss: 0.1426 - val_accuracy: 0.9582\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0900 - accuracy: 0.9749 - val_loss: 0.1431 - val_accuracy: 0.9565\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0889 - accuracy: 0.9756 - val_loss: 0.1420 - val_accuracy: 0.9576\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0876 - accuracy: 0.9762 - val_loss: 0.1411 - val_accuracy: 0.9579\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.0864 - accuracy: 0.9765 - val_loss: 0.1410 - val_accuracy: 0.9576\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0856 - accuracy: 0.9770 - val_loss: 0.1400 - val_accuracy: 0.9586\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0844 - accuracy: 0.9765 - val_loss: 0.1406 - val_accuracy: 0.9579\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0837 - accuracy: 0.9770 - val_loss: 0.1393 - val_accuracy: 0.9572\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0825 - accuracy: 0.9771 - val_loss: 0.1391 - val_accuracy: 0.9586\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0814 - accuracy: 0.9777 - val_loss: 0.1380 - val_accuracy: 0.9588\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0806 - accuracy: 0.9783 - val_loss: 0.1373 - val_accuracy: 0.9588\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0795 - accuracy: 0.9784 - val_loss: 0.1381 - val_accuracy: 0.9584\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0784 - accuracy: 0.9791 - val_loss: 0.1374 - val_accuracy: 0.9590\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0777 - accuracy: 0.9788 - val_loss: 0.1370 - val_accuracy: 0.9589\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0765 - accuracy: 0.9790 - val_loss: 0.1375 - val_accuracy: 0.9591\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0759 - accuracy: 0.9796 - val_loss: 0.1361 - val_accuracy: 0.9590\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0748 - accuracy: 0.9798 - val_loss: 0.1373 - val_accuracy: 0.9586\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0740 - accuracy: 0.9797 - val_loss: 0.1352 - val_accuracy: 0.9588\n",
      "20000/20000 [==============================] - 1s 54us/sample - loss: 0.1409 - accuracy: 0.9594\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 2.1978 - accuracy: 0.2323 - val_loss: 2.1092 - val_accuracy: 0.3721\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 2.0460 - accuracy: 0.4284 - val_loss: 1.9441 - val_accuracy: 0.5061\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 1.8735 - accuracy: 0.5317 - val_loss: 1.7529 - val_accuracy: 0.5909\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.6802 - accuracy: 0.6083 - val_loss: 1.5463 - val_accuracy: 0.6610\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.4803 - accuracy: 0.6680 - val_loss: 1.3429 - val_accuracy: 0.7151\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.2913 - accuracy: 0.7189 - val_loss: 1.1594 - val_accuracy: 0.7707\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.1273 - accuracy: 0.7576 - val_loss: 1.0062 - val_accuracy: 0.8077\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.9936 - accuracy: 0.7859 - val_loss: 0.8853 - val_accuracy: 0.8254\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8881 - accuracy: 0.8051 - val_loss: 0.7909 - val_accuracy: 0.8409\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.8054 - accuracy: 0.8187 - val_loss: 0.7166 - val_accuracy: 0.8508\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.7400 - accuracy: 0.8288 - val_loss: 0.6583 - val_accuracy: 0.8572\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.6874 - accuracy: 0.8363 - val_loss: 0.6120 - val_accuracy: 0.8639\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6449 - accuracy: 0.8425 - val_loss: 0.5734 - val_accuracy: 0.8676\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.6100 - accuracy: 0.8467 - val_loss: 0.5421 - val_accuracy: 0.8721\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5807 - accuracy: 0.8519 - val_loss: 0.5159 - val_accuracy: 0.8759\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.5562 - accuracy: 0.8562 - val_loss: 0.4940 - val_accuracy: 0.8785\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.5353 - accuracy: 0.8595 - val_loss: 0.4754 - val_accuracy: 0.8816\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.5172 - accuracy: 0.8633 - val_loss: 0.4592 - val_accuracy: 0.8840\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.5015 - accuracy: 0.8658 - val_loss: 0.4450 - val_accuracy: 0.8870\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4876 - accuracy: 0.8684 - val_loss: 0.4330 - val_accuracy: 0.8889\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4751 - accuracy: 0.8711 - val_loss: 0.4220 - val_accuracy: 0.8907\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4641 - accuracy: 0.8737 - val_loss: 0.4122 - val_accuracy: 0.8923\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.4541 - accuracy: 0.8756 - val_loss: 0.4033 - val_accuracy: 0.8946\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4450 - accuracy: 0.8774 - val_loss: 0.3952 - val_accuracy: 0.8963\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.4366 - accuracy: 0.8788 - val_loss: 0.3884 - val_accuracy: 0.8972\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4291 - accuracy: 0.8813 - val_loss: 0.3816 - val_accuracy: 0.8982\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4220 - accuracy: 0.8824 - val_loss: 0.3754 - val_accuracy: 0.8991\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.4155 - accuracy: 0.8836 - val_loss: 0.3696 - val_accuracy: 0.9009\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4094 - accuracy: 0.8856 - val_loss: 0.3643 - val_accuracy: 0.9034\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4037 - accuracy: 0.8867 - val_loss: 0.3594 - val_accuracy: 0.9029\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3982 - accuracy: 0.8882 - val_loss: 0.3548 - val_accuracy: 0.9041\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3933 - accuracy: 0.8891 - val_loss: 0.3505 - val_accuracy: 0.9045\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3886 - accuracy: 0.8905 - val_loss: 0.3465 - val_accuracy: 0.9051\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3841 - accuracy: 0.8913 - val_loss: 0.3426 - val_accuracy: 0.9055\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3799 - accuracy: 0.8923 - val_loss: 0.3391 - val_accuracy: 0.9054\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3759 - accuracy: 0.8930 - val_loss: 0.3357 - val_accuracy: 0.9057\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3719 - accuracy: 0.8939 - val_loss: 0.3325 - val_accuracy: 0.9061\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3683 - accuracy: 0.8950 - val_loss: 0.3292 - val_accuracy: 0.9069\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3648 - accuracy: 0.8955 - val_loss: 0.3265 - val_accuracy: 0.9074\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3615 - accuracy: 0.8964 - val_loss: 0.3234 - val_accuracy: 0.9087\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3582 - accuracy: 0.8976 - val_loss: 0.3205 - val_accuracy: 0.9084\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3551 - accuracy: 0.8976 - val_loss: 0.3181 - val_accuracy: 0.9091\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3521 - accuracy: 0.8983 - val_loss: 0.3156 - val_accuracy: 0.9095\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3494 - accuracy: 0.8992 - val_loss: 0.3131 - val_accuracy: 0.9101\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3465 - accuracy: 0.9000 - val_loss: 0.3109 - val_accuracy: 0.9110\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3439 - accuracy: 0.9003 - val_loss: 0.3087 - val_accuracy: 0.9112\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3414 - accuracy: 0.9014 - val_loss: 0.3064 - val_accuracy: 0.9119\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3389 - accuracy: 0.9025 - val_loss: 0.3042 - val_accuracy: 0.9131\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3364 - accuracy: 0.9030 - val_loss: 0.3021 - val_accuracy: 0.9134\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3341 - accuracy: 0.9032 - val_loss: 0.3004 - val_accuracy: 0.9139\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3318 - accuracy: 0.9040 - val_loss: 0.2986 - val_accuracy: 0.9146\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3297 - accuracy: 0.9048 - val_loss: 0.2967 - val_accuracy: 0.9155\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3275 - accuracy: 0.9054 - val_loss: 0.2950 - val_accuracy: 0.9155\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3255 - accuracy: 0.9059 - val_loss: 0.2933 - val_accuracy: 0.9162\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3235 - accuracy: 0.9065 - val_loss: 0.2913 - val_accuracy: 0.9170\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3215 - accuracy: 0.9071 - val_loss: 0.2896 - val_accuracy: 0.9174\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3196 - accuracy: 0.9079 - val_loss: 0.2883 - val_accuracy: 0.9179\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3177 - accuracy: 0.9080 - val_loss: 0.2866 - val_accuracy: 0.9176\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3159 - accuracy: 0.9081 - val_loss: 0.2852 - val_accuracy: 0.9189\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3141 - accuracy: 0.9089 - val_loss: 0.2835 - val_accuracy: 0.9191\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3124 - accuracy: 0.9096 - val_loss: 0.2820 - val_accuracy: 0.9190\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3106 - accuracy: 0.9103 - val_loss: 0.2807 - val_accuracy: 0.9197\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3090 - accuracy: 0.9109 - val_loss: 0.2794 - val_accuracy: 0.9204\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3073 - accuracy: 0.9112 - val_loss: 0.2778 - val_accuracy: 0.9199\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3057 - accuracy: 0.9119 - val_loss: 0.2765 - val_accuracy: 0.9202\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3041 - accuracy: 0.9120 - val_loss: 0.2753 - val_accuracy: 0.9205\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3025 - accuracy: 0.9129 - val_loss: 0.2741 - val_accuracy: 0.9215\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3011 - accuracy: 0.9135 - val_loss: 0.2727 - val_accuracy: 0.9210\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2996 - accuracy: 0.9138 - val_loss: 0.2714 - val_accuracy: 0.9215\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2981 - accuracy: 0.9138 - val_loss: 0.2704 - val_accuracy: 0.9220\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2967 - accuracy: 0.9147 - val_loss: 0.2692 - val_accuracy: 0.9225\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2954 - accuracy: 0.9152 - val_loss: 0.2680 - val_accuracy: 0.9226\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2940 - accuracy: 0.9157 - val_loss: 0.2667 - val_accuracy: 0.9230\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2926 - accuracy: 0.9157 - val_loss: 0.2655 - val_accuracy: 0.9239\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2912 - accuracy: 0.9163 - val_loss: 0.2649 - val_accuracy: 0.9239\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2899 - accuracy: 0.9170 - val_loss: 0.2635 - val_accuracy: 0.9245\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2887 - accuracy: 0.9169 - val_loss: 0.2625 - val_accuracy: 0.9247\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2874 - accuracy: 0.9172 - val_loss: 0.2613 - val_accuracy: 0.9254\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2862 - accuracy: 0.9180 - val_loss: 0.2602 - val_accuracy: 0.9254\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2849 - accuracy: 0.9183 - val_loss: 0.2592 - val_accuracy: 0.9260\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2837 - accuracy: 0.9187 - val_loss: 0.2584 - val_accuracy: 0.9254\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2825 - accuracy: 0.9188 - val_loss: 0.2573 - val_accuracy: 0.9258\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2813 - accuracy: 0.9195 - val_loss: 0.2563 - val_accuracy: 0.9259\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2801 - accuracy: 0.9192 - val_loss: 0.2555 - val_accuracy: 0.9259\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2790 - accuracy: 0.9196 - val_loss: 0.2547 - val_accuracy: 0.9261\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2779 - accuracy: 0.9204 - val_loss: 0.2535 - val_accuracy: 0.9264\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2768 - accuracy: 0.9206 - val_loss: 0.2526 - val_accuracy: 0.9273\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2756 - accuracy: 0.9208 - val_loss: 0.2518 - val_accuracy: 0.9275\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2746 - accuracy: 0.9212 - val_loss: 0.2508 - val_accuracy: 0.9276\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2735 - accuracy: 0.9214 - val_loss: 0.2499 - val_accuracy: 0.9277\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2724 - accuracy: 0.9222 - val_loss: 0.2492 - val_accuracy: 0.9289\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2713 - accuracy: 0.9224 - val_loss: 0.2480 - val_accuracy: 0.9283\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2703 - accuracy: 0.9228 - val_loss: 0.2471 - val_accuracy: 0.9287\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2692 - accuracy: 0.9232 - val_loss: 0.2467 - val_accuracy: 0.9291\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2683 - accuracy: 0.9231 - val_loss: 0.2456 - val_accuracy: 0.9291\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2672 - accuracy: 0.9242 - val_loss: 0.2448 - val_accuracy: 0.9299\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2663 - accuracy: 0.9238 - val_loss: 0.2439 - val_accuracy: 0.9294\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2653 - accuracy: 0.9243 - val_loss: 0.2432 - val_accuracy: 0.9298\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2643 - accuracy: 0.9245 - val_loss: 0.2425 - val_accuracy: 0.9298\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2633 - accuracy: 0.9246 - val_loss: 0.2416 - val_accuracy: 0.9302\n",
      "20000/20000 [==============================] - 1s 61us/sample - loss: 0.2705 - accuracy: 0.9236\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 46us/sample - loss: 2.2617 - accuracy: 0.1590 - val_loss: 2.1885 - val_accuracy: 0.2327\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.1229 - accuracy: 0.3109 - val_loss: 2.0472 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.9760 - accuracy: 0.4595 - val_loss: 1.8829 - val_accuracy: 0.5332\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.8041 - accuracy: 0.5601 - val_loss: 1.6937 - val_accuracy: 0.6151\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.6137 - accuracy: 0.6228 - val_loss: 1.4929 - val_accuracy: 0.6701\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.4209 - accuracy: 0.6698 - val_loss: 1.2994 - val_accuracy: 0.7204\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.2437 - accuracy: 0.7152 - val_loss: 1.1287 - val_accuracy: 0.7615\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.0936 - accuracy: 0.7507 - val_loss: 0.9889 - val_accuracy: 0.7925\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.9730 - accuracy: 0.7771 - val_loss: 0.8780 - val_accuracy: 0.8138\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.8775 - accuracy: 0.7951 - val_loss: 0.7907 - val_accuracy: 0.8304\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8020 - accuracy: 0.8106 - val_loss: 0.7215 - val_accuracy: 0.8421\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7415 - accuracy: 0.8217 - val_loss: 0.6657 - val_accuracy: 0.8497\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6921 - accuracy: 0.8302 - val_loss: 0.6203 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.6513 - accuracy: 0.8388 - val_loss: 0.5831 - val_accuracy: 0.8626\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6172 - accuracy: 0.8455 - val_loss: 0.5513 - val_accuracy: 0.8679\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5880 - accuracy: 0.8509 - val_loss: 0.5249 - val_accuracy: 0.8714\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5631 - accuracy: 0.8565 - val_loss: 0.5016 - val_accuracy: 0.8766\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5414 - accuracy: 0.8604 - val_loss: 0.4817 - val_accuracy: 0.8798\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5223 - accuracy: 0.8641 - val_loss: 0.4643 - val_accuracy: 0.8823\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5056 - accuracy: 0.8673 - val_loss: 0.4492 - val_accuracy: 0.8854\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4906 - accuracy: 0.8702 - val_loss: 0.4355 - val_accuracy: 0.8875\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4773 - accuracy: 0.8727 - val_loss: 0.4234 - val_accuracy: 0.8917\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4652 - accuracy: 0.8753 - val_loss: 0.4125 - val_accuracy: 0.8935\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4543 - accuracy: 0.8771 - val_loss: 0.4030 - val_accuracy: 0.8960\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4444 - accuracy: 0.8797 - val_loss: 0.3939 - val_accuracy: 0.8976\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4353 - accuracy: 0.8817 - val_loss: 0.3861 - val_accuracy: 0.8988\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4270 - accuracy: 0.8832 - val_loss: 0.3786 - val_accuracy: 0.9003\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4193 - accuracy: 0.8849 - val_loss: 0.3720 - val_accuracy: 0.9011\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4121 - accuracy: 0.8870 - val_loss: 0.3656 - val_accuracy: 0.9024\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4055 - accuracy: 0.8886 - val_loss: 0.3598 - val_accuracy: 0.9035\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3993 - accuracy: 0.8896 - val_loss: 0.3546 - val_accuracy: 0.9045\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3936 - accuracy: 0.8911 - val_loss: 0.3498 - val_accuracy: 0.9059\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3882 - accuracy: 0.8929 - val_loss: 0.3450 - val_accuracy: 0.9056\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3831 - accuracy: 0.8940 - val_loss: 0.3409 - val_accuracy: 0.9062\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3784 - accuracy: 0.8952 - val_loss: 0.3367 - val_accuracy: 0.9069\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3739 - accuracy: 0.8963 - val_loss: 0.3328 - val_accuracy: 0.9075\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3696 - accuracy: 0.8975 - val_loss: 0.3292 - val_accuracy: 0.9095\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3656 - accuracy: 0.8982 - val_loss: 0.3258 - val_accuracy: 0.9104\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3618 - accuracy: 0.8995 - val_loss: 0.3228 - val_accuracy: 0.9103\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3581 - accuracy: 0.9005 - val_loss: 0.3197 - val_accuracy: 0.9116\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3546 - accuracy: 0.9012 - val_loss: 0.3167 - val_accuracy: 0.9130\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3513 - accuracy: 0.9020 - val_loss: 0.3141 - val_accuracy: 0.9133\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3482 - accuracy: 0.9022 - val_loss: 0.3113 - val_accuracy: 0.9126\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3451 - accuracy: 0.9032 - val_loss: 0.3091 - val_accuracy: 0.9136\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3422 - accuracy: 0.9043 - val_loss: 0.3067 - val_accuracy: 0.9146\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3394 - accuracy: 0.9044 - val_loss: 0.3042 - val_accuracy: 0.9149\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3367 - accuracy: 0.9053 - val_loss: 0.3021 - val_accuracy: 0.9146\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3341 - accuracy: 0.9056 - val_loss: 0.2999 - val_accuracy: 0.9158\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3315 - accuracy: 0.9063 - val_loss: 0.2981 - val_accuracy: 0.9149\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3292 - accuracy: 0.9071 - val_loss: 0.2961 - val_accuracy: 0.9160\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3268 - accuracy: 0.9077 - val_loss: 0.2940 - val_accuracy: 0.9165\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3245 - accuracy: 0.9082 - val_loss: 0.2925 - val_accuracy: 0.9169\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3224 - accuracy: 0.9087 - val_loss: 0.2905 - val_accuracy: 0.9187\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3202 - accuracy: 0.9097 - val_loss: 0.2887 - val_accuracy: 0.9178\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3181 - accuracy: 0.9102 - val_loss: 0.2871 - val_accuracy: 0.9195\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3161 - accuracy: 0.9105 - val_loss: 0.2857 - val_accuracy: 0.9199\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3141 - accuracy: 0.9112 - val_loss: 0.2839 - val_accuracy: 0.9201\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3123 - accuracy: 0.9117 - val_loss: 0.2824 - val_accuracy: 0.9212\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3103 - accuracy: 0.9125 - val_loss: 0.2812 - val_accuracy: 0.9210\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3086 - accuracy: 0.9125 - val_loss: 0.2795 - val_accuracy: 0.9222\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.3069 - accuracy: 0.9132 - val_loss: 0.2779 - val_accuracy: 0.9220\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3051 - accuracy: 0.9133 - val_loss: 0.2767 - val_accuracy: 0.9230\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 47us/sample - loss: 0.3033 - accuracy: 0.9144 - val_loss: 0.2756 - val_accuracy: 0.9222\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.3017 - accuracy: 0.9144 - val_loss: 0.2741 - val_accuracy: 0.9233\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3001 - accuracy: 0.9150 - val_loss: 0.2727 - val_accuracy: 0.9230\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2985 - accuracy: 0.9152 - val_loss: 0.2716 - val_accuracy: 0.9239\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2970 - accuracy: 0.9155 - val_loss: 0.2703 - val_accuracy: 0.9243\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2954 - accuracy: 0.9163 - val_loss: 0.2692 - val_accuracy: 0.9243\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2940 - accuracy: 0.9164 - val_loss: 0.2678 - val_accuracy: 0.9252\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2925 - accuracy: 0.9172 - val_loss: 0.2669 - val_accuracy: 0.9246\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.2910 - accuracy: 0.9166 - val_loss: 0.2658 - val_accuracy: 0.9249\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2897 - accuracy: 0.9176 - val_loss: 0.2646 - val_accuracy: 0.9251\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2883 - accuracy: 0.9177 - val_loss: 0.2635 - val_accuracy: 0.9258\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2869 - accuracy: 0.9183 - val_loss: 0.2624 - val_accuracy: 0.9254\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2855 - accuracy: 0.9187 - val_loss: 0.2612 - val_accuracy: 0.9259\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2842 - accuracy: 0.9193 - val_loss: 0.2605 - val_accuracy: 0.9252\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2829 - accuracy: 0.9197 - val_loss: 0.2594 - val_accuracy: 0.9256\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2816 - accuracy: 0.9203 - val_loss: 0.2583 - val_accuracy: 0.9268\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2804 - accuracy: 0.9200 - val_loss: 0.2572 - val_accuracy: 0.9266\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2791 - accuracy: 0.9208 - val_loss: 0.2564 - val_accuracy: 0.9262\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2779 - accuracy: 0.9208 - val_loss: 0.2553 - val_accuracy: 0.9268\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2766 - accuracy: 0.9212 - val_loss: 0.2544 - val_accuracy: 0.9275\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2754 - accuracy: 0.9216 - val_loss: 0.2537 - val_accuracy: 0.9274\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2743 - accuracy: 0.9222 - val_loss: 0.2526 - val_accuracy: 0.9268\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2731 - accuracy: 0.9226 - val_loss: 0.2516 - val_accuracy: 0.9273\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2719 - accuracy: 0.9227 - val_loss: 0.2508 - val_accuracy: 0.9274\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2708 - accuracy: 0.9236 - val_loss: 0.2499 - val_accuracy: 0.9280\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2697 - accuracy: 0.9236 - val_loss: 0.2491 - val_accuracy: 0.9287\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2686 - accuracy: 0.9237 - val_loss: 0.2483 - val_accuracy: 0.9287\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2676 - accuracy: 0.9240 - val_loss: 0.2474 - val_accuracy: 0.9280\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2665 - accuracy: 0.9245 - val_loss: 0.2466 - val_accuracy: 0.9280\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2654 - accuracy: 0.9244 - val_loss: 0.2457 - val_accuracy: 0.9291\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2643 - accuracy: 0.9252 - val_loss: 0.2449 - val_accuracy: 0.9287\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2634 - accuracy: 0.9253 - val_loss: 0.2442 - val_accuracy: 0.9294\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2622 - accuracy: 0.9254 - val_loss: 0.2435 - val_accuracy: 0.9296\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2613 - accuracy: 0.9257 - val_loss: 0.2427 - val_accuracy: 0.9301\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2602 - accuracy: 0.9261 - val_loss: 0.2421 - val_accuracy: 0.9293\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2593 - accuracy: 0.9262 - val_loss: 0.2410 - val_accuracy: 0.9305\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2582 - accuracy: 0.9267 - val_loss: 0.2405 - val_accuracy: 0.9308\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2574 - accuracy: 0.9270 - val_loss: 0.2395 - val_accuracy: 0.9305\n",
      "20000/20000 [==============================] - 1s 65us/sample - loss: 0.2801 - accuracy: 0.9176\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 48us/sample - loss: 2.2832 - accuracy: 0.1421 - val_loss: 2.2290 - val_accuracy: 0.2094\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 2.1769 - accuracy: 0.2870 - val_loss: 2.1147 - val_accuracy: 0.3790\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 2.0443 - accuracy: 0.4426 - val_loss: 1.9629 - val_accuracy: 0.5132\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.8756 - accuracy: 0.5578 - val_loss: 1.7790 - val_accuracy: 0.6109\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 1.6823 - accuracy: 0.6372 - val_loss: 1.5794 - val_accuracy: 0.6735\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 1.4837 - accuracy: 0.6911 - val_loss: 1.3856 - val_accuracy: 0.7174\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 1.2991 - accuracy: 0.7311 - val_loss: 1.2133 - val_accuracy: 0.7563\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.1406 - accuracy: 0.7608 - val_loss: 1.0698 - val_accuracy: 0.7804\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.0115 - accuracy: 0.7845 - val_loss: 0.9547 - val_accuracy: 0.8004\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.9086 - accuracy: 0.8023 - val_loss: 0.8635 - val_accuracy: 0.8165\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.8268 - accuracy: 0.8162 - val_loss: 0.7908 - val_accuracy: 0.8257\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.7612 - accuracy: 0.8261 - val_loss: 0.7319 - val_accuracy: 0.8330\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7081 - accuracy: 0.8344 - val_loss: 0.6842 - val_accuracy: 0.8411\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6644 - accuracy: 0.8413 - val_loss: 0.6447 - val_accuracy: 0.8482\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.6279 - accuracy: 0.8476 - val_loss: 0.6116 - val_accuracy: 0.8526\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5971 - accuracy: 0.8526 - val_loss: 0.5834 - val_accuracy: 0.8580\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.5708 - accuracy: 0.8577 - val_loss: 0.5591 - val_accuracy: 0.8609\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.5480 - accuracy: 0.8618 - val_loss: 0.5383 - val_accuracy: 0.8641\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.5282 - accuracy: 0.8657 - val_loss: 0.5198 - val_accuracy: 0.8677\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.5107 - accuracy: 0.8689 - val_loss: 0.5037 - val_accuracy: 0.8683\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4954 - accuracy: 0.8716 - val_loss: 0.4897 - val_accuracy: 0.8709\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4817 - accuracy: 0.8740 - val_loss: 0.4772 - val_accuracy: 0.8730\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.4694 - accuracy: 0.8763 - val_loss: 0.4656 - val_accuracy: 0.8749\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4583 - accuracy: 0.8789 - val_loss: 0.4557 - val_accuracy: 0.8760\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4483 - accuracy: 0.8800 - val_loss: 0.4462 - val_accuracy: 0.8788\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4392 - accuracy: 0.8824 - val_loss: 0.4379 - val_accuracy: 0.8804\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4309 - accuracy: 0.8839 - val_loss: 0.4301 - val_accuracy: 0.8819\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4232 - accuracy: 0.8864 - val_loss: 0.4233 - val_accuracy: 0.8820\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4162 - accuracy: 0.8872 - val_loss: 0.4167 - val_accuracy: 0.8855\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4098 - accuracy: 0.8886 - val_loss: 0.4105 - val_accuracy: 0.8870\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4036 - accuracy: 0.8903 - val_loss: 0.4050 - val_accuracy: 0.8886\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3980 - accuracy: 0.8912 - val_loss: 0.3997 - val_accuracy: 0.8901\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3928 - accuracy: 0.8923 - val_loss: 0.3952 - val_accuracy: 0.8890\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3879 - accuracy: 0.8937 - val_loss: 0.3905 - val_accuracy: 0.8916\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3832 - accuracy: 0.8944 - val_loss: 0.3862 - val_accuracy: 0.8926\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3788 - accuracy: 0.8949 - val_loss: 0.3823 - val_accuracy: 0.8934\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3747 - accuracy: 0.8965 - val_loss: 0.3784 - val_accuracy: 0.8935\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3707 - accuracy: 0.8970 - val_loss: 0.3750 - val_accuracy: 0.8942\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3671 - accuracy: 0.8982 - val_loss: 0.3716 - val_accuracy: 0.8959\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3635 - accuracy: 0.8987 - val_loss: 0.3685 - val_accuracy: 0.8965\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3601 - accuracy: 0.8993 - val_loss: 0.3652 - val_accuracy: 0.8975\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3570 - accuracy: 0.9006 - val_loss: 0.3624 - val_accuracy: 0.8984\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3539 - accuracy: 0.9010 - val_loss: 0.3597 - val_accuracy: 0.8989\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3509 - accuracy: 0.9018 - val_loss: 0.3570 - val_accuracy: 0.8995\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.3481 - accuracy: 0.9023 - val_loss: 0.3543 - val_accuracy: 0.8996\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3452 - accuracy: 0.9032 - val_loss: 0.3518 - val_accuracy: 0.8999\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3427 - accuracy: 0.9040 - val_loss: 0.3495 - val_accuracy: 0.8997\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3401 - accuracy: 0.9046 - val_loss: 0.3474 - val_accuracy: 0.9004\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3378 - accuracy: 0.9049 - val_loss: 0.3450 - val_accuracy: 0.9015\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3353 - accuracy: 0.9056 - val_loss: 0.3429 - val_accuracy: 0.9016\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3330 - accuracy: 0.9061 - val_loss: 0.3408 - val_accuracy: 0.9014\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3308 - accuracy: 0.9061 - val_loss: 0.3392 - val_accuracy: 0.9015\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3286 - accuracy: 0.9070 - val_loss: 0.3369 - val_accuracy: 0.9020\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3265 - accuracy: 0.9074 - val_loss: 0.3349 - val_accuracy: 0.9026\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3245 - accuracy: 0.9081 - val_loss: 0.3333 - val_accuracy: 0.9026\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3225 - accuracy: 0.9081 - val_loss: 0.3314 - val_accuracy: 0.9036\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3206 - accuracy: 0.9093 - val_loss: 0.3297 - val_accuracy: 0.9043\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3187 - accuracy: 0.9096 - val_loss: 0.3281 - val_accuracy: 0.9043\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3168 - accuracy: 0.9102 - val_loss: 0.3263 - val_accuracy: 0.9047\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3150 - accuracy: 0.9107 - val_loss: 0.3248 - val_accuracy: 0.9053\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3133 - accuracy: 0.9109 - val_loss: 0.3232 - val_accuracy: 0.9057\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3116 - accuracy: 0.9113 - val_loss: 0.3217 - val_accuracy: 0.9059\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3099 - accuracy: 0.9120 - val_loss: 0.3203 - val_accuracy: 0.9066\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3083 - accuracy: 0.9119 - val_loss: 0.3187 - val_accuracy: 0.9072\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3067 - accuracy: 0.9122 - val_loss: 0.3173 - val_accuracy: 0.9079\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3051 - accuracy: 0.9134 - val_loss: 0.3159 - val_accuracy: 0.9085\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3036 - accuracy: 0.9135 - val_loss: 0.3147 - val_accuracy: 0.9081\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3020 - accuracy: 0.9144 - val_loss: 0.3133 - val_accuracy: 0.9097\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3005 - accuracy: 0.9147 - val_loss: 0.3121 - val_accuracy: 0.9095\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2991 - accuracy: 0.9148 - val_loss: 0.3107 - val_accuracy: 0.9103\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2977 - accuracy: 0.9154 - val_loss: 0.3097 - val_accuracy: 0.9097\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2963 - accuracy: 0.9160 - val_loss: 0.3081 - val_accuracy: 0.9110\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2949 - accuracy: 0.9163 - val_loss: 0.3071 - val_accuracy: 0.9097\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2936 - accuracy: 0.9165 - val_loss: 0.3059 - val_accuracy: 0.9124\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2922 - accuracy: 0.9176 - val_loss: 0.3049 - val_accuracy: 0.9118\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2910 - accuracy: 0.9178 - val_loss: 0.3037 - val_accuracy: 0.9120\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2896 - accuracy: 0.9182 - val_loss: 0.3025 - val_accuracy: 0.9128\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2884 - accuracy: 0.9186 - val_loss: 0.3015 - val_accuracy: 0.9121\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2872 - accuracy: 0.9187 - val_loss: 0.3004 - val_accuracy: 0.9126\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2859 - accuracy: 0.9192 - val_loss: 0.2993 - val_accuracy: 0.9140\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2847 - accuracy: 0.9197 - val_loss: 0.2982 - val_accuracy: 0.9140\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2835 - accuracy: 0.9200 - val_loss: 0.2972 - val_accuracy: 0.9141\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2823 - accuracy: 0.9204 - val_loss: 0.2963 - val_accuracy: 0.9139\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2812 - accuracy: 0.9207 - val_loss: 0.2950 - val_accuracy: 0.9144\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2800 - accuracy: 0.9209 - val_loss: 0.2941 - val_accuracy: 0.9145\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2789 - accuracy: 0.9219 - val_loss: 0.2934 - val_accuracy: 0.9149\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2778 - accuracy: 0.9217 - val_loss: 0.2922 - val_accuracy: 0.9156\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2766 - accuracy: 0.9224 - val_loss: 0.2912 - val_accuracy: 0.9166\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2755 - accuracy: 0.9230 - val_loss: 0.2903 - val_accuracy: 0.9171\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2744 - accuracy: 0.9235 - val_loss: 0.2895 - val_accuracy: 0.9171\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2734 - accuracy: 0.9235 - val_loss: 0.2886 - val_accuracy: 0.9178\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2723 - accuracy: 0.9237 - val_loss: 0.2875 - val_accuracy: 0.9176\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2713 - accuracy: 0.9237 - val_loss: 0.2865 - val_accuracy: 0.9172\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2702 - accuracy: 0.9240 - val_loss: 0.2856 - val_accuracy: 0.9183\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2692 - accuracy: 0.9247 - val_loss: 0.2849 - val_accuracy: 0.9185\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2682 - accuracy: 0.9247 - val_loss: 0.2841 - val_accuracy: 0.9193\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2672 - accuracy: 0.9255 - val_loss: 0.2831 - val_accuracy: 0.9185\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2662 - accuracy: 0.9255 - val_loss: 0.2823 - val_accuracy: 0.9191\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2653 - accuracy: 0.9256 - val_loss: 0.2817 - val_accuracy: 0.9186\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2643 - accuracy: 0.9261 - val_loss: 0.2805 - val_accuracy: 0.9197\n",
      "20000/20000 [==============================] - 1s 61us/sample - loss: 0.2741 - accuracy: 0.9204\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.7875 - accuracy: 0.5137 - val_loss: 1.2750 - val_accuracy: 0.7760\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.0442 - accuracy: 0.7861 - val_loss: 0.8005 - val_accuracy: 0.8375\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.7487 - accuracy: 0.8293 - val_loss: 0.6142 - val_accuracy: 0.8619\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.6171 - accuracy: 0.8497 - val_loss: 0.5201 - val_accuracy: 0.8746\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.5434 - accuracy: 0.8635 - val_loss: 0.4637 - val_accuracy: 0.8826\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4958 - accuracy: 0.8731 - val_loss: 0.4265 - val_accuracy: 0.8905\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4623 - accuracy: 0.8788 - val_loss: 0.4001 - val_accuracy: 0.8946\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4373 - accuracy: 0.8838 - val_loss: 0.3801 - val_accuracy: 0.8997\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4178 - accuracy: 0.8874 - val_loss: 0.3641 - val_accuracy: 0.9024\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.4021 - accuracy: 0.8904 - val_loss: 0.3517 - val_accuracy: 0.9053\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3891 - accuracy: 0.8932 - val_loss: 0.3415 - val_accuracy: 0.9072\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3778 - accuracy: 0.8950 - val_loss: 0.3317 - val_accuracy: 0.9096\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3682 - accuracy: 0.8971 - val_loss: 0.3243 - val_accuracy: 0.9112\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3596 - accuracy: 0.8998 - val_loss: 0.3180 - val_accuracy: 0.9119\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3520 - accuracy: 0.9012 - val_loss: 0.3116 - val_accuracy: 0.9128\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3452 - accuracy: 0.9033 - val_loss: 0.3059 - val_accuracy: 0.9145\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3389 - accuracy: 0.9040 - val_loss: 0.3017 - val_accuracy: 0.9162\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3330 - accuracy: 0.9057 - val_loss: 0.2968 - val_accuracy: 0.9159\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3279 - accuracy: 0.9075 - val_loss: 0.2925 - val_accuracy: 0.9176\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3228 - accuracy: 0.9083 - val_loss: 0.2886 - val_accuracy: 0.9171\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3181 - accuracy: 0.9097 - val_loss: 0.2850 - val_accuracy: 0.9183\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3137 - accuracy: 0.9110 - val_loss: 0.2812 - val_accuracy: 0.9193\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3095 - accuracy: 0.9124 - val_loss: 0.2782 - val_accuracy: 0.9206\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3055 - accuracy: 0.9133 - val_loss: 0.2751 - val_accuracy: 0.9206\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3018 - accuracy: 0.9143 - val_loss: 0.2720 - val_accuracy: 0.9215\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2982 - accuracy: 0.9157 - val_loss: 0.2692 - val_accuracy: 0.9230\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2946 - accuracy: 0.9168 - val_loss: 0.2667 - val_accuracy: 0.9227\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2914 - accuracy: 0.9180 - val_loss: 0.2647 - val_accuracy: 0.9230\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2882 - accuracy: 0.9187 - val_loss: 0.2615 - val_accuracy: 0.9258\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2850 - accuracy: 0.9196 - val_loss: 0.2592 - val_accuracy: 0.9258\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2820 - accuracy: 0.9201 - val_loss: 0.2566 - val_accuracy: 0.9265\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2791 - accuracy: 0.9213 - val_loss: 0.2546 - val_accuracy: 0.9271\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2763 - accuracy: 0.9221 - val_loss: 0.2523 - val_accuracy: 0.9276\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2736 - accuracy: 0.9227 - val_loss: 0.2500 - val_accuracy: 0.9285\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2708 - accuracy: 0.9232 - val_loss: 0.2482 - val_accuracy: 0.9290\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2684 - accuracy: 0.9247 - val_loss: 0.2458 - val_accuracy: 0.9296\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2657 - accuracy: 0.9253 - val_loss: 0.2442 - val_accuracy: 0.9304\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2633 - accuracy: 0.9259 - val_loss: 0.2419 - val_accuracy: 0.9311\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2608 - accuracy: 0.9266 - val_loss: 0.2398 - val_accuracy: 0.9327\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2585 - accuracy: 0.9273 - val_loss: 0.2384 - val_accuracy: 0.9317\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2563 - accuracy: 0.9277 - val_loss: 0.2361 - val_accuracy: 0.9334\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2539 - accuracy: 0.9284 - val_loss: 0.2347 - val_accuracy: 0.9348\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2519 - accuracy: 0.9289 - val_loss: 0.2325 - val_accuracy: 0.9337\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2497 - accuracy: 0.9296 - val_loss: 0.2311 - val_accuracy: 0.9339\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2477 - accuracy: 0.9299 - val_loss: 0.2291 - val_accuracy: 0.9351\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2456 - accuracy: 0.9307 - val_loss: 0.2276 - val_accuracy: 0.9356\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2435 - accuracy: 0.9312 - val_loss: 0.2261 - val_accuracy: 0.9370\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2416 - accuracy: 0.9321 - val_loss: 0.2246 - val_accuracy: 0.9385\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2398 - accuracy: 0.9327 - val_loss: 0.2225 - val_accuracy: 0.9377\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2377 - accuracy: 0.9332 - val_loss: 0.2217 - val_accuracy: 0.9373\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2358 - accuracy: 0.9336 - val_loss: 0.2201 - val_accuracy: 0.9373\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2341 - accuracy: 0.9344 - val_loss: 0.2186 - val_accuracy: 0.9374\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2323 - accuracy: 0.9346 - val_loss: 0.2169 - val_accuracy: 0.9392\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2304 - accuracy: 0.9353 - val_loss: 0.2154 - val_accuracy: 0.9401\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2288 - accuracy: 0.9357 - val_loss: 0.2142 - val_accuracy: 0.9400\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2270 - accuracy: 0.9365 - val_loss: 0.2134 - val_accuracy: 0.9395\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2254 - accuracy: 0.9365 - val_loss: 0.2113 - val_accuracy: 0.9415\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2237 - accuracy: 0.9375 - val_loss: 0.2102 - val_accuracy: 0.9419\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2221 - accuracy: 0.9372 - val_loss: 0.2089 - val_accuracy: 0.9423\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2205 - accuracy: 0.9381 - val_loss: 0.2082 - val_accuracy: 0.9416\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2189 - accuracy: 0.9386 - val_loss: 0.2065 - val_accuracy: 0.9427\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2175 - accuracy: 0.9389 - val_loss: 0.2052 - val_accuracy: 0.9434\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2159 - accuracy: 0.9391 - val_loss: 0.2039 - val_accuracy: 0.9442\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2144 - accuracy: 0.9398 - val_loss: 0.2026 - val_accuracy: 0.9439\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2130 - accuracy: 0.9401 - val_loss: 0.2015 - val_accuracy: 0.9452\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2114 - accuracy: 0.9403 - val_loss: 0.2002 - val_accuracy: 0.9457\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2100 - accuracy: 0.9406 - val_loss: 0.1994 - val_accuracy: 0.9460\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2086 - accuracy: 0.9415 - val_loss: 0.1985 - val_accuracy: 0.9456\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2072 - accuracy: 0.9418 - val_loss: 0.1972 - val_accuracy: 0.9460\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2058 - accuracy: 0.9420 - val_loss: 0.1963 - val_accuracy: 0.9461\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2043 - accuracy: 0.9423 - val_loss: 0.1948 - val_accuracy: 0.9473\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2031 - accuracy: 0.9427 - val_loss: 0.1938 - val_accuracy: 0.9476\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2017 - accuracy: 0.9432 - val_loss: 0.1929 - val_accuracy: 0.9470\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2003 - accuracy: 0.9433 - val_loss: 0.1922 - val_accuracy: 0.9466\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1992 - accuracy: 0.9433 - val_loss: 0.1911 - val_accuracy: 0.9479\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1977 - accuracy: 0.9445 - val_loss: 0.1903 - val_accuracy: 0.9477\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1966 - accuracy: 0.9443 - val_loss: 0.1892 - val_accuracy: 0.9480\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1954 - accuracy: 0.9446 - val_loss: 0.1882 - val_accuracy: 0.9484\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1941 - accuracy: 0.9449 - val_loss: 0.1871 - val_accuracy: 0.9489\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1929 - accuracy: 0.9451 - val_loss: 0.1862 - val_accuracy: 0.9488\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1916 - accuracy: 0.9455 - val_loss: 0.1851 - val_accuracy: 0.9494\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1905 - accuracy: 0.9460 - val_loss: 0.1846 - val_accuracy: 0.9494\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1893 - accuracy: 0.9459 - val_loss: 0.1838 - val_accuracy: 0.9495\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1882 - accuracy: 0.9465 - val_loss: 0.1824 - val_accuracy: 0.9501\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1870 - accuracy: 0.9469 - val_loss: 0.1818 - val_accuracy: 0.9499\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1859 - accuracy: 0.9469 - val_loss: 0.1808 - val_accuracy: 0.9510\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1849 - accuracy: 0.9473 - val_loss: 0.1800 - val_accuracy: 0.9511\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1837 - accuracy: 0.9476 - val_loss: 0.1793 - val_accuracy: 0.9507\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1826 - accuracy: 0.9480 - val_loss: 0.1784 - val_accuracy: 0.9515\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1815 - accuracy: 0.9484 - val_loss: 0.1774 - val_accuracy: 0.9517\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1805 - accuracy: 0.9488 - val_loss: 0.1768 - val_accuracy: 0.9519\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1793 - accuracy: 0.9492 - val_loss: 0.1765 - val_accuracy: 0.9513\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1784 - accuracy: 0.9497 - val_loss: 0.1754 - val_accuracy: 0.9526\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1773 - accuracy: 0.9494 - val_loss: 0.1743 - val_accuracy: 0.9520\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1763 - accuracy: 0.9498 - val_loss: 0.1737 - val_accuracy: 0.9520\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1753 - accuracy: 0.9504 - val_loss: 0.1730 - val_accuracy: 0.9526\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1743 - accuracy: 0.9504 - val_loss: 0.1721 - val_accuracy: 0.9524\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1733 - accuracy: 0.9510 - val_loss: 0.1711 - val_accuracy: 0.9525\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1723 - accuracy: 0.9512 - val_loss: 0.1711 - val_accuracy: 0.9528\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1715 - accuracy: 0.9515 - val_loss: 0.1697 - val_accuracy: 0.9534\n",
      "20000/20000 [==============================] - 1s 56us/sample - loss: 0.1925 - accuracy: 0.9438\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 1.7529 - accuracy: 0.5063 - val_loss: 1.2346 - val_accuracy: 0.7621\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.0126 - accuracy: 0.7860 - val_loss: 0.7837 - val_accuracy: 0.8443\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.7325 - accuracy: 0.8345 - val_loss: 0.6050 - val_accuracy: 0.8684\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.6056 - accuracy: 0.8558 - val_loss: 0.5133 - val_accuracy: 0.8801\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.5343 - accuracy: 0.8670 - val_loss: 0.4588 - val_accuracy: 0.8894\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4884 - accuracy: 0.8748 - val_loss: 0.4225 - val_accuracy: 0.8944\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4561 - accuracy: 0.8813 - val_loss: 0.3969 - val_accuracy: 0.8950\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4320 - accuracy: 0.8852 - val_loss: 0.3768 - val_accuracy: 0.9013\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4130 - accuracy: 0.8890 - val_loss: 0.3620 - val_accuracy: 0.9039\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3975 - accuracy: 0.8920 - val_loss: 0.3492 - val_accuracy: 0.9054\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3847 - accuracy: 0.8953 - val_loss: 0.3387 - val_accuracy: 0.9069\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3738 - accuracy: 0.8978 - val_loss: 0.3304 - val_accuracy: 0.9091\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3643 - accuracy: 0.9007 - val_loss: 0.3224 - val_accuracy: 0.9104\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3559 - accuracy: 0.9023 - val_loss: 0.3156 - val_accuracy: 0.9121\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3484 - accuracy: 0.9046 - val_loss: 0.3101 - val_accuracy: 0.9143\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3417 - accuracy: 0.9056 - val_loss: 0.3044 - val_accuracy: 0.9154\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3356 - accuracy: 0.9073 - val_loss: 0.2998 - val_accuracy: 0.9164\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3299 - accuracy: 0.9093 - val_loss: 0.2954 - val_accuracy: 0.9178\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3248 - accuracy: 0.9101 - val_loss: 0.2917 - val_accuracy: 0.9185\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3198 - accuracy: 0.9114 - val_loss: 0.2880 - val_accuracy: 0.9195\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3154 - accuracy: 0.9126 - val_loss: 0.2844 - val_accuracy: 0.9209\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3112 - accuracy: 0.9134 - val_loss: 0.2809 - val_accuracy: 0.9210\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3071 - accuracy: 0.9145 - val_loss: 0.2779 - val_accuracy: 0.9219\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3033 - accuracy: 0.9153 - val_loss: 0.2750 - val_accuracy: 0.9233\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2997 - accuracy: 0.9165 - val_loss: 0.2722 - val_accuracy: 0.9231\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2962 - accuracy: 0.9172 - val_loss: 0.2697 - val_accuracy: 0.9243\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2930 - accuracy: 0.9181 - val_loss: 0.2675 - val_accuracy: 0.9254\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2898 - accuracy: 0.9191 - val_loss: 0.2646 - val_accuracy: 0.9254\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2868 - accuracy: 0.9204 - val_loss: 0.2623 - val_accuracy: 0.9266\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2838 - accuracy: 0.9208 - val_loss: 0.2602 - val_accuracy: 0.9280\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2809 - accuracy: 0.9215 - val_loss: 0.2580 - val_accuracy: 0.9269\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2782 - accuracy: 0.9227 - val_loss: 0.2559 - val_accuracy: 0.9281\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2755 - accuracy: 0.9231 - val_loss: 0.2539 - val_accuracy: 0.9284\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2730 - accuracy: 0.9239 - val_loss: 0.2519 - val_accuracy: 0.9293\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2704 - accuracy: 0.9245 - val_loss: 0.2501 - val_accuracy: 0.9291\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2680 - accuracy: 0.9254 - val_loss: 0.2481 - val_accuracy: 0.9305\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2655 - accuracy: 0.9260 - val_loss: 0.2465 - val_accuracy: 0.9308\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2633 - accuracy: 0.9271 - val_loss: 0.2449 - val_accuracy: 0.9306\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2609 - accuracy: 0.9273 - val_loss: 0.2432 - val_accuracy: 0.9309\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2587 - accuracy: 0.9278 - val_loss: 0.2413 - val_accuracy: 0.9319\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2566 - accuracy: 0.9288 - val_loss: 0.2398 - val_accuracy: 0.9320\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2544 - accuracy: 0.9293 - val_loss: 0.2379 - val_accuracy: 0.9323\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2523 - accuracy: 0.9299 - val_loss: 0.2364 - val_accuracy: 0.9337\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2503 - accuracy: 0.9302 - val_loss: 0.2350 - val_accuracy: 0.9341\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2483 - accuracy: 0.9311 - val_loss: 0.2332 - val_accuracy: 0.9335\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2463 - accuracy: 0.9318 - val_loss: 0.2318 - val_accuracy: 0.9349\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2443 - accuracy: 0.9318 - val_loss: 0.2306 - val_accuracy: 0.9351\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2424 - accuracy: 0.9326 - val_loss: 0.2291 - val_accuracy: 0.9356\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2406 - accuracy: 0.9333 - val_loss: 0.2274 - val_accuracy: 0.9355\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2388 - accuracy: 0.9333 - val_loss: 0.2259 - val_accuracy: 0.9365\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2368 - accuracy: 0.9339 - val_loss: 0.2247 - val_accuracy: 0.9365\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2351 - accuracy: 0.9344 - val_loss: 0.2235 - val_accuracy: 0.9376\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2334 - accuracy: 0.9349 - val_loss: 0.2220 - val_accuracy: 0.9384\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2316 - accuracy: 0.9357 - val_loss: 0.2207 - val_accuracy: 0.9390\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2300 - accuracy: 0.9359 - val_loss: 0.2194 - val_accuracy: 0.9385\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2283 - accuracy: 0.9363 - val_loss: 0.2179 - val_accuracy: 0.9386\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2267 - accuracy: 0.9367 - val_loss: 0.2168 - val_accuracy: 0.9388\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2250 - accuracy: 0.9376 - val_loss: 0.2159 - val_accuracy: 0.9392\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2235 - accuracy: 0.9381 - val_loss: 0.2143 - val_accuracy: 0.9398\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2218 - accuracy: 0.9381 - val_loss: 0.2132 - val_accuracy: 0.9398\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2204 - accuracy: 0.9389 - val_loss: 0.2119 - val_accuracy: 0.9399\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2187 - accuracy: 0.9389 - val_loss: 0.2111 - val_accuracy: 0.9402\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2173 - accuracy: 0.9396 - val_loss: 0.2095 - val_accuracy: 0.9406\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2158 - accuracy: 0.9401 - val_loss: 0.2085 - val_accuracy: 0.9416\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2144 - accuracy: 0.9407 - val_loss: 0.2075 - val_accuracy: 0.9419\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2128 - accuracy: 0.9413 - val_loss: 0.2062 - val_accuracy: 0.9435\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2114 - accuracy: 0.9412 - val_loss: 0.2053 - val_accuracy: 0.9431\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2099 - accuracy: 0.9419 - val_loss: 0.2038 - val_accuracy: 0.9436\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2086 - accuracy: 0.9422 - val_loss: 0.2031 - val_accuracy: 0.9435\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2073 - accuracy: 0.9422 - val_loss: 0.2019 - val_accuracy: 0.9441\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2059 - accuracy: 0.9426 - val_loss: 0.2009 - val_accuracy: 0.9448\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2045 - accuracy: 0.9433 - val_loss: 0.1998 - val_accuracy: 0.9444\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2032 - accuracy: 0.9438 - val_loss: 0.1987 - val_accuracy: 0.9454\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2019 - accuracy: 0.9440 - val_loss: 0.1977 - val_accuracy: 0.9454\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2006 - accuracy: 0.9446 - val_loss: 0.1965 - val_accuracy: 0.9454\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1993 - accuracy: 0.9447 - val_loss: 0.1954 - val_accuracy: 0.9467\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1980 - accuracy: 0.9454 - val_loss: 0.1949 - val_accuracy: 0.9459\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1968 - accuracy: 0.9455 - val_loss: 0.1935 - val_accuracy: 0.9463\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1955 - accuracy: 0.9460 - val_loss: 0.1926 - val_accuracy: 0.9470\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1941 - accuracy: 0.9463 - val_loss: 0.1921 - val_accuracy: 0.9465\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1931 - accuracy: 0.9469 - val_loss: 0.1909 - val_accuracy: 0.9475\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1919 - accuracy: 0.9470 - val_loss: 0.1900 - val_accuracy: 0.9481\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1907 - accuracy: 0.9473 - val_loss: 0.1890 - val_accuracy: 0.9485\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1895 - accuracy: 0.9475 - val_loss: 0.1890 - val_accuracy: 0.9479\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1883 - accuracy: 0.9479 - val_loss: 0.1878 - val_accuracy: 0.9481\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1873 - accuracy: 0.9483 - val_loss: 0.1863 - val_accuracy: 0.9485\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1861 - accuracy: 0.9487 - val_loss: 0.1856 - val_accuracy: 0.9498\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1850 - accuracy: 0.9490 - val_loss: 0.1846 - val_accuracy: 0.9499\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1838 - accuracy: 0.9496 - val_loss: 0.1842 - val_accuracy: 0.9495\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1827 - accuracy: 0.9498 - val_loss: 0.1831 - val_accuracy: 0.9500\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1816 - accuracy: 0.9500 - val_loss: 0.1823 - val_accuracy: 0.9503\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1806 - accuracy: 0.9505 - val_loss: 0.1816 - val_accuracy: 0.9510\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1796 - accuracy: 0.9508 - val_loss: 0.1809 - val_accuracy: 0.9496\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1785 - accuracy: 0.9511 - val_loss: 0.1801 - val_accuracy: 0.9501\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1775 - accuracy: 0.9517 - val_loss: 0.1794 - val_accuracy: 0.9510\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1765 - accuracy: 0.9518 - val_loss: 0.1784 - val_accuracy: 0.9507\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1754 - accuracy: 0.9521 - val_loss: 0.1776 - val_accuracy: 0.9514\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1744 - accuracy: 0.9521 - val_loss: 0.1770 - val_accuracy: 0.9516\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1734 - accuracy: 0.9530 - val_loss: 0.1762 - val_accuracy: 0.9516\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1725 - accuracy: 0.9530 - val_loss: 0.1756 - val_accuracy: 0.9520\n",
      "20000/20000 [==============================] - 1s 56us/sample - loss: 0.2092 - accuracy: 0.9411\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 1.7021 - accuracy: 0.5390 - val_loss: 1.2246 - val_accuracy: 0.7433\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.9762 - accuracy: 0.7934 - val_loss: 0.8116 - val_accuracy: 0.8282\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.7105 - accuracy: 0.8415 - val_loss: 0.6443 - val_accuracy: 0.8515\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.5899 - accuracy: 0.8603 - val_loss: 0.5585 - val_accuracy: 0.8646\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.5221 - accuracy: 0.8712 - val_loss: 0.5059 - val_accuracy: 0.8742\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4783 - accuracy: 0.8778 - val_loss: 0.4701 - val_accuracy: 0.8776\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4475 - accuracy: 0.8833 - val_loss: 0.4437 - val_accuracy: 0.8830\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4244 - accuracy: 0.8872 - val_loss: 0.4239 - val_accuracy: 0.8854\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4062 - accuracy: 0.8907 - val_loss: 0.4080 - val_accuracy: 0.8889\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3915 - accuracy: 0.8940 - val_loss: 0.3947 - val_accuracy: 0.8906\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3793 - accuracy: 0.8971 - val_loss: 0.3837 - val_accuracy: 0.8925\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3685 - accuracy: 0.8992 - val_loss: 0.3740 - val_accuracy: 0.8950\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3595 - accuracy: 0.9008 - val_loss: 0.3658 - val_accuracy: 0.8978\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3513 - accuracy: 0.9030 - val_loss: 0.3589 - val_accuracy: 0.8981\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3441 - accuracy: 0.9046 - val_loss: 0.3517 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3375 - accuracy: 0.9065 - val_loss: 0.3454 - val_accuracy: 0.9010\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3315 - accuracy: 0.9073 - val_loss: 0.3400 - val_accuracy: 0.9015\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3260 - accuracy: 0.9092 - val_loss: 0.3351 - val_accuracy: 0.9035\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3207 - accuracy: 0.9101 - val_loss: 0.3304 - val_accuracy: 0.9045\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3159 - accuracy: 0.9114 - val_loss: 0.3262 - val_accuracy: 0.9065\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3116 - accuracy: 0.9130 - val_loss: 0.3218 - val_accuracy: 0.9070\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3074 - accuracy: 0.9136 - val_loss: 0.3187 - val_accuracy: 0.9089\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.3032 - accuracy: 0.9155 - val_loss: 0.3147 - val_accuracy: 0.9089\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2995 - accuracy: 0.9159 - val_loss: 0.3114 - val_accuracy: 0.9101\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2959 - accuracy: 0.9168 - val_loss: 0.3078 - val_accuracy: 0.9110\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2924 - accuracy: 0.9184 - val_loss: 0.3051 - val_accuracy: 0.9125\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2891 - accuracy: 0.9190 - val_loss: 0.3018 - val_accuracy: 0.9131\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2860 - accuracy: 0.9204 - val_loss: 0.2985 - val_accuracy: 0.9128\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2828 - accuracy: 0.9215 - val_loss: 0.2960 - val_accuracy: 0.9151\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2799 - accuracy: 0.9218 - val_loss: 0.2934 - val_accuracy: 0.9151\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2770 - accuracy: 0.9226 - val_loss: 0.2910 - val_accuracy: 0.9151\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2742 - accuracy: 0.9235 - val_loss: 0.2882 - val_accuracy: 0.9164\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2715 - accuracy: 0.9243 - val_loss: 0.2864 - val_accuracy: 0.9168\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2689 - accuracy: 0.9253 - val_loss: 0.2840 - val_accuracy: 0.9179\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2663 - accuracy: 0.9260 - val_loss: 0.2816 - val_accuracy: 0.9178\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2638 - accuracy: 0.9268 - val_loss: 0.2795 - val_accuracy: 0.9181\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2614 - accuracy: 0.9275 - val_loss: 0.2775 - val_accuracy: 0.9189\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2591 - accuracy: 0.9282 - val_loss: 0.2754 - val_accuracy: 0.9209\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2569 - accuracy: 0.9289 - val_loss: 0.2735 - val_accuracy: 0.9212\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2545 - accuracy: 0.9297 - val_loss: 0.2717 - val_accuracy: 0.9204\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2524 - accuracy: 0.9300 - val_loss: 0.2698 - val_accuracy: 0.9210\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2502 - accuracy: 0.9309 - val_loss: 0.2678 - val_accuracy: 0.9224\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2481 - accuracy: 0.9314 - val_loss: 0.2663 - val_accuracy: 0.9230\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2460 - accuracy: 0.9317 - val_loss: 0.2644 - val_accuracy: 0.9225\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2441 - accuracy: 0.9324 - val_loss: 0.2627 - val_accuracy: 0.9241\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2420 - accuracy: 0.9329 - val_loss: 0.2608 - val_accuracy: 0.9240\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2401 - accuracy: 0.9333 - val_loss: 0.2592 - val_accuracy: 0.9239\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2382 - accuracy: 0.9345 - val_loss: 0.2576 - val_accuracy: 0.9251\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2362 - accuracy: 0.9344 - val_loss: 0.2561 - val_accuracy: 0.9255\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2344 - accuracy: 0.9352 - val_loss: 0.2545 - val_accuracy: 0.9243\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2326 - accuracy: 0.9357 - val_loss: 0.2532 - val_accuracy: 0.9258\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2308 - accuracy: 0.9359 - val_loss: 0.2517 - val_accuracy: 0.9270\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2291 - accuracy: 0.9366 - val_loss: 0.2500 - val_accuracy: 0.9265\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2273 - accuracy: 0.9369 - val_loss: 0.2484 - val_accuracy: 0.9276\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2256 - accuracy: 0.9372 - val_loss: 0.2474 - val_accuracy: 0.9284\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2240 - accuracy: 0.9376 - val_loss: 0.2456 - val_accuracy: 0.9284\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2223 - accuracy: 0.9384 - val_loss: 0.2444 - val_accuracy: 0.9284\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2207 - accuracy: 0.9388 - val_loss: 0.2430 - val_accuracy: 0.9293\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2191 - accuracy: 0.9388 - val_loss: 0.2414 - val_accuracy: 0.9302\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2175 - accuracy: 0.9393 - val_loss: 0.2405 - val_accuracy: 0.9298\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2160 - accuracy: 0.9399 - val_loss: 0.2390 - val_accuracy: 0.9305\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2145 - accuracy: 0.9402 - val_loss: 0.2376 - val_accuracy: 0.9306\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2130 - accuracy: 0.9406 - val_loss: 0.2366 - val_accuracy: 0.9311\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2116 - accuracy: 0.9407 - val_loss: 0.2352 - val_accuracy: 0.9316\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2100 - accuracy: 0.9411 - val_loss: 0.2339 - val_accuracy: 0.9320\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2086 - accuracy: 0.9416 - val_loss: 0.2329 - val_accuracy: 0.9326\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2072 - accuracy: 0.9419 - val_loss: 0.2321 - val_accuracy: 0.9325\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2058 - accuracy: 0.9425 - val_loss: 0.2306 - val_accuracy: 0.9331\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2045 - accuracy: 0.9424 - val_loss: 0.2293 - val_accuracy: 0.9336\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2030 - accuracy: 0.9435 - val_loss: 0.2284 - val_accuracy: 0.9341\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2017 - accuracy: 0.9437 - val_loss: 0.2272 - val_accuracy: 0.9340\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2004 - accuracy: 0.9441 - val_loss: 0.2260 - val_accuracy: 0.9350\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1991 - accuracy: 0.9448 - val_loss: 0.2251 - val_accuracy: 0.9350\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1978 - accuracy: 0.9450 - val_loss: 0.2240 - val_accuracy: 0.9358\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1964 - accuracy: 0.9453 - val_loss: 0.2237 - val_accuracy: 0.9356\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1953 - accuracy: 0.9457 - val_loss: 0.2220 - val_accuracy: 0.9361\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1940 - accuracy: 0.9454 - val_loss: 0.2213 - val_accuracy: 0.9365\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1928 - accuracy: 0.9459 - val_loss: 0.2198 - val_accuracy: 0.9369\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1916 - accuracy: 0.9461 - val_loss: 0.2186 - val_accuracy: 0.9371\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1904 - accuracy: 0.9464 - val_loss: 0.2178 - val_accuracy: 0.9379\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1892 - accuracy: 0.9469 - val_loss: 0.2166 - val_accuracy: 0.9388\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1881 - accuracy: 0.9468 - val_loss: 0.2161 - val_accuracy: 0.9388\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1869 - accuracy: 0.9474 - val_loss: 0.2148 - val_accuracy: 0.9388\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1857 - accuracy: 0.9483 - val_loss: 0.2138 - val_accuracy: 0.9390\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1847 - accuracy: 0.9480 - val_loss: 0.2128 - val_accuracy: 0.9391\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1835 - accuracy: 0.9481 - val_loss: 0.2123 - val_accuracy: 0.9405\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.1824 - accuracy: 0.9488 - val_loss: 0.2115 - val_accuracy: 0.9402\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1814 - accuracy: 0.9486 - val_loss: 0.2102 - val_accuracy: 0.9402\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1802 - accuracy: 0.9495 - val_loss: 0.2096 - val_accuracy: 0.9410\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1792 - accuracy: 0.9497 - val_loss: 0.2084 - val_accuracy: 0.9408\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1782 - accuracy: 0.9500 - val_loss: 0.2076 - val_accuracy: 0.9413\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.1771 - accuracy: 0.9506 - val_loss: 0.2069 - val_accuracy: 0.9409\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.1762 - accuracy: 0.9504 - val_loss: 0.2061 - val_accuracy: 0.9420\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1750 - accuracy: 0.9509 - val_loss: 0.2051 - val_accuracy: 0.9408\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1741 - accuracy: 0.9512 - val_loss: 0.2041 - val_accuracy: 0.9423\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1731 - accuracy: 0.9514 - val_loss: 0.2036 - val_accuracy: 0.9419\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1721 - accuracy: 0.9519 - val_loss: 0.2027 - val_accuracy: 0.9427\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1711 - accuracy: 0.9515 - val_loss: 0.2019 - val_accuracy: 0.9425\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1702 - accuracy: 0.9522 - val_loss: 0.2012 - val_accuracy: 0.9415\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1692 - accuracy: 0.9527 - val_loss: 0.2001 - val_accuracy: 0.9427\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.1983 - accuracy: 0.9431\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 2.3059 - accuracy: 0.1133 - val_loss: 2.2819 - val_accuracy: 0.1375\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 2.2617 - accuracy: 0.1579 - val_loss: 2.2359 - val_accuracy: 0.1998\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 2.2152 - accuracy: 0.2337 - val_loss: 2.1840 - val_accuracy: 0.2965\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 2.1609 - accuracy: 0.3254 - val_loss: 2.1212 - val_accuracy: 0.3840\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 2.0935 - accuracy: 0.3951 - val_loss: 2.0423 - val_accuracy: 0.4367\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.0077 - accuracy: 0.4422 - val_loss: 1.9414 - val_accuracy: 0.4799\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 1.8978 - accuracy: 0.4843 - val_loss: 1.8141 - val_accuracy: 0.5299\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 1.7641 - accuracy: 0.5337 - val_loss: 1.6664 - val_accuracy: 0.5817\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 1.6167 - accuracy: 0.5916 - val_loss: 1.5114 - val_accuracy: 0.6429\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 37us/sample - loss: 1.4677 - accuracy: 0.6497 - val_loss: 1.3601 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 1.3257 - accuracy: 0.6940 - val_loss: 1.2192 - val_accuracy: 0.7419\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 1.1960 - accuracy: 0.7225 - val_loss: 1.0931 - val_accuracy: 0.7616\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 1.0820 - accuracy: 0.7407 - val_loss: 0.9848 - val_accuracy: 0.7736\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.9850 - accuracy: 0.7531 - val_loss: 0.8932 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.9041 - accuracy: 0.7665 - val_loss: 0.8177 - val_accuracy: 0.7979\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.8372 - accuracy: 0.7774 - val_loss: 0.7554 - val_accuracy: 0.8083\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.7823 - accuracy: 0.7882 - val_loss: 0.7048 - val_accuracy: 0.8179\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.7367 - accuracy: 0.7967 - val_loss: 0.6629 - val_accuracy: 0.8266\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.6984 - accuracy: 0.8034 - val_loss: 0.6271 - val_accuracy: 0.8339\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.6658 - accuracy: 0.8108 - val_loss: 0.5962 - val_accuracy: 0.8391\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.6375 - accuracy: 0.8159 - val_loss: 0.5703 - val_accuracy: 0.8426\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.6131 - accuracy: 0.8228 - val_loss: 0.5471 - val_accuracy: 0.8491\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.5913 - accuracy: 0.8288 - val_loss: 0.5274 - val_accuracy: 0.8534\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.5718 - accuracy: 0.8338 - val_loss: 0.5097 - val_accuracy: 0.8564\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.5545 - accuracy: 0.8389 - val_loss: 0.4931 - val_accuracy: 0.8609\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.5387 - accuracy: 0.8436 - val_loss: 0.4796 - val_accuracy: 0.8634\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.5245 - accuracy: 0.8478 - val_loss: 0.4656 - val_accuracy: 0.8673\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.5112 - accuracy: 0.8510 - val_loss: 0.4538 - val_accuracy: 0.8699\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4991 - accuracy: 0.8550 - val_loss: 0.4430 - val_accuracy: 0.8749\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4879 - accuracy: 0.8589 - val_loss: 0.4325 - val_accuracy: 0.8755\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.4776 - accuracy: 0.8614 - val_loss: 0.4235 - val_accuracy: 0.8777\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.4679 - accuracy: 0.8644 - val_loss: 0.4153 - val_accuracy: 0.8816\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4589 - accuracy: 0.8667 - val_loss: 0.4067 - val_accuracy: 0.8852\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4505 - accuracy: 0.8688 - val_loss: 0.3993 - val_accuracy: 0.8866\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4425 - accuracy: 0.8715 - val_loss: 0.3918 - val_accuracy: 0.8892\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4349 - accuracy: 0.8735 - val_loss: 0.3858 - val_accuracy: 0.8895\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4280 - accuracy: 0.8755 - val_loss: 0.3798 - val_accuracy: 0.8924\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4213 - accuracy: 0.8784 - val_loss: 0.3738 - val_accuracy: 0.8934\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4150 - accuracy: 0.8795 - val_loss: 0.3681 - val_accuracy: 0.8942\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4090 - accuracy: 0.8814 - val_loss: 0.3634 - val_accuracy: 0.8961\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4033 - accuracy: 0.8827 - val_loss: 0.3581 - val_accuracy: 0.8966\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3979 - accuracy: 0.8845 - val_loss: 0.3535 - val_accuracy: 0.8972\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3928 - accuracy: 0.8863 - val_loss: 0.3491 - val_accuracy: 0.9003\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3878 - accuracy: 0.8870 - val_loss: 0.3447 - val_accuracy: 0.9010\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3832 - accuracy: 0.8881 - val_loss: 0.3416 - val_accuracy: 0.9013\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3787 - accuracy: 0.8898 - val_loss: 0.3370 - val_accuracy: 0.9034\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3745 - accuracy: 0.8904 - val_loss: 0.3334 - val_accuracy: 0.9036\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.3702 - accuracy: 0.8926 - val_loss: 0.3295 - val_accuracy: 0.9045\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3664 - accuracy: 0.8931 - val_loss: 0.3264 - val_accuracy: 0.9057\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3625 - accuracy: 0.8938 - val_loss: 0.3232 - val_accuracy: 0.9070\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3588 - accuracy: 0.8956 - val_loss: 0.3196 - val_accuracy: 0.9080\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3553 - accuracy: 0.8965 - val_loss: 0.3164 - val_accuracy: 0.9082\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3519 - accuracy: 0.8971 - val_loss: 0.3136 - val_accuracy: 0.9093\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3485 - accuracy: 0.8983 - val_loss: 0.3114 - val_accuracy: 0.9095\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3451 - accuracy: 0.8990 - val_loss: 0.3100 - val_accuracy: 0.9087\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3421 - accuracy: 0.8998 - val_loss: 0.3059 - val_accuracy: 0.9118\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3392 - accuracy: 0.9008 - val_loss: 0.3032 - val_accuracy: 0.9124\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3362 - accuracy: 0.9010 - val_loss: 0.3004 - val_accuracy: 0.9125\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3333 - accuracy: 0.9018 - val_loss: 0.2977 - val_accuracy: 0.9133\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3307 - accuracy: 0.9027 - val_loss: 0.2959 - val_accuracy: 0.9135\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3279 - accuracy: 0.9039 - val_loss: 0.2935 - val_accuracy: 0.9145\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.3254 - accuracy: 0.9038 - val_loss: 0.2915 - val_accuracy: 0.9146\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3228 - accuracy: 0.9049 - val_loss: 0.2890 - val_accuracy: 0.9150\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3203 - accuracy: 0.9056 - val_loss: 0.2869 - val_accuracy: 0.9156\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3180 - accuracy: 0.9063 - val_loss: 0.2854 - val_accuracy: 0.9160\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.3155 - accuracy: 0.9074 - val_loss: 0.2837 - val_accuracy: 0.9160\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3133 - accuracy: 0.9079 - val_loss: 0.2811 - val_accuracy: 0.9164\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3110 - accuracy: 0.9091 - val_loss: 0.2798 - val_accuracy: 0.9161\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.3089 - accuracy: 0.9093 - val_loss: 0.2770 - val_accuracy: 0.9179\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.3067 - accuracy: 0.9103 - val_loss: 0.2756 - val_accuracy: 0.9189\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3046 - accuracy: 0.9111 - val_loss: 0.2741 - val_accuracy: 0.9195\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3025 - accuracy: 0.9119 - val_loss: 0.2726 - val_accuracy: 0.9191\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3005 - accuracy: 0.9117 - val_loss: 0.2703 - val_accuracy: 0.9204\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.2985 - accuracy: 0.9128 - val_loss: 0.2686 - val_accuracy: 0.9209\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2966 - accuracy: 0.9131 - val_loss: 0.2674 - val_accuracy: 0.9211\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2947 - accuracy: 0.9140 - val_loss: 0.2663 - val_accuracy: 0.9219\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2929 - accuracy: 0.9136 - val_loss: 0.2639 - val_accuracy: 0.9224\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.2911 - accuracy: 0.9150 - val_loss: 0.2623 - val_accuracy: 0.9224\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2892 - accuracy: 0.9150 - val_loss: 0.2608 - val_accuracy: 0.9234\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2875 - accuracy: 0.9162 - val_loss: 0.2594 - val_accuracy: 0.9234\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.2857 - accuracy: 0.9165 - val_loss: 0.2579 - val_accuracy: 0.9244\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 2s 48us/sample - loss: 0.2841 - accuracy: 0.9176 - val_loss: 0.2569 - val_accuracy: 0.9246\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2823 - accuracy: 0.9175 - val_loss: 0.2555 - val_accuracy: 0.9246\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2808 - accuracy: 0.9181 - val_loss: 0.2540 - val_accuracy: 0.9260\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2791 - accuracy: 0.9187 - val_loss: 0.2526 - val_accuracy: 0.9262\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2776 - accuracy: 0.9197 - val_loss: 0.2510 - val_accuracy: 0.9265\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2760 - accuracy: 0.9197 - val_loss: 0.2501 - val_accuracy: 0.9271\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2744 - accuracy: 0.9205 - val_loss: 0.2485 - val_accuracy: 0.9273\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2728 - accuracy: 0.9206 - val_loss: 0.2477 - val_accuracy: 0.9271\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2714 - accuracy: 0.9212 - val_loss: 0.2466 - val_accuracy: 0.9277\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2699 - accuracy: 0.9222 - val_loss: 0.2447 - val_accuracy: 0.9276\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2682 - accuracy: 0.9222 - val_loss: 0.2437 - val_accuracy: 0.9290\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2671 - accuracy: 0.9228 - val_loss: 0.2428 - val_accuracy: 0.9291\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2654 - accuracy: 0.9234 - val_loss: 0.2423 - val_accuracy: 0.9290\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2642 - accuracy: 0.9236 - val_loss: 0.2409 - val_accuracy: 0.9287\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2629 - accuracy: 0.9243 - val_loss: 0.2391 - val_accuracy: 0.9299\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2614 - accuracy: 0.9243 - val_loss: 0.2382 - val_accuracy: 0.9296\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2601 - accuracy: 0.9245 - val_loss: 0.2368 - val_accuracy: 0.9299\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2588 - accuracy: 0.9254 - val_loss: 0.2363 - val_accuracy: 0.9301\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2575 - accuracy: 0.9255 - val_loss: 0.2350 - val_accuracy: 0.9304\n",
      "20000/20000 [==============================] - 1s 70us/sample - loss: 0.2652 - accuracy: 0.9243\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 58us/sample - loss: 2.2951 - accuracy: 0.0979 - val_loss: 2.2869 - val_accuracy: 0.1090\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.2775 - accuracy: 0.1310 - val_loss: 2.2695 - val_accuracy: 0.1486\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 2.2603 - accuracy: 0.1808 - val_loss: 2.2516 - val_accuracy: 0.2173\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2419 - accuracy: 0.2499 - val_loss: 2.2315 - val_accuracy: 0.2924\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2206 - accuracy: 0.3207 - val_loss: 2.2078 - val_accuracy: 0.3575\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 2.1947 - accuracy: 0.3770 - val_loss: 2.1785 - val_accuracy: 0.4034\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.1624 - accuracy: 0.4193 - val_loss: 2.1415 - val_accuracy: 0.4334\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 2.1214 - accuracy: 0.4440 - val_loss: 2.0942 - val_accuracy: 0.4588\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.0685 - accuracy: 0.4699 - val_loss: 2.0329 - val_accuracy: 0.4814\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 2.0002 - accuracy: 0.4892 - val_loss: 1.9547 - val_accuracy: 0.4988\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.9146 - accuracy: 0.5083 - val_loss: 1.8581 - val_accuracy: 0.5206\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.8111 - accuracy: 0.5299 - val_loss: 1.7429 - val_accuracy: 0.5476\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.6915 - accuracy: 0.5657 - val_loss: 1.6132 - val_accuracy: 0.5897\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.5605 - accuracy: 0.6068 - val_loss: 1.4743 - val_accuracy: 0.6426\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.4251 - accuracy: 0.6487 - val_loss: 1.3345 - val_accuracy: 0.6877\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.2930 - accuracy: 0.6824 - val_loss: 1.2015 - val_accuracy: 0.7182\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.1709 - accuracy: 0.7110 - val_loss: 1.0815 - val_accuracy: 0.7390\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 1.0631 - accuracy: 0.7316 - val_loss: 0.9765 - val_accuracy: 0.7616\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.9710 - accuracy: 0.7501 - val_loss: 0.8887 - val_accuracy: 0.7799\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.8938 - accuracy: 0.7654 - val_loss: 0.8157 - val_accuracy: 0.7929\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.8293 - accuracy: 0.7775 - val_loss: 0.7543 - val_accuracy: 0.8054\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.7751 - accuracy: 0.7903 - val_loss: 0.7032 - val_accuracy: 0.8164\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7293 - accuracy: 0.8004 - val_loss: 0.6598 - val_accuracy: 0.8225\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6902 - accuracy: 0.8098 - val_loss: 0.6229 - val_accuracy: 0.8309\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.6563 - accuracy: 0.8185 - val_loss: 0.5913 - val_accuracy: 0.8395\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.6267 - accuracy: 0.8267 - val_loss: 0.5636 - val_accuracy: 0.8451\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6008 - accuracy: 0.8339 - val_loss: 0.5398 - val_accuracy: 0.8518\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5779 - accuracy: 0.8395 - val_loss: 0.5185 - val_accuracy: 0.8576\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5578 - accuracy: 0.8444 - val_loss: 0.5000 - val_accuracy: 0.8619\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5398 - accuracy: 0.8486 - val_loss: 0.4834 - val_accuracy: 0.8664\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5235 - accuracy: 0.8518 - val_loss: 0.4683 - val_accuracy: 0.8708\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5088 - accuracy: 0.8560 - val_loss: 0.4549 - val_accuracy: 0.8754\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4954 - accuracy: 0.8600 - val_loss: 0.4428 - val_accuracy: 0.8798\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4832 - accuracy: 0.8625 - val_loss: 0.4320 - val_accuracy: 0.8826\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4719 - accuracy: 0.8655 - val_loss: 0.4222 - val_accuracy: 0.8855\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4616 - accuracy: 0.8688 - val_loss: 0.4125 - val_accuracy: 0.8881\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4521 - accuracy: 0.8715 - val_loss: 0.4044 - val_accuracy: 0.8892\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4434 - accuracy: 0.8740 - val_loss: 0.3966 - val_accuracy: 0.8911\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4352 - accuracy: 0.8760 - val_loss: 0.3894 - val_accuracy: 0.8925\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4274 - accuracy: 0.8786 - val_loss: 0.3823 - val_accuracy: 0.8942\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4202 - accuracy: 0.8802 - val_loss: 0.3764 - val_accuracy: 0.8955\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4136 - accuracy: 0.8818 - val_loss: 0.3704 - val_accuracy: 0.8972\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4072 - accuracy: 0.8837 - val_loss: 0.3649 - val_accuracy: 0.8980\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4012 - accuracy: 0.8857 - val_loss: 0.3599 - val_accuracy: 0.8988\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3955 - accuracy: 0.8867 - val_loss: 0.3550 - val_accuracy: 0.9004\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3901 - accuracy: 0.8882 - val_loss: 0.3503 - val_accuracy: 0.9011\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3851 - accuracy: 0.8905 - val_loss: 0.3465 - val_accuracy: 0.9026\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3800 - accuracy: 0.8915 - val_loss: 0.3420 - val_accuracy: 0.9028\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3754 - accuracy: 0.8931 - val_loss: 0.3379 - val_accuracy: 0.9049\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3712 - accuracy: 0.8939 - val_loss: 0.3341 - val_accuracy: 0.9050\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3668 - accuracy: 0.8956 - val_loss: 0.3305 - val_accuracy: 0.9050\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3625 - accuracy: 0.8974 - val_loss: 0.3269 - val_accuracy: 0.9060\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3587 - accuracy: 0.8981 - val_loss: 0.3238 - val_accuracy: 0.9079\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3547 - accuracy: 0.8994 - val_loss: 0.3206 - val_accuracy: 0.9086\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3509 - accuracy: 0.8996 - val_loss: 0.3173 - val_accuracy: 0.9089\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3474 - accuracy: 0.9015 - val_loss: 0.3148 - val_accuracy: 0.9096\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3440 - accuracy: 0.9018 - val_loss: 0.3115 - val_accuracy: 0.9119\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3406 - accuracy: 0.9028 - val_loss: 0.3088 - val_accuracy: 0.9125\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3374 - accuracy: 0.9035 - val_loss: 0.3062 - val_accuracy: 0.9129\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3342 - accuracy: 0.9043 - val_loss: 0.3034 - val_accuracy: 0.9131\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3310 - accuracy: 0.9054 - val_loss: 0.3015 - val_accuracy: 0.9135\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3281 - accuracy: 0.9059 - val_loss: 0.2986 - val_accuracy: 0.9143\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3251 - accuracy: 0.9068 - val_loss: 0.2960 - val_accuracy: 0.9154\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3224 - accuracy: 0.9072 - val_loss: 0.2942 - val_accuracy: 0.9160\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3196 - accuracy: 0.9078 - val_loss: 0.2918 - val_accuracy: 0.9155\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3169 - accuracy: 0.9087 - val_loss: 0.2894 - val_accuracy: 0.9172\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3143 - accuracy: 0.9093 - val_loss: 0.2874 - val_accuracy: 0.9172\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3118 - accuracy: 0.9104 - val_loss: 0.2856 - val_accuracy: 0.9175\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3093 - accuracy: 0.9107 - val_loss: 0.2834 - val_accuracy: 0.9194\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3069 - accuracy: 0.9117 - val_loss: 0.2812 - val_accuracy: 0.9194\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3044 - accuracy: 0.9126 - val_loss: 0.2794 - val_accuracy: 0.9193\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3020 - accuracy: 0.9128 - val_loss: 0.2776 - val_accuracy: 0.9205\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2998 - accuracy: 0.9143 - val_loss: 0.2758 - val_accuracy: 0.9216\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2976 - accuracy: 0.9147 - val_loss: 0.2739 - val_accuracy: 0.9211\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2955 - accuracy: 0.9152 - val_loss: 0.2720 - val_accuracy: 0.9212\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2933 - accuracy: 0.9152 - val_loss: 0.2711 - val_accuracy: 0.9230\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2912 - accuracy: 0.9162 - val_loss: 0.2688 - val_accuracy: 0.9236\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2890 - accuracy: 0.9172 - val_loss: 0.2671 - val_accuracy: 0.9237\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2870 - accuracy: 0.9173 - val_loss: 0.2658 - val_accuracy: 0.9239\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2850 - accuracy: 0.9182 - val_loss: 0.2642 - val_accuracy: 0.9249\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2832 - accuracy: 0.9182 - val_loss: 0.2624 - val_accuracy: 0.9241\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2811 - accuracy: 0.9187 - val_loss: 0.2611 - val_accuracy: 0.9256\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2794 - accuracy: 0.9196 - val_loss: 0.2593 - val_accuracy: 0.9261\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2773 - accuracy: 0.9197 - val_loss: 0.2577 - val_accuracy: 0.9268\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2757 - accuracy: 0.9201 - val_loss: 0.2564 - val_accuracy: 0.9268\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.2738 - accuracy: 0.9209 - val_loss: 0.2553 - val_accuracy: 0.9274\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2721 - accuracy: 0.9217 - val_loss: 0.2536 - val_accuracy: 0.9271\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2704 - accuracy: 0.9217 - val_loss: 0.2522 - val_accuracy: 0.9270\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2687 - accuracy: 0.9222 - val_loss: 0.2508 - val_accuracy: 0.9279\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2670 - accuracy: 0.9228 - val_loss: 0.2495 - val_accuracy: 0.9281\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2654 - accuracy: 0.9226 - val_loss: 0.2482 - val_accuracy: 0.9291\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2637 - accuracy: 0.9231 - val_loss: 0.2472 - val_accuracy: 0.9287\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2621 - accuracy: 0.9242 - val_loss: 0.2456 - val_accuracy: 0.9286\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2606 - accuracy: 0.9243 - val_loss: 0.2445 - val_accuracy: 0.9302\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2591 - accuracy: 0.9247 - val_loss: 0.2434 - val_accuracy: 0.9293\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2576 - accuracy: 0.9246 - val_loss: 0.2421 - val_accuracy: 0.9299\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2560 - accuracy: 0.9262 - val_loss: 0.2408 - val_accuracy: 0.9301\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2546 - accuracy: 0.9257 - val_loss: 0.2397 - val_accuracy: 0.9296\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2532 - accuracy: 0.9264 - val_loss: 0.2387 - val_accuracy: 0.9302\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2516 - accuracy: 0.9267 - val_loss: 0.2374 - val_accuracy: 0.9329\n",
      "20000/20000 [==============================] - 1s 59us/sample - loss: 0.2782 - accuracy: 0.9193\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 2.3119 - accuracy: 0.0754 - val_loss: 2.3003 - val_accuracy: 0.0845\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 2.2884 - accuracy: 0.0962 - val_loss: 2.2767 - val_accuracy: 0.1046\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 2.2641 - accuracy: 0.1200 - val_loss: 2.2515 - val_accuracy: 0.1276\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 2.2377 - accuracy: 0.1441 - val_loss: 2.2234 - val_accuracy: 0.1509\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 2.2072 - accuracy: 0.1765 - val_loss: 2.1903 - val_accuracy: 0.1940\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.1709 - accuracy: 0.2290 - val_loss: 2.1504 - val_accuracy: 0.2601\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.1271 - accuracy: 0.2969 - val_loss: 2.1023 - val_accuracy: 0.3331\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 2.0739 - accuracy: 0.3673 - val_loss: 2.0441 - val_accuracy: 0.3981\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.0094 - accuracy: 0.4286 - val_loss: 1.9738 - val_accuracy: 0.4512\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.9318 - accuracy: 0.4836 - val_loss: 1.8897 - val_accuracy: 0.5045\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.8401 - accuracy: 0.5361 - val_loss: 1.7918 - val_accuracy: 0.5481\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.7355 - accuracy: 0.5763 - val_loss: 1.6827 - val_accuracy: 0.5861\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.6221 - accuracy: 0.6096 - val_loss: 1.5679 - val_accuracy: 0.6086\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.5057 - accuracy: 0.6358 - val_loss: 1.4528 - val_accuracy: 0.6348\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.3915 - accuracy: 0.6583 - val_loss: 1.3418 - val_accuracy: 0.6705\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 1.2827 - accuracy: 0.6845 - val_loss: 1.2377 - val_accuracy: 0.6934\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.1811 - accuracy: 0.7091 - val_loss: 1.1408 - val_accuracy: 0.7161\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.0878 - accuracy: 0.7301 - val_loss: 1.0527 - val_accuracy: 0.7385\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 1.0037 - accuracy: 0.7496 - val_loss: 0.9732 - val_accuracy: 0.7550\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.9290 - accuracy: 0.7660 - val_loss: 0.9032 - val_accuracy: 0.7675\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8635 - accuracy: 0.7784 - val_loss: 0.8427 - val_accuracy: 0.7812\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.8066 - accuracy: 0.7908 - val_loss: 0.7899 - val_accuracy: 0.7946\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.7575 - accuracy: 0.8004 - val_loss: 0.7451 - val_accuracy: 0.8015\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7153 - accuracy: 0.8098 - val_loss: 0.7050 - val_accuracy: 0.8108\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6788 - accuracy: 0.8174 - val_loss: 0.6716 - val_accuracy: 0.8181\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6473 - accuracy: 0.8243 - val_loss: 0.6430 - val_accuracy: 0.8250\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.6197 - accuracy: 0.8303 - val_loss: 0.6158 - val_accuracy: 0.8326\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5953 - accuracy: 0.8377 - val_loss: 0.5931 - val_accuracy: 0.8366\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5736 - accuracy: 0.8426 - val_loss: 0.5717 - val_accuracy: 0.8429\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5542 - accuracy: 0.8471 - val_loss: 0.5532 - val_accuracy: 0.8472\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.5368 - accuracy: 0.8513 - val_loss: 0.5361 - val_accuracy: 0.8510\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.5211 - accuracy: 0.8553 - val_loss: 0.5216 - val_accuracy: 0.8541\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5068 - accuracy: 0.8587 - val_loss: 0.5077 - val_accuracy: 0.8583\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4940 - accuracy: 0.8620 - val_loss: 0.4958 - val_accuracy: 0.8630\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4821 - accuracy: 0.8651 - val_loss: 0.4846 - val_accuracy: 0.8654\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4711 - accuracy: 0.8684 - val_loss: 0.4741 - val_accuracy: 0.8674\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4613 - accuracy: 0.8699 - val_loss: 0.4641 - val_accuracy: 0.8715\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4521 - accuracy: 0.8732 - val_loss: 0.4546 - val_accuracy: 0.8735\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4435 - accuracy: 0.8752 - val_loss: 0.4463 - val_accuracy: 0.8771\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4358 - accuracy: 0.8769 - val_loss: 0.4390 - val_accuracy: 0.8786\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4284 - accuracy: 0.8788 - val_loss: 0.4324 - val_accuracy: 0.8801\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4215 - accuracy: 0.8809 - val_loss: 0.4257 - val_accuracy: 0.8819\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4151 - accuracy: 0.8827 - val_loss: 0.4195 - val_accuracy: 0.8838\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4091 - accuracy: 0.8842 - val_loss: 0.4142 - val_accuracy: 0.8852\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4034 - accuracy: 0.8856 - val_loss: 0.4082 - val_accuracy: 0.8861\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3982 - accuracy: 0.8870 - val_loss: 0.4039 - val_accuracy: 0.8876\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3930 - accuracy: 0.8883 - val_loss: 0.3983 - val_accuracy: 0.8892\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3882 - accuracy: 0.8898 - val_loss: 0.3936 - val_accuracy: 0.8905\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3837 - accuracy: 0.8915 - val_loss: 0.3894 - val_accuracy: 0.8905\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3794 - accuracy: 0.8924 - val_loss: 0.3863 - val_accuracy: 0.8919\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3754 - accuracy: 0.8930 - val_loss: 0.3822 - val_accuracy: 0.8936\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3714 - accuracy: 0.8945 - val_loss: 0.3775 - val_accuracy: 0.8947\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3676 - accuracy: 0.8957 - val_loss: 0.3743 - val_accuracy: 0.8955\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3640 - accuracy: 0.8972 - val_loss: 0.3709 - val_accuracy: 0.8964\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3604 - accuracy: 0.8978 - val_loss: 0.3686 - val_accuracy: 0.8963\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3571 - accuracy: 0.8988 - val_loss: 0.3647 - val_accuracy: 0.8978\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3538 - accuracy: 0.8996 - val_loss: 0.3618 - val_accuracy: 0.8999\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3509 - accuracy: 0.9006 - val_loss: 0.3591 - val_accuracy: 0.9005\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3479 - accuracy: 0.9021 - val_loss: 0.3562 - val_accuracy: 0.9004\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3450 - accuracy: 0.9026 - val_loss: 0.3532 - val_accuracy: 0.9007\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3423 - accuracy: 0.9030 - val_loss: 0.3505 - val_accuracy: 0.9019\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3395 - accuracy: 0.9032 - val_loss: 0.3483 - val_accuracy: 0.9030\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3369 - accuracy: 0.9046 - val_loss: 0.3459 - val_accuracy: 0.9031\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3343 - accuracy: 0.9050 - val_loss: 0.3440 - val_accuracy: 0.9039\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3319 - accuracy: 0.9056 - val_loss: 0.3420 - val_accuracy: 0.9031\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3296 - accuracy: 0.9066 - val_loss: 0.3396 - val_accuracy: 0.9047\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3271 - accuracy: 0.9069 - val_loss: 0.3378 - val_accuracy: 0.9054\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3249 - accuracy: 0.9081 - val_loss: 0.3351 - val_accuracy: 0.9062\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3226 - accuracy: 0.9088 - val_loss: 0.3329 - val_accuracy: 0.9062\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3206 - accuracy: 0.9088 - val_loss: 0.3309 - val_accuracy: 0.9062\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3183 - accuracy: 0.9093 - val_loss: 0.3290 - val_accuracy: 0.9056\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.3162 - accuracy: 0.9100 - val_loss: 0.3281 - val_accuracy: 0.9071\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.3143 - accuracy: 0.9101 - val_loss: 0.3250 - val_accuracy: 0.9075\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.3122 - accuracy: 0.9112 - val_loss: 0.3230 - val_accuracy: 0.9085\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.3102 - accuracy: 0.9114 - val_loss: 0.3215 - val_accuracy: 0.9078\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3084 - accuracy: 0.9123 - val_loss: 0.3201 - val_accuracy: 0.9085\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3065 - accuracy: 0.9127 - val_loss: 0.3181 - val_accuracy: 0.9084\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3047 - accuracy: 0.9126 - val_loss: 0.3172 - val_accuracy: 0.9085\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3029 - accuracy: 0.9135 - val_loss: 0.3148 - val_accuracy: 0.9105\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3011 - accuracy: 0.9139 - val_loss: 0.3131 - val_accuracy: 0.9109\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2993 - accuracy: 0.9142 - val_loss: 0.3116 - val_accuracy: 0.9099\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2977 - accuracy: 0.9151 - val_loss: 0.3102 - val_accuracy: 0.9104\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2960 - accuracy: 0.9153 - val_loss: 0.3087 - val_accuracy: 0.9091\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2944 - accuracy: 0.9155 - val_loss: 0.3068 - val_accuracy: 0.9109\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2926 - accuracy: 0.9158 - val_loss: 0.3051 - val_accuracy: 0.9110\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2910 - accuracy: 0.9168 - val_loss: 0.3049 - val_accuracy: 0.9101\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2895 - accuracy: 0.9167 - val_loss: 0.3029 - val_accuracy: 0.9110\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2880 - accuracy: 0.9180 - val_loss: 0.3015 - val_accuracy: 0.9115\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2863 - accuracy: 0.9177 - val_loss: 0.3016 - val_accuracy: 0.9109\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2849 - accuracy: 0.9189 - val_loss: 0.2988 - val_accuracy: 0.9130\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2834 - accuracy: 0.9187 - val_loss: 0.2972 - val_accuracy: 0.9151\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2820 - accuracy: 0.9200 - val_loss: 0.2958 - val_accuracy: 0.9130\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2805 - accuracy: 0.9201 - val_loss: 0.2943 - val_accuracy: 0.9136\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.2790 - accuracy: 0.9200 - val_loss: 0.2933 - val_accuracy: 0.9147\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.2777 - accuracy: 0.9209 - val_loss: 0.2923 - val_accuracy: 0.9151\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2763 - accuracy: 0.9210 - val_loss: 0.2906 - val_accuracy: 0.9156\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.2749 - accuracy: 0.9212 - val_loss: 0.2893 - val_accuracy: 0.9164\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2734 - accuracy: 0.9220 - val_loss: 0.2883 - val_accuracy: 0.9166\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2722 - accuracy: 0.9227 - val_loss: 0.2874 - val_accuracy: 0.9159\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2707 - accuracy: 0.9228 - val_loss: 0.2856 - val_accuracy: 0.9184\n",
      "20000/20000 [==============================] - 1s 63us/sample - loss: 0.2772 - accuracy: 0.9186\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 2.3265 - accuracy: 0.1081 - val_loss: 2.3092 - val_accuracy: 0.1182\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2984 - accuracy: 0.1308 - val_loss: 2.2848 - val_accuracy: 0.1441\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2764 - accuracy: 0.1536 - val_loss: 2.2636 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.2564 - accuracy: 0.1763 - val_loss: 2.2429 - val_accuracy: 0.1894\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.2365 - accuracy: 0.2019 - val_loss: 2.2217 - val_accuracy: 0.2165\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2155 - accuracy: 0.2281 - val_loss: 2.1990 - val_accuracy: 0.2499\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.1927 - accuracy: 0.2552 - val_loss: 2.1742 - val_accuracy: 0.2771\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 2.1674 - accuracy: 0.2857 - val_loss: 2.1463 - val_accuracy: 0.3120\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.1389 - accuracy: 0.3186 - val_loss: 2.1148 - val_accuracy: 0.3461\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.1068 - accuracy: 0.3544 - val_loss: 2.0793 - val_accuracy: 0.3834\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.0706 - accuracy: 0.3924 - val_loss: 2.0394 - val_accuracy: 0.4218\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.0298 - accuracy: 0.4291 - val_loss: 1.9948 - val_accuracy: 0.4574\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 1.9842 - accuracy: 0.4638 - val_loss: 1.9450 - val_accuracy: 0.4926\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 1.9337 - accuracy: 0.4983 - val_loss: 1.8904 - val_accuracy: 0.5314\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.8787 - accuracy: 0.5282 - val_loss: 1.8312 - val_accuracy: 0.5644\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.8196 - accuracy: 0.5601 - val_loss: 1.7683 - val_accuracy: 0.5930\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.7571 - accuracy: 0.5838 - val_loss: 1.7023 - val_accuracy: 0.6168\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.6920 - accuracy: 0.6067 - val_loss: 1.6341 - val_accuracy: 0.6365\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.6250 - accuracy: 0.6247 - val_loss: 1.5644 - val_accuracy: 0.6497\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.5572 - accuracy: 0.6410 - val_loss: 1.4945 - val_accuracy: 0.6641\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.4896 - accuracy: 0.6540 - val_loss: 1.4254 - val_accuracy: 0.6799\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.4231 - accuracy: 0.6658 - val_loss: 1.3579 - val_accuracy: 0.6898\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.3587 - accuracy: 0.6766 - val_loss: 1.2931 - val_accuracy: 0.6998\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.2972 - accuracy: 0.6873 - val_loss: 1.2318 - val_accuracy: 0.7111\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.2392 - accuracy: 0.6978 - val_loss: 1.1740 - val_accuracy: 0.7193\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.1850 - accuracy: 0.7055 - val_loss: 1.1201 - val_accuracy: 0.7297\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.1348 - accuracy: 0.7162 - val_loss: 1.0703 - val_accuracy: 0.7372\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.0884 - accuracy: 0.7244 - val_loss: 1.0245 - val_accuracy: 0.7442\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.0458 - accuracy: 0.7325 - val_loss: 0.9824 - val_accuracy: 0.7531\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.0068 - accuracy: 0.7397 - val_loss: 0.9441 - val_accuracy: 0.7626\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.9711 - accuracy: 0.7478 - val_loss: 0.9090 - val_accuracy: 0.7691\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.9385 - accuracy: 0.7542 - val_loss: 0.8770 - val_accuracy: 0.7759\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.9086 - accuracy: 0.7593 - val_loss: 0.8477 - val_accuracy: 0.7826\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8811 - accuracy: 0.7644 - val_loss: 0.8206 - val_accuracy: 0.7880\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8558 - accuracy: 0.7704 - val_loss: 0.7956 - val_accuracy: 0.7926\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.8326 - accuracy: 0.7754 - val_loss: 0.7730 - val_accuracy: 0.7976\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8111 - accuracy: 0.7802 - val_loss: 0.7518 - val_accuracy: 0.8025\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7912 - accuracy: 0.7847 - val_loss: 0.7323 - val_accuracy: 0.8070\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7726 - accuracy: 0.7884 - val_loss: 0.7140 - val_accuracy: 0.8096\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7553 - accuracy: 0.7928 - val_loss: 0.6970 - val_accuracy: 0.8127\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7392 - accuracy: 0.7963 - val_loss: 0.6813 - val_accuracy: 0.8180\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7240 - accuracy: 0.8003 - val_loss: 0.6667 - val_accuracy: 0.8224\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7098 - accuracy: 0.8049 - val_loss: 0.6525 - val_accuracy: 0.8256\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6965 - accuracy: 0.8075 - val_loss: 0.6394 - val_accuracy: 0.8299\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6838 - accuracy: 0.8112 - val_loss: 0.6271 - val_accuracy: 0.8331\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6718 - accuracy: 0.8138 - val_loss: 0.6151 - val_accuracy: 0.8366\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6605 - accuracy: 0.8163 - val_loss: 0.6046 - val_accuracy: 0.8381\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6497 - accuracy: 0.8194 - val_loss: 0.5942 - val_accuracy: 0.8409\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6394 - accuracy: 0.8223 - val_loss: 0.5837 - val_accuracy: 0.8426\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6297 - accuracy: 0.8252 - val_loss: 0.5745 - val_accuracy: 0.8451\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6203 - accuracy: 0.8270 - val_loss: 0.5654 - val_accuracy: 0.8489\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6114 - accuracy: 0.8298 - val_loss: 0.5568 - val_accuracy: 0.8512\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6028 - accuracy: 0.8321 - val_loss: 0.5485 - val_accuracy: 0.8536\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5946 - accuracy: 0.8343 - val_loss: 0.5408 - val_accuracy: 0.8553\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5868 - accuracy: 0.8366 - val_loss: 0.5329 - val_accuracy: 0.8575\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5792 - accuracy: 0.8386 - val_loss: 0.5262 - val_accuracy: 0.8581\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5719 - accuracy: 0.8409 - val_loss: 0.5189 - val_accuracy: 0.8602\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5649 - accuracy: 0.8426 - val_loss: 0.5123 - val_accuracy: 0.8620\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5582 - accuracy: 0.8450 - val_loss: 0.5056 - val_accuracy: 0.8635\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5516 - accuracy: 0.8467 - val_loss: 0.4994 - val_accuracy: 0.8650\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.5454 - accuracy: 0.8484 - val_loss: 0.4933 - val_accuracy: 0.8662\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5393 - accuracy: 0.8499 - val_loss: 0.4875 - val_accuracy: 0.8684\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5334 - accuracy: 0.8520 - val_loss: 0.4815 - val_accuracy: 0.8700\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5277 - accuracy: 0.8537 - val_loss: 0.4761 - val_accuracy: 0.8716\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5223 - accuracy: 0.8555 - val_loss: 0.4709 - val_accuracy: 0.8724\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.5170 - accuracy: 0.8568 - val_loss: 0.4661 - val_accuracy: 0.8742\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5118 - accuracy: 0.8579 - val_loss: 0.4608 - val_accuracy: 0.8749\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.5068 - accuracy: 0.8597 - val_loss: 0.4564 - val_accuracy: 0.8761\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5020 - accuracy: 0.8609 - val_loss: 0.4517 - val_accuracy: 0.8770\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4973 - accuracy: 0.8622 - val_loss: 0.4472 - val_accuracy: 0.8779\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4927 - accuracy: 0.8637 - val_loss: 0.4429 - val_accuracy: 0.8786\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4883 - accuracy: 0.8647 - val_loss: 0.4389 - val_accuracy: 0.8800\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4840 - accuracy: 0.8662 - val_loss: 0.4348 - val_accuracy: 0.8823\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4798 - accuracy: 0.8674 - val_loss: 0.4307 - val_accuracy: 0.8820\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4758 - accuracy: 0.8681 - val_loss: 0.4271 - val_accuracy: 0.8831\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4719 - accuracy: 0.8690 - val_loss: 0.4233 - val_accuracy: 0.8851\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4681 - accuracy: 0.8704 - val_loss: 0.4196 - val_accuracy: 0.8869\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4643 - accuracy: 0.8719 - val_loss: 0.4160 - val_accuracy: 0.8876\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4607 - accuracy: 0.8725 - val_loss: 0.4127 - val_accuracy: 0.8881\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4571 - accuracy: 0.8734 - val_loss: 0.4098 - val_accuracy: 0.8894\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4538 - accuracy: 0.8747 - val_loss: 0.4061 - val_accuracy: 0.8901\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4504 - accuracy: 0.8754 - val_loss: 0.4036 - val_accuracy: 0.8899\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4472 - accuracy: 0.8759 - val_loss: 0.4000 - val_accuracy: 0.8915\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4441 - accuracy: 0.8767 - val_loss: 0.3972 - val_accuracy: 0.8926\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4410 - accuracy: 0.8776 - val_loss: 0.3942 - val_accuracy: 0.8925\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4379 - accuracy: 0.8782 - val_loss: 0.3916 - val_accuracy: 0.8934\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4351 - accuracy: 0.8790 - val_loss: 0.3890 - val_accuracy: 0.8942\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4322 - accuracy: 0.8799 - val_loss: 0.3865 - val_accuracy: 0.8944\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4295 - accuracy: 0.8804 - val_loss: 0.3835 - val_accuracy: 0.8951\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4268 - accuracy: 0.8813 - val_loss: 0.3810 - val_accuracy: 0.8954\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4241 - accuracy: 0.8819 - val_loss: 0.3785 - val_accuracy: 0.8956\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4216 - accuracy: 0.8827 - val_loss: 0.3761 - val_accuracy: 0.8959\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4191 - accuracy: 0.8832 - val_loss: 0.3741 - val_accuracy: 0.8963\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4167 - accuracy: 0.8836 - val_loss: 0.3718 - val_accuracy: 0.8970\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4144 - accuracy: 0.8844 - val_loss: 0.3696 - val_accuracy: 0.8975\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4120 - accuracy: 0.8852 - val_loss: 0.3675 - val_accuracy: 0.8976\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4097 - accuracy: 0.8856 - val_loss: 0.3659 - val_accuracy: 0.8978\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4075 - accuracy: 0.8857 - val_loss: 0.3634 - val_accuracy: 0.8982\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4053 - accuracy: 0.8864 - val_loss: 0.3618 - val_accuracy: 0.8994\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4033 - accuracy: 0.8872 - val_loss: 0.3594 - val_accuracy: 0.9000\n",
      "20000/20000 [==============================] - 1s 58us/sample - loss: 0.4049 - accuracy: 0.8861\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 48us/sample - loss: 2.2948 - accuracy: 0.1794 - val_loss: 2.2887 - val_accuracy: 0.1755\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.2818 - accuracy: 0.1967 - val_loss: 2.2762 - val_accuracy: 0.1909\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 2.2703 - accuracy: 0.2098 - val_loss: 2.2647 - val_accuracy: 0.2062\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.2593 - accuracy: 0.2209 - val_loss: 2.2533 - val_accuracy: 0.2176\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2482 - accuracy: 0.2303 - val_loss: 2.2415 - val_accuracy: 0.2270\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2364 - accuracy: 0.2382 - val_loss: 2.2290 - val_accuracy: 0.2351\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2236 - accuracy: 0.2468 - val_loss: 2.2154 - val_accuracy: 0.2438\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2099 - accuracy: 0.2548 - val_loss: 2.2006 - val_accuracy: 0.2549\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.1949 - accuracy: 0.2637 - val_loss: 2.1844 - val_accuracy: 0.2666\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.1784 - accuracy: 0.2747 - val_loss: 2.1665 - val_accuracy: 0.2786\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.1602 - accuracy: 0.2872 - val_loss: 2.1468 - val_accuracy: 0.2928\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.1401 - accuracy: 0.3005 - val_loss: 2.1249 - val_accuracy: 0.3058\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.1176 - accuracy: 0.3140 - val_loss: 2.1005 - val_accuracy: 0.3229\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.0926 - accuracy: 0.3297 - val_loss: 2.0734 - val_accuracy: 0.3376\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 2.0648 - accuracy: 0.3457 - val_loss: 2.0432 - val_accuracy: 0.3541\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.0339 - accuracy: 0.3633 - val_loss: 2.0097 - val_accuracy: 0.3710\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.9997 - accuracy: 0.3820 - val_loss: 1.9727 - val_accuracy: 0.3970\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.9622 - accuracy: 0.4020 - val_loss: 1.9325 - val_accuracy: 0.4218\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.9218 - accuracy: 0.4233 - val_loss: 1.8892 - val_accuracy: 0.4470\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.8785 - accuracy: 0.4465 - val_loss: 1.8430 - val_accuracy: 0.4745\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.8327 - accuracy: 0.4705 - val_loss: 1.7943 - val_accuracy: 0.5026\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.7847 - accuracy: 0.4963 - val_loss: 1.7433 - val_accuracy: 0.5257\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.7346 - accuracy: 0.5173 - val_loss: 1.6904 - val_accuracy: 0.5421\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.6829 - accuracy: 0.5365 - val_loss: 1.6359 - val_accuracy: 0.5594\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.6296 - accuracy: 0.5546 - val_loss: 1.5801 - val_accuracy: 0.5741\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.5750 - accuracy: 0.5702 - val_loss: 1.5232 - val_accuracy: 0.5904\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.5196 - accuracy: 0.5853 - val_loss: 1.4659 - val_accuracy: 0.6081\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.4642 - accuracy: 0.6021 - val_loss: 1.4089 - val_accuracy: 0.6233\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.4096 - accuracy: 0.6183 - val_loss: 1.3532 - val_accuracy: 0.6440\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.3563 - accuracy: 0.6380 - val_loss: 1.2990 - val_accuracy: 0.6690\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.3046 - accuracy: 0.6578 - val_loss: 1.2466 - val_accuracy: 0.6913\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.2543 - accuracy: 0.6797 - val_loss: 1.1955 - val_accuracy: 0.7113\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.2049 - accuracy: 0.6958 - val_loss: 1.1452 - val_accuracy: 0.7281\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 1.1563 - accuracy: 0.7105 - val_loss: 1.0963 - val_accuracy: 0.7375\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.1100 - accuracy: 0.7214 - val_loss: 1.0500 - val_accuracy: 0.7487\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.0665 - accuracy: 0.7333 - val_loss: 1.0065 - val_accuracy: 0.7590\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.0259 - accuracy: 0.7437 - val_loss: 0.9658 - val_accuracy: 0.7717\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.9878 - accuracy: 0.7536 - val_loss: 0.9277 - val_accuracy: 0.7822\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.9521 - accuracy: 0.7630 - val_loss: 0.8919 - val_accuracy: 0.7944\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.9186 - accuracy: 0.7728 - val_loss: 0.8581 - val_accuracy: 0.8031\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.8871 - accuracy: 0.7814 - val_loss: 0.8268 - val_accuracy: 0.8100\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.8575 - accuracy: 0.7879 - val_loss: 0.7973 - val_accuracy: 0.8166\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8296 - accuracy: 0.7947 - val_loss: 0.7697 - val_accuracy: 0.8220\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.8035 - accuracy: 0.7998 - val_loss: 0.7437 - val_accuracy: 0.8284\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.7789 - accuracy: 0.8065 - val_loss: 0.7193 - val_accuracy: 0.8329\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.7559 - accuracy: 0.8110 - val_loss: 0.6965 - val_accuracy: 0.8381\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7342 - accuracy: 0.8158 - val_loss: 0.6754 - val_accuracy: 0.8414\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7140 - accuracy: 0.8202 - val_loss: 0.6555 - val_accuracy: 0.8441\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6950 - accuracy: 0.8239 - val_loss: 0.6368 - val_accuracy: 0.8460\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6772 - accuracy: 0.8275 - val_loss: 0.6196 - val_accuracy: 0.8487\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6606 - accuracy: 0.8314 - val_loss: 0.6035 - val_accuracy: 0.8514\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6450 - accuracy: 0.8348 - val_loss: 0.5883 - val_accuracy: 0.8549\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6304 - accuracy: 0.8375 - val_loss: 0.5741 - val_accuracy: 0.8585\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6167 - accuracy: 0.8400 - val_loss: 0.5610 - val_accuracy: 0.8605\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6039 - accuracy: 0.8424 - val_loss: 0.5487 - val_accuracy: 0.8635\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5919 - accuracy: 0.8443 - val_loss: 0.5372 - val_accuracy: 0.8641\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5806 - accuracy: 0.8466 - val_loss: 0.5264 - val_accuracy: 0.8670\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5699 - accuracy: 0.8494 - val_loss: 0.5161 - val_accuracy: 0.8680\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5600 - accuracy: 0.8507 - val_loss: 0.5066 - val_accuracy: 0.8701\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5506 - accuracy: 0.8528 - val_loss: 0.4977 - val_accuracy: 0.8712\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5417 - accuracy: 0.8544 - val_loss: 0.4893 - val_accuracy: 0.8731\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5334 - accuracy: 0.8560 - val_loss: 0.4813 - val_accuracy: 0.8749\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5255 - accuracy: 0.8571 - val_loss: 0.4738 - val_accuracy: 0.8756\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5180 - accuracy: 0.8589 - val_loss: 0.4669 - val_accuracy: 0.8777\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5110 - accuracy: 0.8603 - val_loss: 0.4603 - val_accuracy: 0.8784\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5043 - accuracy: 0.8612 - val_loss: 0.4541 - val_accuracy: 0.8790\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4979 - accuracy: 0.8627 - val_loss: 0.4482 - val_accuracy: 0.8815\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4920 - accuracy: 0.8640 - val_loss: 0.4426 - val_accuracy: 0.8819\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4863 - accuracy: 0.8652 - val_loss: 0.4374 - val_accuracy: 0.8839\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4808 - accuracy: 0.8659 - val_loss: 0.4323 - val_accuracy: 0.8850\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4756 - accuracy: 0.8677 - val_loss: 0.4275 - val_accuracy: 0.8851\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4708 - accuracy: 0.8681 - val_loss: 0.4230 - val_accuracy: 0.8860\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4660 - accuracy: 0.8692 - val_loss: 0.4188 - val_accuracy: 0.8866\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4616 - accuracy: 0.8702 - val_loss: 0.4146 - val_accuracy: 0.8875\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4573 - accuracy: 0.8712 - val_loss: 0.4108 - val_accuracy: 0.8876\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4532 - accuracy: 0.8715 - val_loss: 0.4071 - val_accuracy: 0.8888\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4494 - accuracy: 0.8723 - val_loss: 0.4035 - val_accuracy: 0.8892\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4456 - accuracy: 0.8732 - val_loss: 0.4001 - val_accuracy: 0.8891\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4420 - accuracy: 0.8738 - val_loss: 0.3969 - val_accuracy: 0.8901\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4385 - accuracy: 0.8741 - val_loss: 0.3937 - val_accuracy: 0.8906\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4352 - accuracy: 0.8750 - val_loss: 0.3909 - val_accuracy: 0.8910\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4320 - accuracy: 0.8759 - val_loss: 0.3880 - val_accuracy: 0.8914\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4289 - accuracy: 0.8766 - val_loss: 0.3852 - val_accuracy: 0.8924\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4259 - accuracy: 0.8771 - val_loss: 0.3826 - val_accuracy: 0.8929\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4231 - accuracy: 0.8781 - val_loss: 0.3800 - val_accuracy: 0.8941\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4203 - accuracy: 0.8788 - val_loss: 0.3775 - val_accuracy: 0.8954\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4177 - accuracy: 0.8799 - val_loss: 0.3752 - val_accuracy: 0.8955\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4151 - accuracy: 0.8802 - val_loss: 0.3731 - val_accuracy: 0.8950\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4126 - accuracy: 0.8808 - val_loss: 0.3710 - val_accuracy: 0.8956\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4102 - accuracy: 0.8818 - val_loss: 0.3688 - val_accuracy: 0.8959\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4079 - accuracy: 0.8821 - val_loss: 0.3669 - val_accuracy: 0.8964\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4056 - accuracy: 0.8824 - val_loss: 0.3648 - val_accuracy: 0.8965\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4035 - accuracy: 0.8832 - val_loss: 0.3628 - val_accuracy: 0.8985\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4013 - accuracy: 0.8838 - val_loss: 0.3611 - val_accuracy: 0.8982\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3993 - accuracy: 0.8839 - val_loss: 0.3592 - val_accuracy: 0.8986\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3972 - accuracy: 0.8847 - val_loss: 0.3575 - val_accuracy: 0.8994\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3953 - accuracy: 0.8852 - val_loss: 0.3558 - val_accuracy: 0.8991\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3934 - accuracy: 0.8860 - val_loss: 0.3544 - val_accuracy: 0.8990\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3916 - accuracy: 0.8865 - val_loss: 0.3526 - val_accuracy: 0.8995\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3898 - accuracy: 0.8871 - val_loss: 0.3513 - val_accuracy: 0.8996\n",
      "20000/20000 [==============================] - 1s 59us/sample - loss: 0.4026 - accuracy: 0.8820\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 46us/sample - loss: 2.3286 - accuracy: 0.0755 - val_loss: 2.3134 - val_accuracy: 0.0833\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2951 - accuracy: 0.0808 - val_loss: 2.2868 - val_accuracy: 0.0957\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2728 - accuracy: 0.1000 - val_loss: 2.2667 - val_accuracy: 0.1213\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2541 - accuracy: 0.1287 - val_loss: 2.2482 - val_accuracy: 0.1510\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 2.2359 - accuracy: 0.1593 - val_loss: 2.2294 - val_accuracy: 0.1830\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2165 - accuracy: 0.1905 - val_loss: 2.2091 - val_accuracy: 0.2116\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.1955 - accuracy: 0.2174 - val_loss: 2.1870 - val_accuracy: 0.2383\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.1725 - accuracy: 0.2420 - val_loss: 2.1629 - val_accuracy: 0.2595\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.1473 - accuracy: 0.2627 - val_loss: 2.1368 - val_accuracy: 0.2755\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 2.1201 - accuracy: 0.2794 - val_loss: 2.1086 - val_accuracy: 0.2900\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.0909 - accuracy: 0.2966 - val_loss: 2.0784 - val_accuracy: 0.3039\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.0599 - accuracy: 0.3133 - val_loss: 2.0465 - val_accuracy: 0.3206\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.0271 - accuracy: 0.3317 - val_loss: 2.0127 - val_accuracy: 0.3356\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.9924 - accuracy: 0.3489 - val_loss: 1.9769 - val_accuracy: 0.3515\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.9557 - accuracy: 0.3689 - val_loss: 1.9391 - val_accuracy: 0.3697\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.9167 - accuracy: 0.3857 - val_loss: 1.8990 - val_accuracy: 0.3889\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.8752 - accuracy: 0.4041 - val_loss: 1.8564 - val_accuracy: 0.4066\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.8314 - accuracy: 0.4216 - val_loss: 1.8114 - val_accuracy: 0.4271\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.7854 - accuracy: 0.4403 - val_loss: 1.7644 - val_accuracy: 0.4462\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.7376 - accuracy: 0.4603 - val_loss: 1.7159 - val_accuracy: 0.4685\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.6886 - accuracy: 0.4836 - val_loss: 1.6663 - val_accuracy: 0.4939\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.6386 - accuracy: 0.5075 - val_loss: 1.6158 - val_accuracy: 0.5169\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.5880 - accuracy: 0.5342 - val_loss: 1.5651 - val_accuracy: 0.5419\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.5369 - accuracy: 0.5608 - val_loss: 1.5140 - val_accuracy: 0.5627\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.4855 - accuracy: 0.5844 - val_loss: 1.4627 - val_accuracy: 0.5863\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 1.4340 - accuracy: 0.6059 - val_loss: 1.4113 - val_accuracy: 0.6085\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.3827 - accuracy: 0.6274 - val_loss: 1.3602 - val_accuracy: 0.6306\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.3319 - accuracy: 0.6441 - val_loss: 1.3101 - val_accuracy: 0.6457\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.2823 - accuracy: 0.6618 - val_loss: 1.2614 - val_accuracy: 0.6625\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.2344 - accuracy: 0.6768 - val_loss: 1.2147 - val_accuracy: 0.6786\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.1886 - accuracy: 0.6897 - val_loss: 1.1705 - val_accuracy: 0.6901\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.1453 - accuracy: 0.7013 - val_loss: 1.1287 - val_accuracy: 0.7026\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.1045 - accuracy: 0.7118 - val_loss: 1.0893 - val_accuracy: 0.7111\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.0663 - accuracy: 0.7204 - val_loss: 1.0527 - val_accuracy: 0.7225\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.0305 - accuracy: 0.7291 - val_loss: 1.0183 - val_accuracy: 0.7311\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.9972 - accuracy: 0.7383 - val_loss: 0.9866 - val_accuracy: 0.7376\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.9661 - accuracy: 0.7443 - val_loss: 0.9567 - val_accuracy: 0.7436\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.9370 - accuracy: 0.7502 - val_loss: 0.9289 - val_accuracy: 0.7513\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.9099 - accuracy: 0.7558 - val_loss: 0.9027 - val_accuracy: 0.7552\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8847 - accuracy: 0.7621 - val_loss: 0.8784 - val_accuracy: 0.7591\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8610 - accuracy: 0.7663 - val_loss: 0.8558 - val_accuracy: 0.7654\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.8388 - accuracy: 0.7721 - val_loss: 0.8347 - val_accuracy: 0.7713\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.8181 - accuracy: 0.7769 - val_loss: 0.8144 - val_accuracy: 0.7766\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7985 - accuracy: 0.7826 - val_loss: 0.7953 - val_accuracy: 0.7796\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7801 - accuracy: 0.7868 - val_loss: 0.7775 - val_accuracy: 0.7837\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7627 - accuracy: 0.7911 - val_loss: 0.7606 - val_accuracy: 0.7906\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7461 - accuracy: 0.7959 - val_loss: 0.7448 - val_accuracy: 0.7956\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7305 - accuracy: 0.8005 - val_loss: 0.7293 - val_accuracy: 0.7990\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.7156 - accuracy: 0.8043 - val_loss: 0.7150 - val_accuracy: 0.8026\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7015 - accuracy: 0.8072 - val_loss: 0.7011 - val_accuracy: 0.8055\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6881 - accuracy: 0.8113 - val_loss: 0.6880 - val_accuracy: 0.8070\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6755 - accuracy: 0.8140 - val_loss: 0.6758 - val_accuracy: 0.8102\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.6635 - accuracy: 0.8172 - val_loss: 0.6641 - val_accuracy: 0.8139\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6522 - accuracy: 0.8201 - val_loss: 0.6529 - val_accuracy: 0.8175\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6415 - accuracy: 0.8228 - val_loss: 0.6423 - val_accuracy: 0.8192\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6312 - accuracy: 0.8262 - val_loss: 0.6324 - val_accuracy: 0.8211\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6214 - accuracy: 0.8282 - val_loss: 0.6228 - val_accuracy: 0.8244\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6121 - accuracy: 0.8309 - val_loss: 0.6135 - val_accuracy: 0.8281\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6030 - accuracy: 0.8328 - val_loss: 0.6050 - val_accuracy: 0.8301\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5945 - accuracy: 0.8351 - val_loss: 0.5963 - val_accuracy: 0.8330\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5862 - accuracy: 0.8369 - val_loss: 0.5881 - val_accuracy: 0.8354\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5783 - accuracy: 0.8395 - val_loss: 0.5804 - val_accuracy: 0.8371\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5707 - accuracy: 0.8420 - val_loss: 0.5731 - val_accuracy: 0.8381\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5634 - accuracy: 0.8433 - val_loss: 0.5658 - val_accuracy: 0.8414\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5565 - accuracy: 0.8451 - val_loss: 0.5591 - val_accuracy: 0.8426\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.5498 - accuracy: 0.8478 - val_loss: 0.5524 - val_accuracy: 0.8447\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5434 - accuracy: 0.8496 - val_loss: 0.5462 - val_accuracy: 0.8469\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.5372 - accuracy: 0.8513 - val_loss: 0.5400 - val_accuracy: 0.8482\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.5313 - accuracy: 0.8529 - val_loss: 0.5345 - val_accuracy: 0.8495\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.5255 - accuracy: 0.8545 - val_loss: 0.5289 - val_accuracy: 0.8515\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.5200 - accuracy: 0.8562 - val_loss: 0.5232 - val_accuracy: 0.8547\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.5146 - accuracy: 0.8575 - val_loss: 0.5182 - val_accuracy: 0.8545\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5095 - accuracy: 0.8587 - val_loss: 0.5132 - val_accuracy: 0.8564\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5045 - accuracy: 0.8602 - val_loss: 0.5083 - val_accuracy: 0.8587\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4998 - accuracy: 0.8615 - val_loss: 0.5035 - val_accuracy: 0.8590\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4951 - accuracy: 0.8625 - val_loss: 0.4990 - val_accuracy: 0.8602\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4905 - accuracy: 0.8639 - val_loss: 0.4945 - val_accuracy: 0.8629\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4862 - accuracy: 0.8648 - val_loss: 0.4903 - val_accuracy: 0.8631\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4820 - accuracy: 0.8652 - val_loss: 0.4860 - val_accuracy: 0.8649\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4778 - accuracy: 0.8673 - val_loss: 0.4820 - val_accuracy: 0.8650\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4738 - accuracy: 0.8680 - val_loss: 0.4780 - val_accuracy: 0.8662\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4699 - accuracy: 0.8698 - val_loss: 0.4742 - val_accuracy: 0.8666\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4662 - accuracy: 0.8705 - val_loss: 0.4705 - val_accuracy: 0.8686\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4624 - accuracy: 0.8712 - val_loss: 0.4668 - val_accuracy: 0.8692\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4589 - accuracy: 0.8725 - val_loss: 0.4633 - val_accuracy: 0.8705\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4554 - accuracy: 0.8736 - val_loss: 0.4599 - val_accuracy: 0.8714\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4520 - accuracy: 0.8742 - val_loss: 0.4565 - val_accuracy: 0.8721\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4487 - accuracy: 0.8755 - val_loss: 0.4531 - val_accuracy: 0.8730\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4454 - accuracy: 0.8767 - val_loss: 0.4501 - val_accuracy: 0.8741\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4422 - accuracy: 0.8772 - val_loss: 0.4473 - val_accuracy: 0.8734\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4391 - accuracy: 0.8779 - val_loss: 0.4444 - val_accuracy: 0.8752\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4362 - accuracy: 0.8783 - val_loss: 0.4412 - val_accuracy: 0.8759\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4332 - accuracy: 0.8795 - val_loss: 0.4384 - val_accuracy: 0.8761\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4304 - accuracy: 0.8803 - val_loss: 0.4353 - val_accuracy: 0.8779\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4275 - accuracy: 0.8816 - val_loss: 0.4328 - val_accuracy: 0.8776\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4248 - accuracy: 0.8815 - val_loss: 0.4297 - val_accuracy: 0.8791\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4221 - accuracy: 0.8824 - val_loss: 0.4273 - val_accuracy: 0.8801\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4195 - accuracy: 0.8832 - val_loss: 0.4246 - val_accuracy: 0.8810\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4169 - accuracy: 0.8840 - val_loss: 0.4222 - val_accuracy: 0.8808\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4144 - accuracy: 0.8841 - val_loss: 0.4197 - val_accuracy: 0.8821\n",
      "20000/20000 [==============================] - 1s 66us/sample - loss: 0.4061 - accuracy: 0.8853\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 2.2386 - accuracy: 0.1793 - val_loss: 2.1563 - val_accuracy: 0.3129\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.0733 - accuracy: 0.4094 - val_loss: 1.9759 - val_accuracy: 0.5034\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.8812 - accuracy: 0.5426 - val_loss: 1.7642 - val_accuracy: 0.6008\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.6653 - accuracy: 0.6230 - val_loss: 1.5358 - val_accuracy: 0.6844\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 1.4446 - accuracy: 0.6867 - val_loss: 1.3128 - val_accuracy: 0.7424\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.2411 - accuracy: 0.7338 - val_loss: 1.1181 - val_accuracy: 0.7804\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.0721 - accuracy: 0.7690 - val_loss: 0.9623 - val_accuracy: 0.8084\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.9402 - accuracy: 0.7900 - val_loss: 0.8429 - val_accuracy: 0.8255\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.8394 - accuracy: 0.8078 - val_loss: 0.7519 - val_accuracy: 0.8411\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.7621 - accuracy: 0.8214 - val_loss: 0.6818 - val_accuracy: 0.8511\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.7017 - accuracy: 0.8321 - val_loss: 0.6270 - val_accuracy: 0.8594\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6536 - accuracy: 0.8414 - val_loss: 0.5831 - val_accuracy: 0.8652\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.6143 - accuracy: 0.8479 - val_loss: 0.5471 - val_accuracy: 0.8712\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.5818 - accuracy: 0.8544 - val_loss: 0.5175 - val_accuracy: 0.8759\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.5546 - accuracy: 0.8595 - val_loss: 0.4929 - val_accuracy: 0.8798\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.5315 - accuracy: 0.8640 - val_loss: 0.4714 - val_accuracy: 0.8834\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.5117 - accuracy: 0.8683 - val_loss: 0.4535 - val_accuracy: 0.8859\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4945 - accuracy: 0.8712 - val_loss: 0.4373 - val_accuracy: 0.8890\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4792 - accuracy: 0.8746 - val_loss: 0.4236 - val_accuracy: 0.8913\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4659 - accuracy: 0.8776 - val_loss: 0.4118 - val_accuracy: 0.8934\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4539 - accuracy: 0.8795 - val_loss: 0.4004 - val_accuracy: 0.8953\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4431 - accuracy: 0.8811 - val_loss: 0.3909 - val_accuracy: 0.8959\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4334 - accuracy: 0.8831 - val_loss: 0.3824 - val_accuracy: 0.8984\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4247 - accuracy: 0.8852 - val_loss: 0.3744 - val_accuracy: 0.8997\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4166 - accuracy: 0.8867 - val_loss: 0.3670 - val_accuracy: 0.9006\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4093 - accuracy: 0.8884 - val_loss: 0.3607 - val_accuracy: 0.9022\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4025 - accuracy: 0.8900 - val_loss: 0.3545 - val_accuracy: 0.9038\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3962 - accuracy: 0.8911 - val_loss: 0.3492 - val_accuracy: 0.9051\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3904 - accuracy: 0.8928 - val_loss: 0.3441 - val_accuracy: 0.9056\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3849 - accuracy: 0.8938 - val_loss: 0.3393 - val_accuracy: 0.9068\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3798 - accuracy: 0.8943 - val_loss: 0.3344 - val_accuracy: 0.9074\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3750 - accuracy: 0.8959 - val_loss: 0.3305 - val_accuracy: 0.9099\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3705 - accuracy: 0.8973 - val_loss: 0.3266 - val_accuracy: 0.9097\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3661 - accuracy: 0.8977 - val_loss: 0.3227 - val_accuracy: 0.9109\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3621 - accuracy: 0.8988 - val_loss: 0.3191 - val_accuracy: 0.9111\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3582 - accuracy: 0.8991 - val_loss: 0.3158 - val_accuracy: 0.9124\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3545 - accuracy: 0.9006 - val_loss: 0.3127 - val_accuracy: 0.9126\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3510 - accuracy: 0.9013 - val_loss: 0.3097 - val_accuracy: 0.9134\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3476 - accuracy: 0.9019 - val_loss: 0.3069 - val_accuracy: 0.9141\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3444 - accuracy: 0.9028 - val_loss: 0.3038 - val_accuracy: 0.9143\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3412 - accuracy: 0.9035 - val_loss: 0.3012 - val_accuracy: 0.9156\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3382 - accuracy: 0.9038 - val_loss: 0.2989 - val_accuracy: 0.9156\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3353 - accuracy: 0.9048 - val_loss: 0.2966 - val_accuracy: 0.9165\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3326 - accuracy: 0.9059 - val_loss: 0.2940 - val_accuracy: 0.9169\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3298 - accuracy: 0.9056 - val_loss: 0.2916 - val_accuracy: 0.9179\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3272 - accuracy: 0.9066 - val_loss: 0.2898 - val_accuracy: 0.9179\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3246 - accuracy: 0.9072 - val_loss: 0.2877 - val_accuracy: 0.9186\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3223 - accuracy: 0.9086 - val_loss: 0.2854 - val_accuracy: 0.9194\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3199 - accuracy: 0.9089 - val_loss: 0.2833 - val_accuracy: 0.9193\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3176 - accuracy: 0.9099 - val_loss: 0.2816 - val_accuracy: 0.9186\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3153 - accuracy: 0.9104 - val_loss: 0.2799 - val_accuracy: 0.9199\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3131 - accuracy: 0.9104 - val_loss: 0.2777 - val_accuracy: 0.9200\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3110 - accuracy: 0.9113 - val_loss: 0.2760 - val_accuracy: 0.9204\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3088 - accuracy: 0.9115 - val_loss: 0.2743 - val_accuracy: 0.9216\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3068 - accuracy: 0.9120 - val_loss: 0.2729 - val_accuracy: 0.9215\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3049 - accuracy: 0.9130 - val_loss: 0.2710 - val_accuracy: 0.9220\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3029 - accuracy: 0.9131 - val_loss: 0.2695 - val_accuracy: 0.9224\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3011 - accuracy: 0.9139 - val_loss: 0.2677 - val_accuracy: 0.9222\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2991 - accuracy: 0.9143 - val_loss: 0.2665 - val_accuracy: 0.9230\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2974 - accuracy: 0.9145 - val_loss: 0.2648 - val_accuracy: 0.9239\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2956 - accuracy: 0.9153 - val_loss: 0.2634 - val_accuracy: 0.9235\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2938 - accuracy: 0.9158 - val_loss: 0.2620 - val_accuracy: 0.9244\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2921 - accuracy: 0.9162 - val_loss: 0.2608 - val_accuracy: 0.9246\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2905 - accuracy: 0.9164 - val_loss: 0.2593 - val_accuracy: 0.9250\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2889 - accuracy: 0.9173 - val_loss: 0.2578 - val_accuracy: 0.9251\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2872 - accuracy: 0.9173 - val_loss: 0.2566 - val_accuracy: 0.9258\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2855 - accuracy: 0.9179 - val_loss: 0.2552 - val_accuracy: 0.9260\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2841 - accuracy: 0.9191 - val_loss: 0.2538 - val_accuracy: 0.9270\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2824 - accuracy: 0.9192 - val_loss: 0.2530 - val_accuracy: 0.9280\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2809 - accuracy: 0.9194 - val_loss: 0.2516 - val_accuracy: 0.9274\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2795 - accuracy: 0.9205 - val_loss: 0.2504 - val_accuracy: 0.9277\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2780 - accuracy: 0.9208 - val_loss: 0.2493 - val_accuracy: 0.9291\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2766 - accuracy: 0.9218 - val_loss: 0.2479 - val_accuracy: 0.9291\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2751 - accuracy: 0.9217 - val_loss: 0.2470 - val_accuracy: 0.9289\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2737 - accuracy: 0.9222 - val_loss: 0.2457 - val_accuracy: 0.9298\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2723 - accuracy: 0.9227 - val_loss: 0.2448 - val_accuracy: 0.9300\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2709 - accuracy: 0.9233 - val_loss: 0.2437 - val_accuracy: 0.9299\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2696 - accuracy: 0.9236 - val_loss: 0.2423 - val_accuracy: 0.9306\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2682 - accuracy: 0.9239 - val_loss: 0.2415 - val_accuracy: 0.9309\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2669 - accuracy: 0.9246 - val_loss: 0.2406 - val_accuracy: 0.9309\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2656 - accuracy: 0.9247 - val_loss: 0.2396 - val_accuracy: 0.9316\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 27us/sample - loss: 0.2643 - accuracy: 0.9256 - val_loss: 0.2385 - val_accuracy: 0.9311\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2629 - accuracy: 0.9253 - val_loss: 0.2377 - val_accuracy: 0.9323\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2617 - accuracy: 0.9256 - val_loss: 0.2364 - val_accuracy: 0.9321\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2605 - accuracy: 0.9263 - val_loss: 0.2352 - val_accuracy: 0.9325\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2592 - accuracy: 0.9264 - val_loss: 0.2343 - val_accuracy: 0.9324\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2580 - accuracy: 0.9270 - val_loss: 0.2336 - val_accuracy: 0.9339\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2569 - accuracy: 0.9272 - val_loss: 0.2326 - val_accuracy: 0.9344\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2556 - accuracy: 0.9273 - val_loss: 0.2316 - val_accuracy: 0.9348\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2544 - accuracy: 0.9276 - val_loss: 0.2306 - val_accuracy: 0.9346\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2533 - accuracy: 0.9283 - val_loss: 0.2298 - val_accuracy: 0.9341\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.2522 - accuracy: 0.9285 - val_loss: 0.2288 - val_accuracy: 0.9346\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2510 - accuracy: 0.9290 - val_loss: 0.2280 - val_accuracy: 0.9350\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2498 - accuracy: 0.9293 - val_loss: 0.2273 - val_accuracy: 0.9356\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2488 - accuracy: 0.9294 - val_loss: 0.2263 - val_accuracy: 0.9361\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2477 - accuracy: 0.9297 - val_loss: 0.2255 - val_accuracy: 0.9360\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2465 - accuracy: 0.9299 - val_loss: 0.2253 - val_accuracy: 0.9361\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2455 - accuracy: 0.9304 - val_loss: 0.2239 - val_accuracy: 0.9362\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2444 - accuracy: 0.9305 - val_loss: 0.2231 - val_accuracy: 0.9358\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2433 - accuracy: 0.9311 - val_loss: 0.2221 - val_accuracy: 0.9367\n",
      "20000/20000 [==============================] - 1s 51us/sample - loss: 0.2502 - accuracy: 0.9294\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.2749 - accuracy: 0.1648 - val_loss: 2.1807 - val_accuracy: 0.2540\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 2.0962 - accuracy: 0.3502 - val_loss: 1.9942 - val_accuracy: 0.4782\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.9007 - accuracy: 0.5182 - val_loss: 1.7779 - val_accuracy: 0.5875\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.6786 - accuracy: 0.6018 - val_loss: 1.5411 - val_accuracy: 0.6580\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 29us/sample - loss: 1.4479 - accuracy: 0.6702 - val_loss: 1.3101 - val_accuracy: 0.7255\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 1.2392 - accuracy: 0.7236 - val_loss: 1.1136 - val_accuracy: 0.7716\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 1.0689 - accuracy: 0.7621 - val_loss: 0.9579 - val_accuracy: 0.8046\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.9368 - accuracy: 0.7877 - val_loss: 0.8394 - val_accuracy: 0.8229\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.8363 - accuracy: 0.8060 - val_loss: 0.7495 - val_accuracy: 0.8366\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.7595 - accuracy: 0.8187 - val_loss: 0.6809 - val_accuracy: 0.8487\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.6998 - accuracy: 0.8288 - val_loss: 0.6266 - val_accuracy: 0.8576\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.6523 - accuracy: 0.8362 - val_loss: 0.5838 - val_accuracy: 0.8630\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.6138 - accuracy: 0.8437 - val_loss: 0.5488 - val_accuracy: 0.8700\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.5819 - accuracy: 0.8491 - val_loss: 0.5198 - val_accuracy: 0.8760\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.5552 - accuracy: 0.8547 - val_loss: 0.4957 - val_accuracy: 0.8795\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.5323 - accuracy: 0.8602 - val_loss: 0.4748 - val_accuracy: 0.8825\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.5127 - accuracy: 0.8643 - val_loss: 0.4571 - val_accuracy: 0.8856\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4956 - accuracy: 0.8677 - val_loss: 0.4414 - val_accuracy: 0.8900\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4805 - accuracy: 0.8710 - val_loss: 0.4280 - val_accuracy: 0.8917\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4670 - accuracy: 0.8737 - val_loss: 0.4160 - val_accuracy: 0.8945\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4552 - accuracy: 0.8765 - val_loss: 0.4053 - val_accuracy: 0.8970\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.4443 - accuracy: 0.8787 - val_loss: 0.3960 - val_accuracy: 0.8984\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.4347 - accuracy: 0.8809 - val_loss: 0.3874 - val_accuracy: 0.8990\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4258 - accuracy: 0.8825 - val_loss: 0.3796 - val_accuracy: 0.9021\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4177 - accuracy: 0.8842 - val_loss: 0.3726 - val_accuracy: 0.9034\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4102 - accuracy: 0.8863 - val_loss: 0.3662 - val_accuracy: 0.9039\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4034 - accuracy: 0.8879 - val_loss: 0.3601 - val_accuracy: 0.9056\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3971 - accuracy: 0.8897 - val_loss: 0.3547 - val_accuracy: 0.9075\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3912 - accuracy: 0.8911 - val_loss: 0.3496 - val_accuracy: 0.9082\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3856 - accuracy: 0.8923 - val_loss: 0.3448 - val_accuracy: 0.9087\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3805 - accuracy: 0.8938 - val_loss: 0.3405 - val_accuracy: 0.9091\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3757 - accuracy: 0.8951 - val_loss: 0.3363 - val_accuracy: 0.9101\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3711 - accuracy: 0.8962 - val_loss: 0.3325 - val_accuracy: 0.9105\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3668 - accuracy: 0.8968 - val_loss: 0.3289 - val_accuracy: 0.9118\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3627 - accuracy: 0.8982 - val_loss: 0.3256 - val_accuracy: 0.9120\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3589 - accuracy: 0.8991 - val_loss: 0.3219 - val_accuracy: 0.9128\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3552 - accuracy: 0.9001 - val_loss: 0.3190 - val_accuracy: 0.9136\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3517 - accuracy: 0.9007 - val_loss: 0.3159 - val_accuracy: 0.9137\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3484 - accuracy: 0.9019 - val_loss: 0.3131 - val_accuracy: 0.9141\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3451 - accuracy: 0.9022 - val_loss: 0.3106 - val_accuracy: 0.9147\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3421 - accuracy: 0.9033 - val_loss: 0.3079 - val_accuracy: 0.9158\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3391 - accuracy: 0.9041 - val_loss: 0.3055 - val_accuracy: 0.9176\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3362 - accuracy: 0.9049 - val_loss: 0.3030 - val_accuracy: 0.9176\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3335 - accuracy: 0.9057 - val_loss: 0.3008 - val_accuracy: 0.9187\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3308 - accuracy: 0.9063 - val_loss: 0.2987 - val_accuracy: 0.9194\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3282 - accuracy: 0.9078 - val_loss: 0.2966 - val_accuracy: 0.9190\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3259 - accuracy: 0.9075 - val_loss: 0.2943 - val_accuracy: 0.9204\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3234 - accuracy: 0.9082 - val_loss: 0.2925 - val_accuracy: 0.9205\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3212 - accuracy: 0.9088 - val_loss: 0.2904 - val_accuracy: 0.9214\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3188 - accuracy: 0.9091 - val_loss: 0.2885 - val_accuracy: 0.9222\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3166 - accuracy: 0.9098 - val_loss: 0.2867 - val_accuracy: 0.9220\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3145 - accuracy: 0.9105 - val_loss: 0.2848 - val_accuracy: 0.9230\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.3124 - accuracy: 0.9112 - val_loss: 0.2833 - val_accuracy: 0.9230\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3103 - accuracy: 0.9119 - val_loss: 0.2817 - val_accuracy: 0.9225\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3083 - accuracy: 0.9121 - val_loss: 0.2801 - val_accuracy: 0.9229\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3064 - accuracy: 0.9132 - val_loss: 0.2784 - val_accuracy: 0.9240\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3044 - accuracy: 0.9132 - val_loss: 0.2770 - val_accuracy: 0.9240\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3026 - accuracy: 0.9139 - val_loss: 0.2752 - val_accuracy: 0.9243\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3008 - accuracy: 0.9143 - val_loss: 0.2739 - val_accuracy: 0.9245\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2990 - accuracy: 0.9151 - val_loss: 0.2725 - val_accuracy: 0.9245\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2973 - accuracy: 0.9153 - val_loss: 0.2710 - val_accuracy: 0.9246\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2955 - accuracy: 0.9156 - val_loss: 0.2697 - val_accuracy: 0.9259\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2939 - accuracy: 0.9162 - val_loss: 0.2683 - val_accuracy: 0.9256\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2922 - accuracy: 0.9164 - val_loss: 0.2670 - val_accuracy: 0.9255\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2907 - accuracy: 0.9167 - val_loss: 0.2659 - val_accuracy: 0.9254\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2890 - accuracy: 0.9174 - val_loss: 0.2645 - val_accuracy: 0.9268\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2875 - accuracy: 0.9179 - val_loss: 0.2633 - val_accuracy: 0.9264\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2860 - accuracy: 0.9178 - val_loss: 0.2619 - val_accuracy: 0.9268\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2845 - accuracy: 0.9183 - val_loss: 0.2609 - val_accuracy: 0.9265\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2830 - accuracy: 0.9185 - val_loss: 0.2597 - val_accuracy: 0.9268\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2816 - accuracy: 0.9193 - val_loss: 0.2583 - val_accuracy: 0.9273\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2802 - accuracy: 0.9197 - val_loss: 0.2575 - val_accuracy: 0.9269\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2788 - accuracy: 0.9204 - val_loss: 0.2563 - val_accuracy: 0.9275\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2774 - accuracy: 0.9203 - val_loss: 0.2552 - val_accuracy: 0.9285\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2761 - accuracy: 0.9208 - val_loss: 0.2541 - val_accuracy: 0.9277\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2748 - accuracy: 0.9209 - val_loss: 0.2531 - val_accuracy: 0.9285\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2735 - accuracy: 0.9218 - val_loss: 0.2519 - val_accuracy: 0.9290\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2722 - accuracy: 0.9218 - val_loss: 0.2510 - val_accuracy: 0.9293\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2709 - accuracy: 0.9222 - val_loss: 0.2500 - val_accuracy: 0.9299\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2696 - accuracy: 0.9225 - val_loss: 0.2491 - val_accuracy: 0.9298\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2684 - accuracy: 0.9227 - val_loss: 0.2481 - val_accuracy: 0.9299\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2671 - accuracy: 0.9230 - val_loss: 0.2471 - val_accuracy: 0.9311\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2659 - accuracy: 0.9239 - val_loss: 0.2463 - val_accuracy: 0.9302\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2647 - accuracy: 0.9238 - val_loss: 0.2454 - val_accuracy: 0.9308\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2636 - accuracy: 0.9243 - val_loss: 0.2442 - val_accuracy: 0.9311\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2624 - accuracy: 0.9242 - val_loss: 0.2433 - val_accuracy: 0.9317\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2613 - accuracy: 0.9251 - val_loss: 0.2423 - val_accuracy: 0.9319\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2601 - accuracy: 0.9252 - val_loss: 0.2414 - val_accuracy: 0.9325\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2590 - accuracy: 0.9261 - val_loss: 0.2405 - val_accuracy: 0.9323\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2579 - accuracy: 0.9260 - val_loss: 0.2398 - val_accuracy: 0.9326\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2569 - accuracy: 0.9266 - val_loss: 0.2389 - val_accuracy: 0.9326\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2558 - accuracy: 0.9266 - val_loss: 0.2378 - val_accuracy: 0.9330\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2547 - accuracy: 0.9270 - val_loss: 0.2371 - val_accuracy: 0.9333\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.2536 - accuracy: 0.9273 - val_loss: 0.2364 - val_accuracy: 0.9336\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2525 - accuracy: 0.9279 - val_loss: 0.2355 - val_accuracy: 0.9336\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2515 - accuracy: 0.9276 - val_loss: 0.2347 - val_accuracy: 0.9339\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2505 - accuracy: 0.9281 - val_loss: 0.2338 - val_accuracy: 0.9346\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2494 - accuracy: 0.9286 - val_loss: 0.2330 - val_accuracy: 0.9348\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2484 - accuracy: 0.9288 - val_loss: 0.2326 - val_accuracy: 0.9346\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2474 - accuracy: 0.9299 - val_loss: 0.2316 - val_accuracy: 0.9339\n",
      "20000/20000 [==============================] - 1s 54us/sample - loss: 0.2713 - accuracy: 0.9209\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 2.2478 - accuracy: 0.1968 - val_loss: 2.1647 - val_accuracy: 0.2950\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 2.0707 - accuracy: 0.4033 - val_loss: 1.9816 - val_accuracy: 0.4831\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 1.8663 - accuracy: 0.5633 - val_loss: 1.7588 - val_accuracy: 0.6106\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 1.6265 - accuracy: 0.6573 - val_loss: 1.5120 - val_accuracy: 0.6850\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 1.3836 - accuracy: 0.7128 - val_loss: 1.2813 - val_accuracy: 0.7415\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.1728 - accuracy: 0.7583 - val_loss: 1.0930 - val_accuracy: 0.7837\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.0076 - accuracy: 0.7915 - val_loss: 0.9502 - val_accuracy: 0.8145\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.8833 - accuracy: 0.8153 - val_loss: 0.8423 - val_accuracy: 0.8309\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.7900 - accuracy: 0.8299 - val_loss: 0.7615 - val_accuracy: 0.8386\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.7188 - accuracy: 0.8414 - val_loss: 0.6980 - val_accuracy: 0.8462\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.6635 - accuracy: 0.8489 - val_loss: 0.6491 - val_accuracy: 0.8526\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.6196 - accuracy: 0.8544 - val_loss: 0.6090 - val_accuracy: 0.8584\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.5839 - accuracy: 0.8598 - val_loss: 0.5765 - val_accuracy: 0.8629\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5545 - accuracy: 0.8637 - val_loss: 0.5500 - val_accuracy: 0.8656\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.5299 - accuracy: 0.8676 - val_loss: 0.5271 - val_accuracy: 0.8686\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.5090 - accuracy: 0.8709 - val_loss: 0.5079 - val_accuracy: 0.8724\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4910 - accuracy: 0.8739 - val_loss: 0.4911 - val_accuracy: 0.8760\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4754 - accuracy: 0.8768 - val_loss: 0.4765 - val_accuracy: 0.8781\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 28us/sample - loss: 0.4617 - accuracy: 0.8797 - val_loss: 0.4639 - val_accuracy: 0.8791\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4496 - accuracy: 0.8821 - val_loss: 0.4527 - val_accuracy: 0.8811\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4387 - accuracy: 0.8841 - val_loss: 0.4430 - val_accuracy: 0.8813\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4291 - accuracy: 0.8861 - val_loss: 0.4340 - val_accuracy: 0.8840\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4203 - accuracy: 0.8882 - val_loss: 0.4257 - val_accuracy: 0.8852\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4123 - accuracy: 0.8894 - val_loss: 0.4181 - val_accuracy: 0.8873\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4051 - accuracy: 0.8909 - val_loss: 0.4114 - val_accuracy: 0.8873\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3984 - accuracy: 0.8922 - val_loss: 0.4052 - val_accuracy: 0.8890\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3922 - accuracy: 0.8936 - val_loss: 0.3996 - val_accuracy: 0.8882\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3864 - accuracy: 0.8948 - val_loss: 0.3944 - val_accuracy: 0.8896\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3812 - accuracy: 0.8960 - val_loss: 0.3892 - val_accuracy: 0.8913\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3762 - accuracy: 0.8968 - val_loss: 0.3846 - val_accuracy: 0.8921\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3715 - accuracy: 0.8982 - val_loss: 0.3805 - val_accuracy: 0.8924\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3671 - accuracy: 0.8989 - val_loss: 0.3769 - val_accuracy: 0.8938\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3630 - accuracy: 0.9001 - val_loss: 0.3726 - val_accuracy: 0.8939\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.3590 - accuracy: 0.9009 - val_loss: 0.3693 - val_accuracy: 0.8945\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.3553 - accuracy: 0.9017 - val_loss: 0.3658 - val_accuracy: 0.8955\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.3518 - accuracy: 0.9026 - val_loss: 0.3627 - val_accuracy: 0.8969\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 46us/sample - loss: 0.3484 - accuracy: 0.9038 - val_loss: 0.3596 - val_accuracy: 0.8972\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3452 - accuracy: 0.9043 - val_loss: 0.3565 - val_accuracy: 0.8984\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.3421 - accuracy: 0.9050 - val_loss: 0.3540 - val_accuracy: 0.8984\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3392 - accuracy: 0.9057 - val_loss: 0.3513 - val_accuracy: 0.8992\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3364 - accuracy: 0.9068 - val_loss: 0.3487 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3336 - accuracy: 0.9072 - val_loss: 0.3463 - val_accuracy: 0.9003\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3310 - accuracy: 0.9079 - val_loss: 0.3438 - val_accuracy: 0.9011\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3285 - accuracy: 0.9083 - val_loss: 0.3416 - val_accuracy: 0.9022\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3259 - accuracy: 0.9091 - val_loss: 0.3396 - val_accuracy: 0.9025\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3237 - accuracy: 0.9100 - val_loss: 0.3372 - val_accuracy: 0.9029\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3213 - accuracy: 0.9099 - val_loss: 0.3353 - val_accuracy: 0.9036\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.3190 - accuracy: 0.9108 - val_loss: 0.3333 - val_accuracy: 0.9038\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3169 - accuracy: 0.9113 - val_loss: 0.3314 - val_accuracy: 0.9047\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3148 - accuracy: 0.9120 - val_loss: 0.3299 - val_accuracy: 0.9054\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3126 - accuracy: 0.9121 - val_loss: 0.3279 - val_accuracy: 0.9061\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3108 - accuracy: 0.9130 - val_loss: 0.3258 - val_accuracy: 0.9068\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3088 - accuracy: 0.9132 - val_loss: 0.3244 - val_accuracy: 0.9080\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3069 - accuracy: 0.9141 - val_loss: 0.3224 - val_accuracy: 0.9078\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3050 - accuracy: 0.9146 - val_loss: 0.3210 - val_accuracy: 0.9084\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3032 - accuracy: 0.9146 - val_loss: 0.3194 - val_accuracy: 0.9078\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3014 - accuracy: 0.9150 - val_loss: 0.3180 - val_accuracy: 0.9094\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2997 - accuracy: 0.9159 - val_loss: 0.3165 - val_accuracy: 0.9091\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2979 - accuracy: 0.9164 - val_loss: 0.3149 - val_accuracy: 0.9085\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.2963 - accuracy: 0.9168 - val_loss: 0.3134 - val_accuracy: 0.9089\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2945 - accuracy: 0.9172 - val_loss: 0.3119 - val_accuracy: 0.9103\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2929 - accuracy: 0.9181 - val_loss: 0.3106 - val_accuracy: 0.9104\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2913 - accuracy: 0.9184 - val_loss: 0.3089 - val_accuracy: 0.9105\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2898 - accuracy: 0.9185 - val_loss: 0.3078 - val_accuracy: 0.9109\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.2882 - accuracy: 0.9192 - val_loss: 0.3065 - val_accuracy: 0.9105\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 45us/sample - loss: 0.2867 - accuracy: 0.9195 - val_loss: 0.3051 - val_accuracy: 0.9111\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.2852 - accuracy: 0.9203 - val_loss: 0.3036 - val_accuracy: 0.9119\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2837 - accuracy: 0.9207 - val_loss: 0.3026 - val_accuracy: 0.9121\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2822 - accuracy: 0.9214 - val_loss: 0.3016 - val_accuracy: 0.9125\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2809 - accuracy: 0.9208 - val_loss: 0.3003 - val_accuracy: 0.9121\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2795 - accuracy: 0.9216 - val_loss: 0.2989 - val_accuracy: 0.9133\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2780 - accuracy: 0.9216 - val_loss: 0.2975 - val_accuracy: 0.9133\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2768 - accuracy: 0.9223 - val_loss: 0.2964 - val_accuracy: 0.9136\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2753 - accuracy: 0.9229 - val_loss: 0.2953 - val_accuracy: 0.9136\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2740 - accuracy: 0.9232 - val_loss: 0.2942 - val_accuracy: 0.9140\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.2727 - accuracy: 0.9241 - val_loss: 0.2930 - val_accuracy: 0.9140\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2714 - accuracy: 0.9238 - val_loss: 0.2917 - val_accuracy: 0.9144\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2700 - accuracy: 0.9243 - val_loss: 0.2910 - val_accuracy: 0.9149\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2689 - accuracy: 0.9242 - val_loss: 0.2896 - val_accuracy: 0.9146\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.2676 - accuracy: 0.9247 - val_loss: 0.2886 - val_accuracy: 0.9146\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2662 - accuracy: 0.9251 - val_loss: 0.2873 - val_accuracy: 0.9160\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.2651 - accuracy: 0.9258 - val_loss: 0.2865 - val_accuracy: 0.9151\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2638 - accuracy: 0.9255 - val_loss: 0.2854 - val_accuracy: 0.9160\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2626 - accuracy: 0.9262 - val_loss: 0.2843 - val_accuracy: 0.9158\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.2614 - accuracy: 0.9267 - val_loss: 0.2834 - val_accuracy: 0.9160\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2602 - accuracy: 0.9268 - val_loss: 0.2824 - val_accuracy: 0.9170\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2590 - accuracy: 0.9278 - val_loss: 0.2813 - val_accuracy: 0.9178\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2579 - accuracy: 0.9276 - val_loss: 0.2803 - val_accuracy: 0.9184\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2568 - accuracy: 0.9279 - val_loss: 0.2792 - val_accuracy: 0.9178\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2556 - accuracy: 0.9279 - val_loss: 0.2783 - val_accuracy: 0.9200\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2545 - accuracy: 0.9283 - val_loss: 0.2773 - val_accuracy: 0.9199\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2533 - accuracy: 0.9285 - val_loss: 0.2766 - val_accuracy: 0.9202\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2523 - accuracy: 0.9288 - val_loss: 0.2754 - val_accuracy: 0.9210\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2512 - accuracy: 0.9292 - val_loss: 0.2744 - val_accuracy: 0.9209\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2501 - accuracy: 0.9295 - val_loss: 0.2735 - val_accuracy: 0.9208\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2490 - accuracy: 0.9294 - val_loss: 0.2725 - val_accuracy: 0.9212\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2479 - accuracy: 0.9299 - val_loss: 0.2718 - val_accuracy: 0.9215\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2469 - accuracy: 0.9305 - val_loss: 0.2707 - val_accuracy: 0.9219\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2458 - accuracy: 0.9307 - val_loss: 0.2701 - val_accuracy: 0.9222\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2448 - accuracy: 0.9311 - val_loss: 0.2689 - val_accuracy: 0.9236\n",
      "20000/20000 [==============================] - 1s 57us/sample - loss: 0.2585 - accuracy: 0.9242\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 1.9684 - accuracy: 0.4275 - val_loss: 1.4575 - val_accuracy: 0.7400\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 1.0633 - accuracy: 0.7786 - val_loss: 0.7103 - val_accuracy: 0.8495\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.6459 - accuracy: 0.8429 - val_loss: 0.4980 - val_accuracy: 0.8823\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.5076 - accuracy: 0.8669 - val_loss: 0.4112 - val_accuracy: 0.8966\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4411 - accuracy: 0.8808 - val_loss: 0.3657 - val_accuracy: 0.9038\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4016 - accuracy: 0.8901 - val_loss: 0.3405 - val_accuracy: 0.9079\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3749 - accuracy: 0.8947 - val_loss: 0.3192 - val_accuracy: 0.9125\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3551 - accuracy: 0.8991 - val_loss: 0.3041 - val_accuracy: 0.9134\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3394 - accuracy: 0.9042 - val_loss: 0.2933 - val_accuracy: 0.9178\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3262 - accuracy: 0.9067 - val_loss: 0.2837 - val_accuracy: 0.9193\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3153 - accuracy: 0.9095 - val_loss: 0.2751 - val_accuracy: 0.9220\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3058 - accuracy: 0.9121 - val_loss: 0.2683 - val_accuracy: 0.9239\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2973 - accuracy: 0.9147 - val_loss: 0.2636 - val_accuracy: 0.9246\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2896 - accuracy: 0.9163 - val_loss: 0.2565 - val_accuracy: 0.9254\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2823 - accuracy: 0.9191 - val_loss: 0.2514 - val_accuracy: 0.9279\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2755 - accuracy: 0.9209 - val_loss: 0.2462 - val_accuracy: 0.9276\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2695 - accuracy: 0.9225 - val_loss: 0.2413 - val_accuracy: 0.9294\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2638 - accuracy: 0.9244 - val_loss: 0.2377 - val_accuracy: 0.9316\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2582 - accuracy: 0.9256 - val_loss: 0.2339 - val_accuracy: 0.9320\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2527 - accuracy: 0.9282 - val_loss: 0.2302 - val_accuracy: 0.9334\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2479 - accuracy: 0.9292 - val_loss: 0.2267 - val_accuracy: 0.9330\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2432 - accuracy: 0.9310 - val_loss: 0.2229 - val_accuracy: 0.9349\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2386 - accuracy: 0.9320 - val_loss: 0.2186 - val_accuracy: 0.9364\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2343 - accuracy: 0.9333 - val_loss: 0.2157 - val_accuracy: 0.9369\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2300 - accuracy: 0.9341 - val_loss: 0.2123 - val_accuracy: 0.9384\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2258 - accuracy: 0.9349 - val_loss: 0.2114 - val_accuracy: 0.9384\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2222 - accuracy: 0.9362 - val_loss: 0.2067 - val_accuracy: 0.9395\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2182 - accuracy: 0.9374 - val_loss: 0.2047 - val_accuracy: 0.9401\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2148 - accuracy: 0.9382 - val_loss: 0.2018 - val_accuracy: 0.9415\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2113 - accuracy: 0.9393 - val_loss: 0.1984 - val_accuracy: 0.9426\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2077 - accuracy: 0.9408 - val_loss: 0.1972 - val_accuracy: 0.9434\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2045 - accuracy: 0.9414 - val_loss: 0.1943 - val_accuracy: 0.9442\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2012 - accuracy: 0.9418 - val_loss: 0.1919 - val_accuracy: 0.9451\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1980 - accuracy: 0.9430 - val_loss: 0.1893 - val_accuracy: 0.9470\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1951 - accuracy: 0.9447 - val_loss: 0.1869 - val_accuracy: 0.9477\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1920 - accuracy: 0.9450 - val_loss: 0.1852 - val_accuracy: 0.9479\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1891 - accuracy: 0.9459 - val_loss: 0.1834 - val_accuracy: 0.9495\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1861 - accuracy: 0.9471 - val_loss: 0.1812 - val_accuracy: 0.9510\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1835 - accuracy: 0.9474 - val_loss: 0.1790 - val_accuracy: 0.9507\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1805 - accuracy: 0.9482 - val_loss: 0.1774 - val_accuracy: 0.9509\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1782 - accuracy: 0.9489 - val_loss: 0.1750 - val_accuracy: 0.9531\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1754 - accuracy: 0.9495 - val_loss: 0.1743 - val_accuracy: 0.9516\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1731 - accuracy: 0.9501 - val_loss: 0.1722 - val_accuracy: 0.9540\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1706 - accuracy: 0.9508 - val_loss: 0.1698 - val_accuracy: 0.9544\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1682 - accuracy: 0.9523 - val_loss: 0.1685 - val_accuracy: 0.9539\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1660 - accuracy: 0.9530 - val_loss: 0.1678 - val_accuracy: 0.9539\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1637 - accuracy: 0.9531 - val_loss: 0.1656 - val_accuracy: 0.9539\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1612 - accuracy: 0.9544 - val_loss: 0.1650 - val_accuracy: 0.9544\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1592 - accuracy: 0.9551 - val_loss: 0.1628 - val_accuracy: 0.9548\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1570 - accuracy: 0.9555 - val_loss: 0.1608 - val_accuracy: 0.9556\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1550 - accuracy: 0.9563 - val_loss: 0.1600 - val_accuracy: 0.9557\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1529 - accuracy: 0.9570 - val_loss: 0.1593 - val_accuracy: 0.9565\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1510 - accuracy: 0.9581 - val_loss: 0.1578 - val_accuracy: 0.9565\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1490 - accuracy: 0.9583 - val_loss: 0.1565 - val_accuracy: 0.9565\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1472 - accuracy: 0.9587 - val_loss: 0.1548 - val_accuracy: 0.9566\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1452 - accuracy: 0.9593 - val_loss: 0.1541 - val_accuracy: 0.9578\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1436 - accuracy: 0.9597 - val_loss: 0.1526 - val_accuracy: 0.9576\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1416 - accuracy: 0.9613 - val_loss: 0.1509 - val_accuracy: 0.9582\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1400 - accuracy: 0.9609 - val_loss: 0.1500 - val_accuracy: 0.9580\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1382 - accuracy: 0.9614 - val_loss: 0.1497 - val_accuracy: 0.9585\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1365 - accuracy: 0.9618 - val_loss: 0.1480 - val_accuracy: 0.9581\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1347 - accuracy: 0.9624 - val_loss: 0.1470 - val_accuracy: 0.9588\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1331 - accuracy: 0.9633 - val_loss: 0.1466 - val_accuracy: 0.9586\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1314 - accuracy: 0.9641 - val_loss: 0.1447 - val_accuracy: 0.9588\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1298 - accuracy: 0.9649 - val_loss: 0.1438 - val_accuracy: 0.9586\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1284 - accuracy: 0.9648 - val_loss: 0.1432 - val_accuracy: 0.9591\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1268 - accuracy: 0.9652 - val_loss: 0.1429 - val_accuracy: 0.9595\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1252 - accuracy: 0.9655 - val_loss: 0.1420 - val_accuracy: 0.9594\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1238 - accuracy: 0.9661 - val_loss: 0.1408 - val_accuracy: 0.9596\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1224 - accuracy: 0.9662 - val_loss: 0.1403 - val_accuracy: 0.9591\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1209 - accuracy: 0.9662 - val_loss: 0.1396 - val_accuracy: 0.9601\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1195 - accuracy: 0.9669 - val_loss: 0.1392 - val_accuracy: 0.9607\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1181 - accuracy: 0.9673 - val_loss: 0.1370 - val_accuracy: 0.9617\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1168 - accuracy: 0.9683 - val_loss: 0.1367 - val_accuracy: 0.9619\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1153 - accuracy: 0.9684 - val_loss: 0.1360 - val_accuracy: 0.9616\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1140 - accuracy: 0.9684 - val_loss: 0.1360 - val_accuracy: 0.9616\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1127 - accuracy: 0.9688 - val_loss: 0.1342 - val_accuracy: 0.9619\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1117 - accuracy: 0.9693 - val_loss: 0.1331 - val_accuracy: 0.9629\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1103 - accuracy: 0.9700 - val_loss: 0.1325 - val_accuracy: 0.9622\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1091 - accuracy: 0.9703 - val_loss: 0.1317 - val_accuracy: 0.9620\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1079 - accuracy: 0.9703 - val_loss: 0.1312 - val_accuracy: 0.9630\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.1065 - accuracy: 0.9710 - val_loss: 0.1307 - val_accuracy: 0.9635\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1055 - accuracy: 0.9714 - val_loss: 0.1304 - val_accuracy: 0.9620\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.1043 - accuracy: 0.9717 - val_loss: 0.1292 - val_accuracy: 0.9631\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1031 - accuracy: 0.9717 - val_loss: 0.1279 - val_accuracy: 0.9624\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1019 - accuracy: 0.9725 - val_loss: 0.1285 - val_accuracy: 0.9632\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1009 - accuracy: 0.9730 - val_loss: 0.1275 - val_accuracy: 0.9644\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1000 - accuracy: 0.9723 - val_loss: 0.1273 - val_accuracy: 0.9639\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0987 - accuracy: 0.9733 - val_loss: 0.1258 - val_accuracy: 0.9643\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0976 - accuracy: 0.9735 - val_loss: 0.1264 - val_accuracy: 0.9651\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0967 - accuracy: 0.9740 - val_loss: 0.1259 - val_accuracy: 0.9646\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0957 - accuracy: 0.9739 - val_loss: 0.1246 - val_accuracy: 0.9651\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0945 - accuracy: 0.9747 - val_loss: 0.1239 - val_accuracy: 0.9659\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0935 - accuracy: 0.9749 - val_loss: 0.1246 - val_accuracy: 0.9639\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0926 - accuracy: 0.9749 - val_loss: 0.1241 - val_accuracy: 0.9644\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.1223 - val_accuracy: 0.9647\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0905 - accuracy: 0.9761 - val_loss: 0.1240 - val_accuracy: 0.9653\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0897 - accuracy: 0.9760 - val_loss: 0.1222 - val_accuracy: 0.9663\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0886 - accuracy: 0.9762 - val_loss: 0.1215 - val_accuracy: 0.9664\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0878 - accuracy: 0.9766 - val_loss: 0.1210 - val_accuracy: 0.9664\n",
      "20000/20000 [==============================] - 1s 57us/sample - loss: 0.1309 - accuracy: 0.9603\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 1.7102 - accuracy: 0.5287 - val_loss: 1.0823 - val_accuracy: 0.7876\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.8244 - accuracy: 0.8164 - val_loss: 0.5962 - val_accuracy: 0.8668\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.5567 - accuracy: 0.8616 - val_loss: 0.4505 - val_accuracy: 0.8873\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4577 - accuracy: 0.8808 - val_loss: 0.3874 - val_accuracy: 0.8979\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4074 - accuracy: 0.8902 - val_loss: 0.3508 - val_accuracy: 0.9043\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3760 - accuracy: 0.8965 - val_loss: 0.3278 - val_accuracy: 0.9095\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3542 - accuracy: 0.9010 - val_loss: 0.3114 - val_accuracy: 0.9125\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3376 - accuracy: 0.9046 - val_loss: 0.2977 - val_accuracy: 0.9169\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3237 - accuracy: 0.9080 - val_loss: 0.2863 - val_accuracy: 0.9200\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3126 - accuracy: 0.9116 - val_loss: 0.2779 - val_accuracy: 0.9211\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3022 - accuracy: 0.9142 - val_loss: 0.2706 - val_accuracy: 0.9235\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2933 - accuracy: 0.9160 - val_loss: 0.2630 - val_accuracy: 0.9239\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2852 - accuracy: 0.9187 - val_loss: 0.2562 - val_accuracy: 0.9258\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2772 - accuracy: 0.9205 - val_loss: 0.2505 - val_accuracy: 0.9281\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2706 - accuracy: 0.9225 - val_loss: 0.2452 - val_accuracy: 0.9296\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2644 - accuracy: 0.9243 - val_loss: 0.2396 - val_accuracy: 0.9285\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2581 - accuracy: 0.9262 - val_loss: 0.2364 - val_accuracy: 0.9317\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2522 - accuracy: 0.9274 - val_loss: 0.2308 - val_accuracy: 0.9341\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2469 - accuracy: 0.9293 - val_loss: 0.2265 - val_accuracy: 0.9344\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2418 - accuracy: 0.9293 - val_loss: 0.2226 - val_accuracy: 0.9351\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2370 - accuracy: 0.9320 - val_loss: 0.2185 - val_accuracy: 0.9360\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2321 - accuracy: 0.9334 - val_loss: 0.2145 - val_accuracy: 0.9395\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2278 - accuracy: 0.9352 - val_loss: 0.2111 - val_accuracy: 0.9405\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2235 - accuracy: 0.9362 - val_loss: 0.2088 - val_accuracy: 0.9415\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2195 - accuracy: 0.9374 - val_loss: 0.2052 - val_accuracy: 0.9423\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2156 - accuracy: 0.9392 - val_loss: 0.2016 - val_accuracy: 0.9426\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2117 - accuracy: 0.9400 - val_loss: 0.1997 - val_accuracy: 0.9448\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2077 - accuracy: 0.9413 - val_loss: 0.1964 - val_accuracy: 0.9463\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2044 - accuracy: 0.9423 - val_loss: 0.1928 - val_accuracy: 0.9461\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2009 - accuracy: 0.9432 - val_loss: 0.1910 - val_accuracy: 0.9471\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1976 - accuracy: 0.9445 - val_loss: 0.1876 - val_accuracy: 0.9480\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1943 - accuracy: 0.9460 - val_loss: 0.1866 - val_accuracy: 0.9475\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1913 - accuracy: 0.9459 - val_loss: 0.1840 - val_accuracy: 0.9484\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1883 - accuracy: 0.9473 - val_loss: 0.1815 - val_accuracy: 0.9492\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1853 - accuracy: 0.9480 - val_loss: 0.1801 - val_accuracy: 0.9479\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1826 - accuracy: 0.9488 - val_loss: 0.1763 - val_accuracy: 0.9519\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1797 - accuracy: 0.9500 - val_loss: 0.1748 - val_accuracy: 0.9514\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1770 - accuracy: 0.9503 - val_loss: 0.1731 - val_accuracy: 0.9514\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1743 - accuracy: 0.9513 - val_loss: 0.1712 - val_accuracy: 0.9531\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1718 - accuracy: 0.9519 - val_loss: 0.1694 - val_accuracy: 0.9520\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1692 - accuracy: 0.9526 - val_loss: 0.1675 - val_accuracy: 0.9530\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1667 - accuracy: 0.9536 - val_loss: 0.1659 - val_accuracy: 0.9536\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1643 - accuracy: 0.9540 - val_loss: 0.1642 - val_accuracy: 0.9532\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1622 - accuracy: 0.9541 - val_loss: 0.1629 - val_accuracy: 0.9542\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1598 - accuracy: 0.9556 - val_loss: 0.1605 - val_accuracy: 0.9548\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1574 - accuracy: 0.9563 - val_loss: 0.1596 - val_accuracy: 0.9550\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1554 - accuracy: 0.9562 - val_loss: 0.1578 - val_accuracy: 0.9565\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1530 - accuracy: 0.9569 - val_loss: 0.1574 - val_accuracy: 0.9554\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1511 - accuracy: 0.9572 - val_loss: 0.1562 - val_accuracy: 0.9557\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1490 - accuracy: 0.9581 - val_loss: 0.1534 - val_accuracy: 0.9569\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1470 - accuracy: 0.9588 - val_loss: 0.1528 - val_accuracy: 0.9575\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1452 - accuracy: 0.9588 - val_loss: 0.1509 - val_accuracy: 0.9578\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.1432 - accuracy: 0.9592 - val_loss: 0.1505 - val_accuracy: 0.9584\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1411 - accuracy: 0.9601 - val_loss: 0.1492 - val_accuracy: 0.9579\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1391 - accuracy: 0.9610 - val_loss: 0.1478 - val_accuracy: 0.9585\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1374 - accuracy: 0.9614 - val_loss: 0.1467 - val_accuracy: 0.9603\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1359 - accuracy: 0.9617 - val_loss: 0.1454 - val_accuracy: 0.9589\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1340 - accuracy: 0.9625 - val_loss: 0.1452 - val_accuracy: 0.9597\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1323 - accuracy: 0.9630 - val_loss: 0.1431 - val_accuracy: 0.9614\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1307 - accuracy: 0.9630 - val_loss: 0.1426 - val_accuracy: 0.9604\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1290 - accuracy: 0.9638 - val_loss: 0.1423 - val_accuracy: 0.9597\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1273 - accuracy: 0.9644 - val_loss: 0.1425 - val_accuracy: 0.9596\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1259 - accuracy: 0.9648 - val_loss: 0.1398 - val_accuracy: 0.9620\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1241 - accuracy: 0.9654 - val_loss: 0.1393 - val_accuracy: 0.9614\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1228 - accuracy: 0.9665 - val_loss: 0.1380 - val_accuracy: 0.9617\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1213 - accuracy: 0.9663 - val_loss: 0.1378 - val_accuracy: 0.9621\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1197 - accuracy: 0.9668 - val_loss: 0.1375 - val_accuracy: 0.9636\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1184 - accuracy: 0.9669 - val_loss: 0.1359 - val_accuracy: 0.9622\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1168 - accuracy: 0.9676 - val_loss: 0.1355 - val_accuracy: 0.9624\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1153 - accuracy: 0.9680 - val_loss: 0.1361 - val_accuracy: 0.9620\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1142 - accuracy: 0.9685 - val_loss: 0.1336 - val_accuracy: 0.9619\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1128 - accuracy: 0.9684 - val_loss: 0.1336 - val_accuracy: 0.9634\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1114 - accuracy: 0.9690 - val_loss: 0.1328 - val_accuracy: 0.9631\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1102 - accuracy: 0.9697 - val_loss: 0.1331 - val_accuracy: 0.9625\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1089 - accuracy: 0.9696 - val_loss: 0.1311 - val_accuracy: 0.9635\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1075 - accuracy: 0.9705 - val_loss: 0.1307 - val_accuracy: 0.9643\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1062 - accuracy: 0.9705 - val_loss: 0.1301 - val_accuracy: 0.9640\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1050 - accuracy: 0.9707 - val_loss: 0.1297 - val_accuracy: 0.9645\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1039 - accuracy: 0.9714 - val_loss: 0.1285 - val_accuracy: 0.9643\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1026 - accuracy: 0.9717 - val_loss: 0.1292 - val_accuracy: 0.9635\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1014 - accuracy: 0.9717 - val_loss: 0.1289 - val_accuracy: 0.9632\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1004 - accuracy: 0.9724 - val_loss: 0.1277 - val_accuracy: 0.9645\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0991 - accuracy: 0.9729 - val_loss: 0.1291 - val_accuracy: 0.9634\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0981 - accuracy: 0.9729 - val_loss: 0.1261 - val_accuracy: 0.9645\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0971 - accuracy: 0.9734 - val_loss: 0.1251 - val_accuracy: 0.9645\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0959 - accuracy: 0.9736 - val_loss: 0.1255 - val_accuracy: 0.9660\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0949 - accuracy: 0.9744 - val_loss: 0.1242 - val_accuracy: 0.9659\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0940 - accuracy: 0.9743 - val_loss: 0.1243 - val_accuracy: 0.9647\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0928 - accuracy: 0.9743 - val_loss: 0.1240 - val_accuracy: 0.9661\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0917 - accuracy: 0.9753 - val_loss: 0.1230 - val_accuracy: 0.9650\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0908 - accuracy: 0.9750 - val_loss: 0.1233 - val_accuracy: 0.9659\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0896 - accuracy: 0.9755 - val_loss: 0.1223 - val_accuracy: 0.9661\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0889 - accuracy: 0.9758 - val_loss: 0.1213 - val_accuracy: 0.9659\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0878 - accuracy: 0.9765 - val_loss: 0.1231 - val_accuracy: 0.9657\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0872 - accuracy: 0.9764 - val_loss: 0.1213 - val_accuracy: 0.9656\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0861 - accuracy: 0.9768 - val_loss: 0.1201 - val_accuracy: 0.9668\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0851 - accuracy: 0.9768 - val_loss: 0.1209 - val_accuracy: 0.9661\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0842 - accuracy: 0.9771 - val_loss: 0.1209 - val_accuracy: 0.9665\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0834 - accuracy: 0.9775 - val_loss: 0.1204 - val_accuracy: 0.9663\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0826 - accuracy: 0.9780 - val_loss: 0.1197 - val_accuracy: 0.9656\n",
      "20000/20000 [==============================] - 1s 57us/sample - loss: 0.1409 - accuracy: 0.9581\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 1.8221 - accuracy: 0.5013 - val_loss: 1.2934 - val_accuracy: 0.7045\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.9408 - accuracy: 0.7767 - val_loss: 0.7101 - val_accuracy: 0.8215\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6040 - accuracy: 0.8430 - val_loss: 0.5318 - val_accuracy: 0.8624\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4834 - accuracy: 0.8705 - val_loss: 0.4512 - val_accuracy: 0.8774\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.4230 - accuracy: 0.8836 - val_loss: 0.4082 - val_accuracy: 0.8867\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3875 - accuracy: 0.8915 - val_loss: 0.3806 - val_accuracy: 0.8944\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3625 - accuracy: 0.8976 - val_loss: 0.3593 - val_accuracy: 0.8986\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3441 - accuracy: 0.9022 - val_loss: 0.3437 - val_accuracy: 0.9024\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3292 - accuracy: 0.9065 - val_loss: 0.3318 - val_accuracy: 0.9043\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3165 - accuracy: 0.9102 - val_loss: 0.3205 - val_accuracy: 0.9068\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.3058 - accuracy: 0.9123 - val_loss: 0.3126 - val_accuracy: 0.9095\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2959 - accuracy: 0.9150 - val_loss: 0.3035 - val_accuracy: 0.9097\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2873 - accuracy: 0.9178 - val_loss: 0.2948 - val_accuracy: 0.9126\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2794 - accuracy: 0.9202 - val_loss: 0.2893 - val_accuracy: 0.9158\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2720 - accuracy: 0.9215 - val_loss: 0.2820 - val_accuracy: 0.9179\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2654 - accuracy: 0.9234 - val_loss: 0.2767 - val_accuracy: 0.9199\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2589 - accuracy: 0.9261 - val_loss: 0.2709 - val_accuracy: 0.9227\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2529 - accuracy: 0.9275 - val_loss: 0.2645 - val_accuracy: 0.9234\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2470 - accuracy: 0.9298 - val_loss: 0.2604 - val_accuracy: 0.9252\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2419 - accuracy: 0.9312 - val_loss: 0.2559 - val_accuracy: 0.9280\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2368 - accuracy: 0.9329 - val_loss: 0.2521 - val_accuracy: 0.9280\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2319 - accuracy: 0.9337 - val_loss: 0.2477 - val_accuracy: 0.9289\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2271 - accuracy: 0.9353 - val_loss: 0.2432 - val_accuracy: 0.9300\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2226 - accuracy: 0.9369 - val_loss: 0.2396 - val_accuracy: 0.9310\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2185 - accuracy: 0.9376 - val_loss: 0.2368 - val_accuracy: 0.9324\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2143 - accuracy: 0.9389 - val_loss: 0.2323 - val_accuracy: 0.9324\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2102 - accuracy: 0.9404 - val_loss: 0.2302 - val_accuracy: 0.9336\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2066 - accuracy: 0.9409 - val_loss: 0.2281 - val_accuracy: 0.9349\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2028 - accuracy: 0.9418 - val_loss: 0.2254 - val_accuracy: 0.9354\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1996 - accuracy: 0.9422 - val_loss: 0.2202 - val_accuracy: 0.9359\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1959 - accuracy: 0.9442 - val_loss: 0.2185 - val_accuracy: 0.9365\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1927 - accuracy: 0.9443 - val_loss: 0.2163 - val_accuracy: 0.9376\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1894 - accuracy: 0.9460 - val_loss: 0.2132 - val_accuracy: 0.9383\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1865 - accuracy: 0.9462 - val_loss: 0.2107 - val_accuracy: 0.9392\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1835 - accuracy: 0.9475 - val_loss: 0.2078 - val_accuracy: 0.9404\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.1804 - accuracy: 0.9481 - val_loss: 0.2066 - val_accuracy: 0.9406\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1777 - accuracy: 0.9490 - val_loss: 0.2036 - val_accuracy: 0.9406\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1749 - accuracy: 0.9495 - val_loss: 0.2023 - val_accuracy: 0.9427\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.1724 - accuracy: 0.9503 - val_loss: 0.1990 - val_accuracy: 0.9420\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1695 - accuracy: 0.9514 - val_loss: 0.1971 - val_accuracy: 0.9427\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.1672 - accuracy: 0.9523 - val_loss: 0.1954 - val_accuracy: 0.9434\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1647 - accuracy: 0.9528 - val_loss: 0.1934 - val_accuracy: 0.9438\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1623 - accuracy: 0.9533 - val_loss: 0.1916 - val_accuracy: 0.9438\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1599 - accuracy: 0.9541 - val_loss: 0.1906 - val_accuracy: 0.9448\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1577 - accuracy: 0.9551 - val_loss: 0.1876 - val_accuracy: 0.9450\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1554 - accuracy: 0.9553 - val_loss: 0.1862 - val_accuracy: 0.9457\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1531 - accuracy: 0.9563 - val_loss: 0.1842 - val_accuracy: 0.9474\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1509 - accuracy: 0.9561 - val_loss: 0.1828 - val_accuracy: 0.9461\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1489 - accuracy: 0.9573 - val_loss: 0.1812 - val_accuracy: 0.9466\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1467 - accuracy: 0.9579 - val_loss: 0.1799 - val_accuracy: 0.9481\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1448 - accuracy: 0.9583 - val_loss: 0.1783 - val_accuracy: 0.9481\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.1427 - accuracy: 0.9595 - val_loss: 0.1766 - val_accuracy: 0.9494\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1409 - accuracy: 0.9600 - val_loss: 0.1763 - val_accuracy: 0.9490\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1388 - accuracy: 0.9603 - val_loss: 0.1741 - val_accuracy: 0.9495\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1370 - accuracy: 0.9613 - val_loss: 0.1728 - val_accuracy: 0.9504\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.1351 - accuracy: 0.9618 - val_loss: 0.1718 - val_accuracy: 0.9506\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1331 - accuracy: 0.9617 - val_loss: 0.1704 - val_accuracy: 0.9510\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1315 - accuracy: 0.9626 - val_loss: 0.1686 - val_accuracy: 0.9505\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1298 - accuracy: 0.9629 - val_loss: 0.1679 - val_accuracy: 0.9504\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1280 - accuracy: 0.9633 - val_loss: 0.1671 - val_accuracy: 0.9513\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.1264 - accuracy: 0.9638 - val_loss: 0.1660 - val_accuracy: 0.9523\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1249 - accuracy: 0.9644 - val_loss: 0.1639 - val_accuracy: 0.9520\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1232 - accuracy: 0.9649 - val_loss: 0.1627 - val_accuracy: 0.9524\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1215 - accuracy: 0.9658 - val_loss: 0.1609 - val_accuracy: 0.9524\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.1196 - accuracy: 0.9664 - val_loss: 0.1616 - val_accuracy: 0.9545\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1184 - accuracy: 0.9666 - val_loss: 0.1598 - val_accuracy: 0.9532\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1170 - accuracy: 0.9669 - val_loss: 0.1584 - val_accuracy: 0.9532\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1154 - accuracy: 0.9678 - val_loss: 0.1580 - val_accuracy: 0.9538\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1141 - accuracy: 0.9678 - val_loss: 0.1565 - val_accuracy: 0.9542\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1124 - accuracy: 0.9678 - val_loss: 0.1551 - val_accuracy: 0.9541\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1110 - accuracy: 0.9684 - val_loss: 0.1554 - val_accuracy: 0.9544\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1095 - accuracy: 0.9690 - val_loss: 0.1533 - val_accuracy: 0.9554\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1082 - accuracy: 0.9692 - val_loss: 0.1521 - val_accuracy: 0.9557\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1068 - accuracy: 0.9701 - val_loss: 0.1511 - val_accuracy: 0.9557\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1055 - accuracy: 0.9702 - val_loss: 0.1518 - val_accuracy: 0.9551\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1042 - accuracy: 0.9709 - val_loss: 0.1495 - val_accuracy: 0.9561\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1031 - accuracy: 0.9714 - val_loss: 0.1488 - val_accuracy: 0.9554\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1019 - accuracy: 0.9716 - val_loss: 0.1482 - val_accuracy: 0.9567\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1006 - accuracy: 0.9719 - val_loss: 0.1471 - val_accuracy: 0.9559\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0993 - accuracy: 0.9724 - val_loss: 0.1470 - val_accuracy: 0.9561\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0982 - accuracy: 0.9731 - val_loss: 0.1456 - val_accuracy: 0.9563\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0969 - accuracy: 0.9729 - val_loss: 0.1450 - val_accuracy: 0.9574\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0957 - accuracy: 0.9737 - val_loss: 0.1451 - val_accuracy: 0.9580\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0947 - accuracy: 0.9739 - val_loss: 0.1439 - val_accuracy: 0.9582\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0935 - accuracy: 0.9746 - val_loss: 0.1426 - val_accuracy: 0.9574\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0924 - accuracy: 0.9748 - val_loss: 0.1423 - val_accuracy: 0.9574\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0914 - accuracy: 0.9747 - val_loss: 0.1416 - val_accuracy: 0.9575\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0903 - accuracy: 0.9751 - val_loss: 0.1403 - val_accuracy: 0.9589\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0892 - accuracy: 0.9753 - val_loss: 0.1394 - val_accuracy: 0.9586\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0881 - accuracy: 0.9757 - val_loss: 0.1396 - val_accuracy: 0.9590\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0874 - accuracy: 0.9761 - val_loss: 0.1390 - val_accuracy: 0.9588\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0862 - accuracy: 0.9765 - val_loss: 0.1379 - val_accuracy: 0.9590\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0852 - accuracy: 0.9767 - val_loss: 0.1370 - val_accuracy: 0.9597\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0843 - accuracy: 0.9770 - val_loss: 0.1362 - val_accuracy: 0.9597\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0833 - accuracy: 0.9772 - val_loss: 0.1359 - val_accuracy: 0.9600\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0824 - accuracy: 0.9773 - val_loss: 0.1352 - val_accuracy: 0.9600\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0813 - accuracy: 0.9778 - val_loss: 0.1359 - val_accuracy: 0.9600\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0805 - accuracy: 0.9782 - val_loss: 0.1351 - val_accuracy: 0.9613\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0795 - accuracy: 0.9790 - val_loss: 0.1356 - val_accuracy: 0.9606\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0788 - accuracy: 0.9790 - val_loss: 0.1340 - val_accuracy: 0.9609\n",
      "20000/20000 [==============================] - 1s 62us/sample - loss: 0.1333 - accuracy: 0.9609\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 54us/sample - loss: 2.3083 - accuracy: 0.0944 - val_loss: 2.3035 - val_accuracy: 0.0970\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.2973 - accuracy: 0.1021 - val_loss: 2.2926 - val_accuracy: 0.1067\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 2.2869 - accuracy: 0.1113 - val_loss: 2.2817 - val_accuracy: 0.1173\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.2762 - accuracy: 0.1216 - val_loss: 2.2703 - val_accuracy: 0.1297\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.2649 - accuracy: 0.1349 - val_loss: 2.2580 - val_accuracy: 0.1435\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 2.2525 - accuracy: 0.1498 - val_loss: 2.2445 - val_accuracy: 0.1567\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.2389 - accuracy: 0.1618 - val_loss: 2.2296 - val_accuracy: 0.1654\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.2239 - accuracy: 0.1714 - val_loss: 2.2131 - val_accuracy: 0.1737\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.2074 - accuracy: 0.1804 - val_loss: 2.1951 - val_accuracy: 0.1813\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.1894 - accuracy: 0.1896 - val_loss: 2.1758 - val_accuracy: 0.1885\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.1703 - accuracy: 0.1996 - val_loss: 2.1553 - val_accuracy: 0.2005\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 2.1501 - accuracy: 0.2120 - val_loss: 2.1339 - val_accuracy: 0.2164\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.1288 - accuracy: 0.2301 - val_loss: 2.1114 - val_accuracy: 0.2361\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 2.1065 - accuracy: 0.2500 - val_loss: 2.0877 - val_accuracy: 0.2616\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.0829 - accuracy: 0.2772 - val_loss: 2.0627 - val_accuracy: 0.2895\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 2.0579 - accuracy: 0.3033 - val_loss: 2.0361 - val_accuracy: 0.3195\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.0313 - accuracy: 0.3306 - val_loss: 2.0079 - val_accuracy: 0.3530\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.0030 - accuracy: 0.3617 - val_loss: 1.9779 - val_accuracy: 0.3808\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.9729 - accuracy: 0.3872 - val_loss: 1.9460 - val_accuracy: 0.4078\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.9407 - accuracy: 0.4120 - val_loss: 1.9119 - val_accuracy: 0.4334\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.9062 - accuracy: 0.4347 - val_loss: 1.8753 - val_accuracy: 0.4552\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.8691 - accuracy: 0.4541 - val_loss: 1.8359 - val_accuracy: 0.4765\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.8292 - accuracy: 0.4730 - val_loss: 1.7934 - val_accuracy: 0.4969\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 1.7861 - accuracy: 0.4916 - val_loss: 1.7476 - val_accuracy: 0.5167\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.7397 - accuracy: 0.5115 - val_loss: 1.6982 - val_accuracy: 0.5397\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.6897 - accuracy: 0.5319 - val_loss: 1.6452 - val_accuracy: 0.5605\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.6362 - accuracy: 0.5515 - val_loss: 1.5885 - val_accuracy: 0.5846\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.5794 - accuracy: 0.5738 - val_loss: 1.5286 - val_accuracy: 0.6087\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.5195 - accuracy: 0.5935 - val_loss: 1.4660 - val_accuracy: 0.6336\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.4575 - accuracy: 0.6163 - val_loss: 1.4011 - val_accuracy: 0.6550\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.3941 - accuracy: 0.6384 - val_loss: 1.3354 - val_accuracy: 0.6744\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.3305 - accuracy: 0.6571 - val_loss: 1.2703 - val_accuracy: 0.6949\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.2683 - accuracy: 0.6748 - val_loss: 1.2072 - val_accuracy: 0.7120\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.2087 - accuracy: 0.6895 - val_loss: 1.1472 - val_accuracy: 0.7262\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 1.1528 - accuracy: 0.7030 - val_loss: 1.0915 - val_accuracy: 0.7371\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.1011 - accuracy: 0.7155 - val_loss: 1.0399 - val_accuracy: 0.7474\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.0538 - accuracy: 0.7256 - val_loss: 0.9929 - val_accuracy: 0.7564\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 1.0109 - accuracy: 0.7332 - val_loss: 0.9504 - val_accuracy: 0.7663\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.9718 - accuracy: 0.7423 - val_loss: 0.9116 - val_accuracy: 0.7725\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.9362 - accuracy: 0.7499 - val_loss: 0.8763 - val_accuracy: 0.7794\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.9038 - accuracy: 0.7569 - val_loss: 0.8441 - val_accuracy: 0.7866\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.8741 - accuracy: 0.7633 - val_loss: 0.8147 - val_accuracy: 0.7944\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.8468 - accuracy: 0.7689 - val_loss: 0.7874 - val_accuracy: 0.8019\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.8216 - accuracy: 0.7752 - val_loss: 0.7625 - val_accuracy: 0.8050\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.7984 - accuracy: 0.7807 - val_loss: 0.7398 - val_accuracy: 0.8100\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.7773 - accuracy: 0.7857 - val_loss: 0.7186 - val_accuracy: 0.8163\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 47us/sample - loss: 0.7578 - accuracy: 0.7906 - val_loss: 0.6994 - val_accuracy: 0.8217\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.7398 - accuracy: 0.7955 - val_loss: 0.6814 - val_accuracy: 0.8269\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.7232 - accuracy: 0.7996 - val_loss: 0.6653 - val_accuracy: 0.8290\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.7077 - accuracy: 0.8039 - val_loss: 0.6496 - val_accuracy: 0.8342\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.6932 - accuracy: 0.8086 - val_loss: 0.6356 - val_accuracy: 0.8360\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.6797 - accuracy: 0.8105 - val_loss: 0.6220 - val_accuracy: 0.8381\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.6671 - accuracy: 0.8145 - val_loss: 0.6091 - val_accuracy: 0.8434\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.6551 - accuracy: 0.8173 - val_loss: 0.5975 - val_accuracy: 0.8443\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.6439 - accuracy: 0.8205 - val_loss: 0.5872 - val_accuracy: 0.8464\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.6333 - accuracy: 0.8237 - val_loss: 0.5761 - val_accuracy: 0.8504\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.6231 - accuracy: 0.8268 - val_loss: 0.5664 - val_accuracy: 0.8533\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 0.6136 - accuracy: 0.8296 - val_loss: 0.5568 - val_accuracy: 0.8553\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 0.6044 - accuracy: 0.8317 - val_loss: 0.5475 - val_accuracy: 0.8568\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 46us/sample - loss: 0.5958 - accuracy: 0.8344 - val_loss: 0.5392 - val_accuracy: 0.8594\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5874 - accuracy: 0.8363 - val_loss: 0.5316 - val_accuracy: 0.8611\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.5794 - accuracy: 0.8386 - val_loss: 0.5237 - val_accuracy: 0.8626\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.5719 - accuracy: 0.8407 - val_loss: 0.5162 - val_accuracy: 0.8639\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.5645 - accuracy: 0.8430 - val_loss: 0.5095 - val_accuracy: 0.8652\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.5575 - accuracy: 0.8451 - val_loss: 0.5022 - val_accuracy: 0.8677\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.5507 - accuracy: 0.8466 - val_loss: 0.4957 - val_accuracy: 0.8691\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 2s 48us/sample - loss: 0.5443 - accuracy: 0.8483 - val_loss: 0.4900 - val_accuracy: 0.8700\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.5379 - accuracy: 0.8499 - val_loss: 0.4842 - val_accuracy: 0.8714\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.5317 - accuracy: 0.8508 - val_loss: 0.4778 - val_accuracy: 0.8734\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.5259 - accuracy: 0.8532 - val_loss: 0.4727 - val_accuracy: 0.8741\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.5202 - accuracy: 0.8546 - val_loss: 0.4673 - val_accuracy: 0.8752\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.5147 - accuracy: 0.8559 - val_loss: 0.4624 - val_accuracy: 0.8780\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.5093 - accuracy: 0.8573 - val_loss: 0.4573 - val_accuracy: 0.8788\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.5041 - accuracy: 0.8593 - val_loss: 0.4528 - val_accuracy: 0.8805\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4991 - accuracy: 0.8611 - val_loss: 0.4483 - val_accuracy: 0.8823\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4942 - accuracy: 0.8629 - val_loss: 0.4434 - val_accuracy: 0.8825\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4894 - accuracy: 0.8642 - val_loss: 0.4389 - val_accuracy: 0.8830\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4848 - accuracy: 0.8656 - val_loss: 0.4349 - val_accuracy: 0.8848\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4801 - accuracy: 0.8668 - val_loss: 0.4305 - val_accuracy: 0.8856\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4758 - accuracy: 0.8684 - val_loss: 0.4271 - val_accuracy: 0.8860\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4716 - accuracy: 0.8698 - val_loss: 0.4229 - val_accuracy: 0.8876\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4673 - accuracy: 0.8707 - val_loss: 0.4189 - val_accuracy: 0.8885\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4632 - accuracy: 0.8715 - val_loss: 0.4154 - val_accuracy: 0.8898\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4593 - accuracy: 0.8729 - val_loss: 0.4115 - val_accuracy: 0.8898\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 0.4553 - accuracy: 0.8738 - val_loss: 0.4082 - val_accuracy: 0.8904\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.4517 - accuracy: 0.8747 - val_loss: 0.4051 - val_accuracy: 0.8925\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4480 - accuracy: 0.8761 - val_loss: 0.4016 - val_accuracy: 0.8921\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.4443 - accuracy: 0.8767 - val_loss: 0.3985 - val_accuracy: 0.8941\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.4408 - accuracy: 0.8775 - val_loss: 0.3953 - val_accuracy: 0.8940\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4374 - accuracy: 0.8787 - val_loss: 0.3927 - val_accuracy: 0.8941\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4340 - accuracy: 0.8798 - val_loss: 0.3895 - val_accuracy: 0.8957\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4308 - accuracy: 0.8805 - val_loss: 0.3866 - val_accuracy: 0.8949\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.4275 - accuracy: 0.8813 - val_loss: 0.3840 - val_accuracy: 0.8954\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4244 - accuracy: 0.8825 - val_loss: 0.3813 - val_accuracy: 0.8960\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4214 - accuracy: 0.8828 - val_loss: 0.3786 - val_accuracy: 0.8974\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4184 - accuracy: 0.8838 - val_loss: 0.3757 - val_accuracy: 0.8982\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4155 - accuracy: 0.8842 - val_loss: 0.3736 - val_accuracy: 0.8979\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4127 - accuracy: 0.8852 - val_loss: 0.3710 - val_accuracy: 0.8982\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4099 - accuracy: 0.8858 - val_loss: 0.3686 - val_accuracy: 0.8992\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4072 - accuracy: 0.8869 - val_loss: 0.3663 - val_accuracy: 0.8988\n",
      "20000/20000 [==============================] - 1s 74us/sample - loss: 0.4081 - accuracy: 0.8881\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 63us/sample - loss: 2.3249 - accuracy: 0.0929 - val_loss: 2.3165 - val_accuracy: 0.0885\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 46us/sample - loss: 2.3094 - accuracy: 0.0943 - val_loss: 2.3037 - val_accuracy: 0.0894\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 2.2987 - accuracy: 0.0962 - val_loss: 2.2946 - val_accuracy: 0.0920\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.2905 - accuracy: 0.1011 - val_loss: 2.2870 - val_accuracy: 0.0962\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 46us/sample - loss: 2.2831 - accuracy: 0.1073 - val_loss: 2.2795 - val_accuracy: 0.1026\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 2.2756 - accuracy: 0.1177 - val_loss: 2.2717 - val_accuracy: 0.1170\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 2.2675 - accuracy: 0.1319 - val_loss: 2.2629 - val_accuracy: 0.1379\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.2585 - accuracy: 0.1511 - val_loss: 2.2531 - val_accuracy: 0.1605\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2483 - accuracy: 0.1726 - val_loss: 2.2421 - val_accuracy: 0.1803\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2368 - accuracy: 0.1930 - val_loss: 2.2298 - val_accuracy: 0.1999\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2242 - accuracy: 0.2139 - val_loss: 2.2163 - val_accuracy: 0.2191\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 2.2103 - accuracy: 0.2362 - val_loss: 2.2015 - val_accuracy: 0.2431\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 2.1951 - accuracy: 0.2603 - val_loss: 2.1852 - val_accuracy: 0.2686\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 2.1784 - accuracy: 0.2882 - val_loss: 2.1673 - val_accuracy: 0.2976\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 2.1599 - accuracy: 0.3187 - val_loss: 2.1476 - val_accuracy: 0.3300\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.1396 - accuracy: 0.3488 - val_loss: 2.1259 - val_accuracy: 0.3586\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 51us/sample - loss: 2.1171 - accuracy: 0.3774 - val_loss: 2.1019 - val_accuracy: 0.3870\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 2.0923 - accuracy: 0.4005 - val_loss: 2.0756 - val_accuracy: 0.4079\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 48us/sample - loss: 2.0650 - accuracy: 0.4194 - val_loss: 2.0465 - val_accuracy: 0.4255\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 54us/sample - loss: 2.0348 - accuracy: 0.4355 - val_loss: 2.0144 - val_accuracy: 0.4440\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 50us/sample - loss: 2.0015 - accuracy: 0.4477 - val_loss: 1.9790 - val_accuracy: 0.4566\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.9646 - accuracy: 0.4592 - val_loss: 1.9395 - val_accuracy: 0.4690\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 1.9237 - accuracy: 0.4714 - val_loss: 1.8959 - val_accuracy: 0.4805\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.8785 - accuracy: 0.4838 - val_loss: 1.8477 - val_accuracy: 0.4924\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.8287 - accuracy: 0.4964 - val_loss: 1.7947 - val_accuracy: 0.5073\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 2s 47us/sample - loss: 1.7742 - accuracy: 0.5099 - val_loss: 1.7364 - val_accuracy: 0.5268\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 50us/sample - loss: 1.7150 - accuracy: 0.5258 - val_loss: 1.6732 - val_accuracy: 0.5450\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 1.6516 - accuracy: 0.5441 - val_loss: 1.6060 - val_accuracy: 0.5667\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 1.5849 - accuracy: 0.5663 - val_loss: 1.5356 - val_accuracy: 0.5922\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 1.5157 - accuracy: 0.5895 - val_loss: 1.4631 - val_accuracy: 0.6206\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 1.4451 - accuracy: 0.6148 - val_loss: 1.3896 - val_accuracy: 0.6419\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 1.3741 - accuracy: 0.6400 - val_loss: 1.3158 - val_accuracy: 0.6687\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 1.3036 - accuracy: 0.6631 - val_loss: 1.2432 - val_accuracy: 0.6971\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.2348 - accuracy: 0.6837 - val_loss: 1.1728 - val_accuracy: 0.7214\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.1688 - accuracy: 0.7047 - val_loss: 1.1057 - val_accuracy: 0.7400\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 1.1065 - accuracy: 0.7227 - val_loss: 1.0428 - val_accuracy: 0.7526\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 1.0481 - accuracy: 0.7358 - val_loss: 0.9841 - val_accuracy: 0.7648\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.9944 - accuracy: 0.7490 - val_loss: 0.9304 - val_accuracy: 0.7778\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.9450 - accuracy: 0.7589 - val_loss: 0.8811 - val_accuracy: 0.7904\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.9002 - accuracy: 0.7687 - val_loss: 0.8369 - val_accuracy: 0.7983\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.8596 - accuracy: 0.7769 - val_loss: 0.7966 - val_accuracy: 0.8050\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.8228 - accuracy: 0.7846 - val_loss: 0.7604 - val_accuracy: 0.8104\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.7897 - accuracy: 0.7902 - val_loss: 0.7278 - val_accuracy: 0.8170\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.7598 - accuracy: 0.7960 - val_loss: 0.6988 - val_accuracy: 0.8224\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.7329 - accuracy: 0.8013 - val_loss: 0.6723 - val_accuracy: 0.8276\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.7084 - accuracy: 0.8060 - val_loss: 0.6482 - val_accuracy: 0.8339\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.6863 - accuracy: 0.8118 - val_loss: 0.6270 - val_accuracy: 0.8379\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.6661 - accuracy: 0.8163 - val_loss: 0.6077 - val_accuracy: 0.8399\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.6479 - accuracy: 0.8200 - val_loss: 0.5898 - val_accuracy: 0.8468\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.6314 - accuracy: 0.8233 - val_loss: 0.5744 - val_accuracy: 0.8501\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.6165 - accuracy: 0.8264 - val_loss: 0.5602 - val_accuracy: 0.8528\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.6029 - accuracy: 0.8301 - val_loss: 0.5469 - val_accuracy: 0.8546\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.5904 - accuracy: 0.8328 - val_loss: 0.5352 - val_accuracy: 0.8600\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.5789 - accuracy: 0.8350 - val_loss: 0.5243 - val_accuracy: 0.8615\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.5682 - accuracy: 0.8382 - val_loss: 0.5145 - val_accuracy: 0.8627\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.5583 - accuracy: 0.8403 - val_loss: 0.5055 - val_accuracy: 0.8650\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.5490 - accuracy: 0.8423 - val_loss: 0.4966 - val_accuracy: 0.8670\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.5405 - accuracy: 0.8444 - val_loss: 0.4884 - val_accuracy: 0.8691\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.5324 - accuracy: 0.8467 - val_loss: 0.4814 - val_accuracy: 0.8689\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.5248 - accuracy: 0.8487 - val_loss: 0.4740 - val_accuracy: 0.8717\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.5176 - accuracy: 0.8503 - val_loss: 0.4675 - val_accuracy: 0.8729\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.5109 - accuracy: 0.8529 - val_loss: 0.4613 - val_accuracy: 0.8746\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.5046 - accuracy: 0.8546 - val_loss: 0.4554 - val_accuracy: 0.8755\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4984 - accuracy: 0.8568 - val_loss: 0.4500 - val_accuracy: 0.8765\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4927 - accuracy: 0.8578 - val_loss: 0.4452 - val_accuracy: 0.8765\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4872 - accuracy: 0.8590 - val_loss: 0.4401 - val_accuracy: 0.8784\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4819 - accuracy: 0.8617 - val_loss: 0.4351 - val_accuracy: 0.8794\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4770 - accuracy: 0.8626 - val_loss: 0.4309 - val_accuracy: 0.8800\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.4722 - accuracy: 0.8640 - val_loss: 0.4266 - val_accuracy: 0.8809\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.4676 - accuracy: 0.8653 - val_loss: 0.4225 - val_accuracy: 0.8823\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.4633 - accuracy: 0.8665 - val_loss: 0.4185 - val_accuracy: 0.8826\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4590 - accuracy: 0.8677 - val_loss: 0.4151 - val_accuracy: 0.8827\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4551 - accuracy: 0.8685 - val_loss: 0.4113 - val_accuracy: 0.8842\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.4511 - accuracy: 0.8698 - val_loss: 0.4079 - val_accuracy: 0.8859\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.4473 - accuracy: 0.8708 - val_loss: 0.4049 - val_accuracy: 0.8870\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4437 - accuracy: 0.8716 - val_loss: 0.4015 - val_accuracy: 0.8871\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 0.4402 - accuracy: 0.8726 - val_loss: 0.3987 - val_accuracy: 0.8880\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.4367 - accuracy: 0.8734 - val_loss: 0.3959 - val_accuracy: 0.8889\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4336 - accuracy: 0.8745 - val_loss: 0.3932 - val_accuracy: 0.8906\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4303 - accuracy: 0.8749 - val_loss: 0.3900 - val_accuracy: 0.8917\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4274 - accuracy: 0.8760 - val_loss: 0.3874 - val_accuracy: 0.8915\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4243 - accuracy: 0.8767 - val_loss: 0.3848 - val_accuracy: 0.8930\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4215 - accuracy: 0.8776 - val_loss: 0.3826 - val_accuracy: 0.8926\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.4186 - accuracy: 0.8788 - val_loss: 0.3803 - val_accuracy: 0.8923\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4159 - accuracy: 0.8798 - val_loss: 0.3778 - val_accuracy: 0.8934\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.4133 - accuracy: 0.8802 - val_loss: 0.3755 - val_accuracy: 0.8951\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4107 - accuracy: 0.8814 - val_loss: 0.3733 - val_accuracy: 0.8957\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.4081 - accuracy: 0.8819 - val_loss: 0.3711 - val_accuracy: 0.8960\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.4057 - accuracy: 0.8827 - val_loss: 0.3689 - val_accuracy: 0.8970\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4033 - accuracy: 0.8835 - val_loss: 0.3668 - val_accuracy: 0.8967\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.4009 - accuracy: 0.8845 - val_loss: 0.3647 - val_accuracy: 0.8984\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 2s 53us/sample - loss: 0.3986 - accuracy: 0.8848 - val_loss: 0.3628 - val_accuracy: 0.8982\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 47us/sample - loss: 0.3964 - accuracy: 0.8857 - val_loss: 0.3610 - val_accuracy: 0.8980\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.3942 - accuracy: 0.8866 - val_loss: 0.3594 - val_accuracy: 0.8985\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3921 - accuracy: 0.8867 - val_loss: 0.3575 - val_accuracy: 0.8990\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3901 - accuracy: 0.8873 - val_loss: 0.3556 - val_accuracy: 0.8997\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3880 - accuracy: 0.8887 - val_loss: 0.3540 - val_accuracy: 0.8999\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.3858 - accuracy: 0.8888 - val_loss: 0.3528 - val_accuracy: 0.8999\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.3840 - accuracy: 0.8894 - val_loss: 0.3504 - val_accuracy: 0.9009\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.3821 - accuracy: 0.8898 - val_loss: 0.3486 - val_accuracy: 0.9007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 2s 78us/sample - loss: 0.4016 - accuracy: 0.8850\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 57us/sample - loss: 2.3105 - accuracy: 0.1060 - val_loss: 2.3052 - val_accuracy: 0.1084\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 47us/sample - loss: 2.2972 - accuracy: 0.1156 - val_loss: 2.2928 - val_accuracy: 0.1201\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 2.2850 - accuracy: 0.1315 - val_loss: 2.2811 - val_accuracy: 0.1375\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.2733 - accuracy: 0.1554 - val_loss: 2.2694 - val_accuracy: 0.1708\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 2.2613 - accuracy: 0.1920 - val_loss: 2.2571 - val_accuracy: 0.2081\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.2486 - accuracy: 0.2305 - val_loss: 2.2438 - val_accuracy: 0.2397\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.2346 - accuracy: 0.2625 - val_loss: 2.2292 - val_accuracy: 0.2697\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.2192 - accuracy: 0.2921 - val_loss: 2.2130 - val_accuracy: 0.2955\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.2021 - accuracy: 0.3194 - val_loss: 2.1951 - val_accuracy: 0.3181\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.1834 - accuracy: 0.3417 - val_loss: 2.1754 - val_accuracy: 0.3451\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 2.1627 - accuracy: 0.3636 - val_loss: 2.1536 - val_accuracy: 0.3674\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 2.1398 - accuracy: 0.3827 - val_loss: 2.1294 - val_accuracy: 0.3850\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.1145 - accuracy: 0.3977 - val_loss: 2.1029 - val_accuracy: 0.3994\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.0868 - accuracy: 0.4094 - val_loss: 2.0739 - val_accuracy: 0.4150\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 2.0564 - accuracy: 0.4195 - val_loss: 2.0421 - val_accuracy: 0.4210\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 2.0233 - accuracy: 0.4283 - val_loss: 2.0075 - val_accuracy: 0.4309\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 1.9872 - accuracy: 0.4373 - val_loss: 1.9698 - val_accuracy: 0.4400\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 1.9480 - accuracy: 0.4449 - val_loss: 1.9290 - val_accuracy: 0.4479\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 1.9058 - accuracy: 0.4530 - val_loss: 1.8854 - val_accuracy: 0.4565\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 1.8610 - accuracy: 0.4633 - val_loss: 1.8393 - val_accuracy: 0.4676\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 1.8141 - accuracy: 0.4733 - val_loss: 1.7914 - val_accuracy: 0.4799\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 1.7657 - accuracy: 0.4828 - val_loss: 1.7422 - val_accuracy: 0.4944\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 1.7163 - accuracy: 0.4947 - val_loss: 1.6923 - val_accuracy: 0.5056\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 1.6662 - accuracy: 0.5049 - val_loss: 1.6419 - val_accuracy: 0.5196\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 51us/sample - loss: 1.6160 - accuracy: 0.5182 - val_loss: 1.5912 - val_accuracy: 0.5350\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.5655 - accuracy: 0.5320 - val_loss: 1.5405 - val_accuracy: 0.5447\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.5148 - accuracy: 0.5482 - val_loss: 1.4897 - val_accuracy: 0.5625\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.4640 - accuracy: 0.5657 - val_loss: 1.4387 - val_accuracy: 0.5806\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.4130 - accuracy: 0.5845 - val_loss: 1.3877 - val_accuracy: 0.6014\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 1.3622 - accuracy: 0.6075 - val_loss: 1.3371 - val_accuracy: 0.6230\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 1.3118 - accuracy: 0.6304 - val_loss: 1.2870 - val_accuracy: 0.6444\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 1.2622 - accuracy: 0.6519 - val_loss: 1.2379 - val_accuracy: 0.6644\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 1.2137 - accuracy: 0.6706 - val_loss: 1.1903 - val_accuracy: 0.6833\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 1.1667 - accuracy: 0.6872 - val_loss: 1.1442 - val_accuracy: 0.6976\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 54us/sample - loss: 1.1215 - accuracy: 0.6994 - val_loss: 1.1000 - val_accuracy: 0.7094\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 1.0782 - accuracy: 0.7105 - val_loss: 1.0576 - val_accuracy: 0.7193\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 1.0370 - accuracy: 0.7189 - val_loss: 1.0174 - val_accuracy: 0.7262\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.9981 - accuracy: 0.7283 - val_loss: 0.9797 - val_accuracy: 0.7344\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 0.9617 - accuracy: 0.7368 - val_loss: 0.9447 - val_accuracy: 0.7411\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.9277 - accuracy: 0.7427 - val_loss: 0.9120 - val_accuracy: 0.7483\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.8963 - accuracy: 0.7496 - val_loss: 0.8817 - val_accuracy: 0.7555\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.8672 - accuracy: 0.7542 - val_loss: 0.8540 - val_accuracy: 0.7615\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.8405 - accuracy: 0.7601 - val_loss: 0.8280 - val_accuracy: 0.7664\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.8158 - accuracy: 0.7644 - val_loss: 0.8045 - val_accuracy: 0.7721\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.7932 - accuracy: 0.7693 - val_loss: 0.7827 - val_accuracy: 0.7765\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.7724 - accuracy: 0.7734 - val_loss: 0.7627 - val_accuracy: 0.7824\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.7532 - accuracy: 0.7785 - val_loss: 0.7442 - val_accuracy: 0.7849\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.7354 - accuracy: 0.7816 - val_loss: 0.7270 - val_accuracy: 0.7878\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.7188 - accuracy: 0.7859 - val_loss: 0.7108 - val_accuracy: 0.7915\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.7034 - accuracy: 0.7904 - val_loss: 0.6958 - val_accuracy: 0.7959\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.6890 - accuracy: 0.7945 - val_loss: 0.6820 - val_accuracy: 0.7989\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.6755 - accuracy: 0.7982 - val_loss: 0.6688 - val_accuracy: 0.8023\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.6628 - accuracy: 0.8026 - val_loss: 0.6565 - val_accuracy: 0.8060\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.6508 - accuracy: 0.8060 - val_loss: 0.6448 - val_accuracy: 0.8090\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.6395 - accuracy: 0.8094 - val_loss: 0.6336 - val_accuracy: 0.8121\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6286 - accuracy: 0.8124 - val_loss: 0.6230 - val_accuracy: 0.8161\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.6184 - accuracy: 0.8159 - val_loss: 0.6130 - val_accuracy: 0.8190\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.6086 - accuracy: 0.8195 - val_loss: 0.6036 - val_accuracy: 0.8224\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5992 - accuracy: 0.8218 - val_loss: 0.5941 - val_accuracy: 0.8254\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5902 - accuracy: 0.8253 - val_loss: 0.5853 - val_accuracy: 0.8294\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5816 - accuracy: 0.8275 - val_loss: 0.5769 - val_accuracy: 0.8316\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.5733 - accuracy: 0.8308 - val_loss: 0.5686 - val_accuracy: 0.8342\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.5652 - accuracy: 0.8338 - val_loss: 0.5608 - val_accuracy: 0.8379\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.5575 - accuracy: 0.8362 - val_loss: 0.5532 - val_accuracy: 0.8413\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.5499 - accuracy: 0.8390 - val_loss: 0.5457 - val_accuracy: 0.8432\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.5427 - accuracy: 0.8412 - val_loss: 0.5388 - val_accuracy: 0.8435\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.5357 - accuracy: 0.8446 - val_loss: 0.5317 - val_accuracy: 0.8475\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.5288 - accuracy: 0.8457 - val_loss: 0.5253 - val_accuracy: 0.8500\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.5222 - accuracy: 0.8478 - val_loss: 0.5188 - val_accuracy: 0.8509\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.5158 - accuracy: 0.8502 - val_loss: 0.5128 - val_accuracy: 0.8540\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.5097 - accuracy: 0.8514 - val_loss: 0.5069 - val_accuracy: 0.8559\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.5037 - accuracy: 0.8542 - val_loss: 0.5008 - val_accuracy: 0.8574\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4979 - accuracy: 0.8556 - val_loss: 0.4954 - val_accuracy: 0.8595\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4922 - accuracy: 0.8569 - val_loss: 0.4897 - val_accuracy: 0.8618\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4867 - accuracy: 0.8586 - val_loss: 0.4847 - val_accuracy: 0.8635\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4815 - accuracy: 0.8604 - val_loss: 0.4799 - val_accuracy: 0.8644\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4764 - accuracy: 0.8616 - val_loss: 0.4750 - val_accuracy: 0.8661\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4715 - accuracy: 0.8622 - val_loss: 0.4703 - val_accuracy: 0.8679\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4668 - accuracy: 0.8643 - val_loss: 0.4656 - val_accuracy: 0.8686\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4622 - accuracy: 0.8652 - val_loss: 0.4615 - val_accuracy: 0.8690\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4578 - accuracy: 0.8667 - val_loss: 0.4573 - val_accuracy: 0.8714\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4535 - accuracy: 0.8676 - val_loss: 0.4531 - val_accuracy: 0.8710\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4494 - accuracy: 0.8688 - val_loss: 0.4492 - val_accuracy: 0.8726\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4454 - accuracy: 0.8698 - val_loss: 0.4455 - val_accuracy: 0.8737\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4416 - accuracy: 0.8714 - val_loss: 0.4420 - val_accuracy: 0.8742\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4378 - accuracy: 0.8729 - val_loss: 0.4383 - val_accuracy: 0.8745\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4341 - accuracy: 0.8735 - val_loss: 0.4351 - val_accuracy: 0.8763\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4306 - accuracy: 0.8745 - val_loss: 0.4320 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4272 - accuracy: 0.8755 - val_loss: 0.4288 - val_accuracy: 0.8777\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4239 - accuracy: 0.8770 - val_loss: 0.4256 - val_accuracy: 0.8791\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.4207 - accuracy: 0.8773 - val_loss: 0.4226 - val_accuracy: 0.8789\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4176 - accuracy: 0.8789 - val_loss: 0.4197 - val_accuracy: 0.8795\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4146 - accuracy: 0.8798 - val_loss: 0.4172 - val_accuracy: 0.8794\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4117 - accuracy: 0.8802 - val_loss: 0.4142 - val_accuracy: 0.8810\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.4087 - accuracy: 0.8812 - val_loss: 0.4116 - val_accuracy: 0.8817\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4061 - accuracy: 0.8820 - val_loss: 0.4093 - val_accuracy: 0.8816\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4034 - accuracy: 0.8832 - val_loss: 0.4068 - val_accuracy: 0.8831\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.4008 - accuracy: 0.8838 - val_loss: 0.4044 - val_accuracy: 0.8840\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3983 - accuracy: 0.8846 - val_loss: 0.4021 - val_accuracy: 0.8845\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3958 - accuracy: 0.8857 - val_loss: 0.4001 - val_accuracy: 0.8851\n",
      "20000/20000 [==============================] - 1s 61us/sample - loss: 0.3868 - accuracy: 0.8871\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 2.0479 - accuracy: 0.3568 - val_loss: 1.5576 - val_accuracy: 0.6200\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.1126 - accuracy: 0.7115 - val_loss: 0.7150 - val_accuracy: 0.8285\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.6332 - accuracy: 0.8241 - val_loss: 0.4801 - val_accuracy: 0.8725\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.4912 - accuracy: 0.8565 - val_loss: 0.4028 - val_accuracy: 0.8891\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4316 - accuracy: 0.8730 - val_loss: 0.3667 - val_accuracy: 0.8967\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3970 - accuracy: 0.8830 - val_loss: 0.3407 - val_accuracy: 0.9031\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3728 - accuracy: 0.8901 - val_loss: 0.3239 - val_accuracy: 0.9071\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3536 - accuracy: 0.8962 - val_loss: 0.3087 - val_accuracy: 0.9103\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.3388 - accuracy: 0.9004 - val_loss: 0.2991 - val_accuracy: 0.9130\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3258 - accuracy: 0.9045 - val_loss: 0.2867 - val_accuracy: 0.9151\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3146 - accuracy: 0.9075 - val_loss: 0.2775 - val_accuracy: 0.9190\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3038 - accuracy: 0.9112 - val_loss: 0.2747 - val_accuracy: 0.9185\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2950 - accuracy: 0.9140 - val_loss: 0.2652 - val_accuracy: 0.9218\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2865 - accuracy: 0.9160 - val_loss: 0.2567 - val_accuracy: 0.9233\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2784 - accuracy: 0.9192 - val_loss: 0.2521 - val_accuracy: 0.9255\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2711 - accuracy: 0.9208 - val_loss: 0.2460 - val_accuracy: 0.9271\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2640 - accuracy: 0.9233 - val_loss: 0.2405 - val_accuracy: 0.9285\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2577 - accuracy: 0.9257 - val_loss: 0.2350 - val_accuracy: 0.9310\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2513 - accuracy: 0.9269 - val_loss: 0.2305 - val_accuracy: 0.9323\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2452 - accuracy: 0.9297 - val_loss: 0.2248 - val_accuracy: 0.9345\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2390 - accuracy: 0.9307 - val_loss: 0.2213 - val_accuracy: 0.9369\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2334 - accuracy: 0.9335 - val_loss: 0.2188 - val_accuracy: 0.9359\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2286 - accuracy: 0.9338 - val_loss: 0.2137 - val_accuracy: 0.9360\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2234 - accuracy: 0.9350 - val_loss: 0.2090 - val_accuracy: 0.9404\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2183 - accuracy: 0.9376 - val_loss: 0.2070 - val_accuracy: 0.9409\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2141 - accuracy: 0.9384 - val_loss: 0.2047 - val_accuracy: 0.9426\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2099 - accuracy: 0.9398 - val_loss: 0.1995 - val_accuracy: 0.9421\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2061 - accuracy: 0.9404 - val_loss: 0.1970 - val_accuracy: 0.9442\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2018 - accuracy: 0.9418 - val_loss: 0.1958 - val_accuracy: 0.9449\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1982 - accuracy: 0.9433 - val_loss: 0.1913 - val_accuracy: 0.9449\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1937 - accuracy: 0.9442 - val_loss: 0.1934 - val_accuracy: 0.9441\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1906 - accuracy: 0.9453 - val_loss: 0.1874 - val_accuracy: 0.9471\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1872 - accuracy: 0.9464 - val_loss: 0.1851 - val_accuracy: 0.9481\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1843 - accuracy: 0.9471 - val_loss: 0.1818 - val_accuracy: 0.9489\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1807 - accuracy: 0.9487 - val_loss: 0.1814 - val_accuracy: 0.9475\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1776 - accuracy: 0.9491 - val_loss: 0.1807 - val_accuracy: 0.9491\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1746 - accuracy: 0.9499 - val_loss: 0.1766 - val_accuracy: 0.9501\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1719 - accuracy: 0.9505 - val_loss: 0.1786 - val_accuracy: 0.9486\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1695 - accuracy: 0.9505 - val_loss: 0.1754 - val_accuracy: 0.9504\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1664 - accuracy: 0.9521 - val_loss: 0.1743 - val_accuracy: 0.9513\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1637 - accuracy: 0.9532 - val_loss: 0.1700 - val_accuracy: 0.9519\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1614 - accuracy: 0.9547 - val_loss: 0.1708 - val_accuracy: 0.9523\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1586 - accuracy: 0.9551 - val_loss: 0.1670 - val_accuracy: 0.9535\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1570 - accuracy: 0.9553 - val_loss: 0.1669 - val_accuracy: 0.9535\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1539 - accuracy: 0.9563 - val_loss: 0.1661 - val_accuracy: 0.9548\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1516 - accuracy: 0.9563 - val_loss: 0.1660 - val_accuracy: 0.9513\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1497 - accuracy: 0.9567 - val_loss: 0.1617 - val_accuracy: 0.9546\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1470 - accuracy: 0.9577 - val_loss: 0.1611 - val_accuracy: 0.9544\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1450 - accuracy: 0.9591 - val_loss: 0.1604 - val_accuracy: 0.9539\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1429 - accuracy: 0.9591 - val_loss: 0.1591 - val_accuracy: 0.9555\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1410 - accuracy: 0.9603 - val_loss: 0.1585 - val_accuracy: 0.9549\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1394 - accuracy: 0.9603 - val_loss: 0.1570 - val_accuracy: 0.9565\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1372 - accuracy: 0.9607 - val_loss: 0.1554 - val_accuracy: 0.9560\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1356 - accuracy: 0.9621 - val_loss: 0.1546 - val_accuracy: 0.9563\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1331 - accuracy: 0.9617 - val_loss: 0.1542 - val_accuracy: 0.9560\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1317 - accuracy: 0.9627 - val_loss: 0.1535 - val_accuracy: 0.9565\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1300 - accuracy: 0.9628 - val_loss: 0.1516 - val_accuracy: 0.9569\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1284 - accuracy: 0.9637 - val_loss: 0.1507 - val_accuracy: 0.9584\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1265 - accuracy: 0.9637 - val_loss: 0.1491 - val_accuracy: 0.9584\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1249 - accuracy: 0.9644 - val_loss: 0.1492 - val_accuracy: 0.9579\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1231 - accuracy: 0.9655 - val_loss: 0.1476 - val_accuracy: 0.9584\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1219 - accuracy: 0.9656 - val_loss: 0.1486 - val_accuracy: 0.9595\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1201 - accuracy: 0.9662 - val_loss: 0.1464 - val_accuracy: 0.9591\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1187 - accuracy: 0.9660 - val_loss: 0.1475 - val_accuracy: 0.9582\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1174 - accuracy: 0.9668 - val_loss: 0.1456 - val_accuracy: 0.9589\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1162 - accuracy: 0.9668 - val_loss: 0.1451 - val_accuracy: 0.9596\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1146 - accuracy: 0.9676 - val_loss: 0.1447 - val_accuracy: 0.9601\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.1132 - accuracy: 0.9675 - val_loss: 0.1430 - val_accuracy: 0.9597\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1120 - accuracy: 0.9679 - val_loss: 0.1452 - val_accuracy: 0.9594\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1106 - accuracy: 0.9684 - val_loss: 0.1432 - val_accuracy: 0.9599\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1096 - accuracy: 0.9690 - val_loss: 0.1424 - val_accuracy: 0.9609\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1084 - accuracy: 0.9682 - val_loss: 0.1415 - val_accuracy: 0.9614\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1069 - accuracy: 0.9694 - val_loss: 0.1424 - val_accuracy: 0.9604\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1055 - accuracy: 0.9697 - val_loss: 0.1475 - val_accuracy: 0.9559\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1049 - accuracy: 0.9698 - val_loss: 0.1446 - val_accuracy: 0.9604\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1029 - accuracy: 0.9705 - val_loss: 0.1414 - val_accuracy: 0.9601\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1019 - accuracy: 0.9712 - val_loss: 0.1412 - val_accuracy: 0.9613\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1008 - accuracy: 0.9714 - val_loss: 0.1417 - val_accuracy: 0.9600\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0997 - accuracy: 0.9710 - val_loss: 0.1410 - val_accuracy: 0.9614\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0987 - accuracy: 0.9719 - val_loss: 0.1400 - val_accuracy: 0.9611\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0977 - accuracy: 0.9713 - val_loss: 0.1394 - val_accuracy: 0.9614\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0960 - accuracy: 0.9727 - val_loss: 0.1423 - val_accuracy: 0.9611\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0957 - accuracy: 0.9718 - val_loss: 0.1384 - val_accuracy: 0.9614\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0947 - accuracy: 0.9724 - val_loss: 0.1384 - val_accuracy: 0.9616\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0935 - accuracy: 0.9730 - val_loss: 0.1369 - val_accuracy: 0.9604\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0921 - accuracy: 0.9737 - val_loss: 0.1410 - val_accuracy: 0.9625\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0908 - accuracy: 0.9743 - val_loss: 0.1403 - val_accuracy: 0.9604\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0905 - accuracy: 0.9745 - val_loss: 0.1363 - val_accuracy: 0.9628\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0897 - accuracy: 0.9742 - val_loss: 0.1370 - val_accuracy: 0.9621\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0882 - accuracy: 0.9751 - val_loss: 0.1381 - val_accuracy: 0.9634\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0874 - accuracy: 0.9745 - val_loss: 0.1363 - val_accuracy: 0.9628\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0864 - accuracy: 0.9751 - val_loss: 0.1368 - val_accuracy: 0.9617\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.0854 - accuracy: 0.9760 - val_loss: 0.1383 - val_accuracy: 0.9622\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0851 - accuracy: 0.9760 - val_loss: 0.1359 - val_accuracy: 0.9604\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0837 - accuracy: 0.9755 - val_loss: 0.1403 - val_accuracy: 0.9594\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0829 - accuracy: 0.9766 - val_loss: 0.1365 - val_accuracy: 0.9625\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0820 - accuracy: 0.9766 - val_loss: 0.1408 - val_accuracy: 0.9595\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0810 - accuracy: 0.9767 - val_loss: 0.1342 - val_accuracy: 0.9613\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0799 - accuracy: 0.9773 - val_loss: 0.1354 - val_accuracy: 0.9631\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0792 - accuracy: 0.9773 - val_loss: 0.1356 - val_accuracy: 0.9628\n",
      "20000/20000 [==============================] - 1s 59us/sample - loss: 0.1444 - accuracy: 0.9589\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 2.1479 - accuracy: 0.3328 - val_loss: 1.9050 - val_accuracy: 0.4832\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 1.4490 - accuracy: 0.6265 - val_loss: 0.9300 - val_accuracy: 0.7768\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.7695 - accuracy: 0.7897 - val_loss: 0.5828 - val_accuracy: 0.8411\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.5558 - accuracy: 0.8450 - val_loss: 0.4547 - val_accuracy: 0.8727\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.4582 - accuracy: 0.8696 - val_loss: 0.3889 - val_accuracy: 0.8904\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4036 - accuracy: 0.8832 - val_loss: 0.3548 - val_accuracy: 0.8979\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3691 - accuracy: 0.8939 - val_loss: 0.3297 - val_accuracy: 0.9050\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.3450 - accuracy: 0.9010 - val_loss: 0.3123 - val_accuracy: 0.9089\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3266 - accuracy: 0.9060 - val_loss: 0.2962 - val_accuracy: 0.9145\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.3117 - accuracy: 0.9106 - val_loss: 0.2856 - val_accuracy: 0.9164\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2996 - accuracy: 0.9137 - val_loss: 0.2755 - val_accuracy: 0.9197\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 37us/sample - loss: 0.2890 - accuracy: 0.9166 - val_loss: 0.2681 - val_accuracy: 0.9221\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 38us/sample - loss: 0.2791 - accuracy: 0.9188 - val_loss: 0.2619 - val_accuracy: 0.9239\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.2713 - accuracy: 0.9220 - val_loss: 0.2548 - val_accuracy: 0.9246\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2633 - accuracy: 0.9242 - val_loss: 0.2471 - val_accuracy: 0.9279\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2566 - accuracy: 0.9254 - val_loss: 0.2435 - val_accuracy: 0.9298\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2499 - accuracy: 0.9275 - val_loss: 0.2394 - val_accuracy: 0.9291\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2432 - accuracy: 0.9301 - val_loss: 0.2337 - val_accuracy: 0.9301\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2372 - accuracy: 0.9313 - val_loss: 0.2304 - val_accuracy: 0.9331\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2312 - accuracy: 0.9325 - val_loss: 0.2235 - val_accuracy: 0.9361\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2260 - accuracy: 0.9339 - val_loss: 0.2189 - val_accuracy: 0.9369\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2209 - accuracy: 0.9352 - val_loss: 0.2155 - val_accuracy: 0.9385\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2151 - accuracy: 0.9367 - val_loss: 0.2179 - val_accuracy: 0.9371\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2107 - accuracy: 0.9382 - val_loss: 0.2105 - val_accuracy: 0.9400\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2062 - accuracy: 0.9397 - val_loss: 0.2042 - val_accuracy: 0.9416\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2020 - accuracy: 0.9414 - val_loss: 0.2010 - val_accuracy: 0.9424\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1975 - accuracy: 0.9424 - val_loss: 0.1985 - val_accuracy: 0.9426\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1932 - accuracy: 0.9441 - val_loss: 0.1972 - val_accuracy: 0.9431\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1893 - accuracy: 0.9456 - val_loss: 0.1943 - val_accuracy: 0.9452\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1852 - accuracy: 0.9467 - val_loss: 0.1896 - val_accuracy: 0.9455\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1817 - accuracy: 0.9478 - val_loss: 0.1879 - val_accuracy: 0.9465\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1779 - accuracy: 0.9478 - val_loss: 0.1848 - val_accuracy: 0.9469\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1747 - accuracy: 0.9494 - val_loss: 0.1845 - val_accuracy: 0.9464\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1712 - accuracy: 0.9503 - val_loss: 0.1831 - val_accuracy: 0.9469\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1683 - accuracy: 0.9511 - val_loss: 0.1805 - val_accuracy: 0.9488\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1649 - accuracy: 0.9517 - val_loss: 0.1779 - val_accuracy: 0.9495\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1619 - accuracy: 0.9528 - val_loss: 0.1744 - val_accuracy: 0.9499\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1591 - accuracy: 0.9535 - val_loss: 0.1733 - val_accuracy: 0.9495\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1564 - accuracy: 0.9540 - val_loss: 0.1732 - val_accuracy: 0.9520\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1534 - accuracy: 0.9559 - val_loss: 0.1708 - val_accuracy: 0.9514\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1508 - accuracy: 0.9566 - val_loss: 0.1703 - val_accuracy: 0.9520\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1487 - accuracy: 0.9568 - val_loss: 0.1687 - val_accuracy: 0.9513\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1455 - accuracy: 0.9574 - val_loss: 0.1665 - val_accuracy: 0.9546\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1433 - accuracy: 0.9579 - val_loss: 0.1657 - val_accuracy: 0.9548\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1410 - accuracy: 0.9593 - val_loss: 0.1653 - val_accuracy: 0.9523\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1390 - accuracy: 0.9601 - val_loss: 0.1636 - val_accuracy: 0.9551\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1363 - accuracy: 0.9600 - val_loss: 0.1630 - val_accuracy: 0.9545\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1347 - accuracy: 0.9606 - val_loss: 0.1608 - val_accuracy: 0.9536\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1324 - accuracy: 0.9606 - val_loss: 0.1602 - val_accuracy: 0.9551\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1301 - accuracy: 0.9616 - val_loss: 0.1593 - val_accuracy: 0.9559\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1287 - accuracy: 0.9623 - val_loss: 0.1573 - val_accuracy: 0.9554\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1266 - accuracy: 0.9627 - val_loss: 0.1567 - val_accuracy: 0.9546\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1245 - accuracy: 0.9635 - val_loss: 0.1596 - val_accuracy: 0.9548\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1225 - accuracy: 0.9641 - val_loss: 0.1583 - val_accuracy: 0.9565\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1207 - accuracy: 0.9645 - val_loss: 0.1558 - val_accuracy: 0.9571\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1196 - accuracy: 0.9653 - val_loss: 0.1553 - val_accuracy: 0.9563\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1169 - accuracy: 0.9659 - val_loss: 0.1551 - val_accuracy: 0.9571\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1152 - accuracy: 0.9669 - val_loss: 0.1526 - val_accuracy: 0.9578\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1142 - accuracy: 0.9667 - val_loss: 0.1532 - val_accuracy: 0.9579\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1127 - accuracy: 0.9670 - val_loss: 0.1527 - val_accuracy: 0.9565\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1110 - accuracy: 0.9678 - val_loss: 0.1514 - val_accuracy: 0.9582\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1098 - accuracy: 0.9691 - val_loss: 0.1534 - val_accuracy: 0.9574\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1078 - accuracy: 0.9687 - val_loss: 0.1555 - val_accuracy: 0.9559\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1068 - accuracy: 0.9685 - val_loss: 0.1529 - val_accuracy: 0.9571\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1053 - accuracy: 0.9694 - val_loss: 0.1495 - val_accuracy: 0.9591\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1038 - accuracy: 0.9692 - val_loss: 0.1485 - val_accuracy: 0.9584\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1025 - accuracy: 0.9703 - val_loss: 0.1521 - val_accuracy: 0.9572\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1011 - accuracy: 0.9705 - val_loss: 0.1503 - val_accuracy: 0.9596\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0999 - accuracy: 0.9712 - val_loss: 0.1507 - val_accuracy: 0.9585\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0983 - accuracy: 0.9714 - val_loss: 0.1467 - val_accuracy: 0.9589\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0977 - accuracy: 0.9716 - val_loss: 0.1485 - val_accuracy: 0.9595\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0958 - accuracy: 0.9718 - val_loss: 0.1470 - val_accuracy: 0.9594\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0945 - accuracy: 0.9731 - val_loss: 0.1468 - val_accuracy: 0.9596\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0936 - accuracy: 0.9730 - val_loss: 0.1462 - val_accuracy: 0.9603\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0923 - accuracy: 0.9733 - val_loss: 0.1462 - val_accuracy: 0.9601\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0911 - accuracy: 0.9740 - val_loss: 0.1461 - val_accuracy: 0.9591\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0899 - accuracy: 0.9742 - val_loss: 0.1468 - val_accuracy: 0.9599\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0886 - accuracy: 0.9737 - val_loss: 0.1448 - val_accuracy: 0.9590\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0877 - accuracy: 0.9744 - val_loss: 0.1458 - val_accuracy: 0.9601\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0866 - accuracy: 0.9753 - val_loss: 0.1440 - val_accuracy: 0.9605\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.1472 - val_accuracy: 0.9590\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0850 - accuracy: 0.9760 - val_loss: 0.1446 - val_accuracy: 0.9611\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0834 - accuracy: 0.9760 - val_loss: 0.1446 - val_accuracy: 0.9605\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0824 - accuracy: 0.9762 - val_loss: 0.1439 - val_accuracy: 0.9607\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0813 - accuracy: 0.9765 - val_loss: 0.1447 - val_accuracy: 0.9601\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0803 - accuracy: 0.9771 - val_loss: 0.1436 - val_accuracy: 0.9615\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0791 - accuracy: 0.9773 - val_loss: 0.1444 - val_accuracy: 0.9614\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0784 - accuracy: 0.9778 - val_loss: 0.1441 - val_accuracy: 0.9613\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0777 - accuracy: 0.9769 - val_loss: 0.1428 - val_accuracy: 0.9615\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.1439 - val_accuracy: 0.9616\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0759 - accuracy: 0.9773 - val_loss: 0.1457 - val_accuracy: 0.9609\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0745 - accuracy: 0.9783 - val_loss: 0.1447 - val_accuracy: 0.9615\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0736 - accuracy: 0.9787 - val_loss: 0.1423 - val_accuracy: 0.9613\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0730 - accuracy: 0.9786 - val_loss: 0.1423 - val_accuracy: 0.9615\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0719 - accuracy: 0.9791 - val_loss: 0.1444 - val_accuracy: 0.9619\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0709 - accuracy: 0.9795 - val_loss: 0.1432 - val_accuracy: 0.9622\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0701 - accuracy: 0.9798 - val_loss: 0.1428 - val_accuracy: 0.9622\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.0694 - accuracy: 0.9797 - val_loss: 0.1442 - val_accuracy: 0.9617\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0688 - accuracy: 0.9803 - val_loss: 0.1423 - val_accuracy: 0.9614\n",
      "20000/20000 [==============================] - 1s 53us/sample - loss: 0.1635 - accuracy: 0.9538\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 2.0554 - accuracy: 0.3099 - val_loss: 1.6815 - val_accuracy: 0.5665\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 1.1392 - accuracy: 0.7109 - val_loss: 0.7506 - val_accuracy: 0.7893\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.6122 - accuracy: 0.8288 - val_loss: 0.5249 - val_accuracy: 0.8521\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.4758 - accuracy: 0.8647 - val_loss: 0.4406 - val_accuracy: 0.8749\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.4152 - accuracy: 0.8813 - val_loss: 0.4001 - val_accuracy: 0.8860\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3780 - accuracy: 0.8933 - val_loss: 0.3690 - val_accuracy: 0.8944\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3525 - accuracy: 0.8989 - val_loss: 0.3488 - val_accuracy: 0.8978\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.3322 - accuracy: 0.9057 - val_loss: 0.3335 - val_accuracy: 0.9026\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.3160 - accuracy: 0.9104 - val_loss: 0.3209 - val_accuracy: 0.9079\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.3023 - accuracy: 0.9133 - val_loss: 0.3103 - val_accuracy: 0.9094\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2899 - accuracy: 0.9169 - val_loss: 0.2993 - val_accuracy: 0.9151\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2792 - accuracy: 0.9194 - val_loss: 0.2958 - val_accuracy: 0.9160\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2689 - accuracy: 0.9232 - val_loss: 0.2852 - val_accuracy: 0.9191\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2597 - accuracy: 0.9247 - val_loss: 0.2779 - val_accuracy: 0.9201\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2514 - accuracy: 0.9272 - val_loss: 0.2691 - val_accuracy: 0.9212\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2436 - accuracy: 0.9301 - val_loss: 0.2614 - val_accuracy: 0.9247\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2358 - accuracy: 0.9317 - val_loss: 0.2555 - val_accuracy: 0.9276\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2293 - accuracy: 0.9345 - val_loss: 0.2485 - val_accuracy: 0.9293\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2224 - accuracy: 0.9358 - val_loss: 0.2429 - val_accuracy: 0.9298\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2164 - accuracy: 0.9370 - val_loss: 0.2393 - val_accuracy: 0.9304\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2103 - accuracy: 0.9394 - val_loss: 0.2346 - val_accuracy: 0.9333\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.2046 - accuracy: 0.9413 - val_loss: 0.2336 - val_accuracy: 0.9304\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1994 - accuracy: 0.9420 - val_loss: 0.2257 - val_accuracy: 0.9336\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 29us/sample - loss: 0.1944 - accuracy: 0.9436 - val_loss: 0.2253 - val_accuracy: 0.9342\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1901 - accuracy: 0.9444 - val_loss: 0.2184 - val_accuracy: 0.9356\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1856 - accuracy: 0.9462 - val_loss: 0.2154 - val_accuracy: 0.9369\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1811 - accuracy: 0.9473 - val_loss: 0.2172 - val_accuracy: 0.9377\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1772 - accuracy: 0.9481 - val_loss: 0.2087 - val_accuracy: 0.9390\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1732 - accuracy: 0.9494 - val_loss: 0.2061 - val_accuracy: 0.9388\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1693 - accuracy: 0.9504 - val_loss: 0.2055 - val_accuracy: 0.9392\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1662 - accuracy: 0.9516 - val_loss: 0.2027 - val_accuracy: 0.9419\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1623 - accuracy: 0.9529 - val_loss: 0.1975 - val_accuracy: 0.9421\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1594 - accuracy: 0.9528 - val_loss: 0.1994 - val_accuracy: 0.9416\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1563 - accuracy: 0.9542 - val_loss: 0.1932 - val_accuracy: 0.9434\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1531 - accuracy: 0.9549 - val_loss: 0.1917 - val_accuracy: 0.9450\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1506 - accuracy: 0.9561 - val_loss: 0.1900 - val_accuracy: 0.9452\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1471 - accuracy: 0.9570 - val_loss: 0.1899 - val_accuracy: 0.9455\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1448 - accuracy: 0.9578 - val_loss: 0.1871 - val_accuracy: 0.9465\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1422 - accuracy: 0.9590 - val_loss: 0.1837 - val_accuracy: 0.9477\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1393 - accuracy: 0.9593 - val_loss: 0.1821 - val_accuracy: 0.9480\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 1s 30us/sample - loss: 0.1376 - accuracy: 0.9598 - val_loss: 0.1832 - val_accuracy: 0.9479\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1349 - accuracy: 0.9605 - val_loss: 0.1832 - val_accuracy: 0.9473\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1326 - accuracy: 0.9604 - val_loss: 0.1772 - val_accuracy: 0.9492\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1305 - accuracy: 0.9615 - val_loss: 0.1744 - val_accuracy: 0.9501\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.1281 - accuracy: 0.9620 - val_loss: 0.1755 - val_accuracy: 0.9499\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.1264 - accuracy: 0.9628 - val_loss: 0.1740 - val_accuracy: 0.9491\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.1241 - accuracy: 0.9634 - val_loss: 0.1721 - val_accuracy: 0.9504\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.1219 - accuracy: 0.9643 - val_loss: 0.1736 - val_accuracy: 0.9504\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1201 - accuracy: 0.9646 - val_loss: 0.1697 - val_accuracy: 0.9510\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1179 - accuracy: 0.9655 - val_loss: 0.1716 - val_accuracy: 0.9500\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.1162 - accuracy: 0.9654 - val_loss: 0.1692 - val_accuracy: 0.9524\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1146 - accuracy: 0.9663 - val_loss: 0.1667 - val_accuracy: 0.9520\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.1130 - accuracy: 0.9671 - val_loss: 0.1674 - val_accuracy: 0.9517\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1111 - accuracy: 0.9672 - val_loss: 0.1641 - val_accuracy: 0.9531\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.1092 - accuracy: 0.9677 - val_loss: 0.1667 - val_accuracy: 0.9506\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1078 - accuracy: 0.9689 - val_loss: 0.1643 - val_accuracy: 0.9530\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.1060 - accuracy: 0.9693 - val_loss: 0.1617 - val_accuracy: 0.9536\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.1045 - accuracy: 0.9695 - val_loss: 0.1623 - val_accuracy: 0.9523\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.1029 - accuracy: 0.9698 - val_loss: 0.1611 - val_accuracy: 0.9544\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1014 - accuracy: 0.9703 - val_loss: 0.1602 - val_accuracy: 0.9535\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1003 - accuracy: 0.9707 - val_loss: 0.1606 - val_accuracy: 0.9541\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0982 - accuracy: 0.9716 - val_loss: 0.1583 - val_accuracy: 0.9550\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.0972 - accuracy: 0.9719 - val_loss: 0.1575 - val_accuracy: 0.9542\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.0956 - accuracy: 0.9730 - val_loss: 0.1583 - val_accuracy: 0.9542\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.0943 - accuracy: 0.9721 - val_loss: 0.1579 - val_accuracy: 0.9563\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0932 - accuracy: 0.9726 - val_loss: 0.1555 - val_accuracy: 0.9553\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.0917 - accuracy: 0.9737 - val_loss: 0.1555 - val_accuracy: 0.9557\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.0905 - accuracy: 0.9738 - val_loss: 0.1581 - val_accuracy: 0.9564\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0889 - accuracy: 0.9745 - val_loss: 0.1535 - val_accuracy: 0.9566\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0879 - accuracy: 0.9744 - val_loss: 0.1553 - val_accuracy: 0.9564\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0865 - accuracy: 0.9751 - val_loss: 0.1542 - val_accuracy: 0.9565\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.0858 - accuracy: 0.9761 - val_loss: 0.1533 - val_accuracy: 0.9566\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0843 - accuracy: 0.9755 - val_loss: 0.1562 - val_accuracy: 0.9571\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.0830 - accuracy: 0.9763 - val_loss: 0.1517 - val_accuracy: 0.9567\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.0823 - accuracy: 0.9763 - val_loss: 0.1535 - val_accuracy: 0.9572\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.0809 - accuracy: 0.9769 - val_loss: 0.1515 - val_accuracy: 0.9570\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0801 - accuracy: 0.9771 - val_loss: 0.1532 - val_accuracy: 0.9576\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0788 - accuracy: 0.9782 - val_loss: 0.1533 - val_accuracy: 0.9567\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0774 - accuracy: 0.9778 - val_loss: 0.1503 - val_accuracy: 0.9574\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.0765 - accuracy: 0.9784 - val_loss: 0.1512 - val_accuracy: 0.9574\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.0756 - accuracy: 0.9793 - val_loss: 0.1536 - val_accuracy: 0.9581\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0751 - accuracy: 0.9784 - val_loss: 0.1496 - val_accuracy: 0.9565\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0738 - accuracy: 0.9788 - val_loss: 0.1506 - val_accuracy: 0.9575\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.0732 - accuracy: 0.9792 - val_loss: 0.1513 - val_accuracy: 0.9559\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0717 - accuracy: 0.9793 - val_loss: 0.1504 - val_accuracy: 0.9579\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.0708 - accuracy: 0.9799 - val_loss: 0.1529 - val_accuracy: 0.9572\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0697 - accuracy: 0.9802 - val_loss: 0.1496 - val_accuracy: 0.9578\n",
      "20000/20000 [==============================] - 2s 78us/sample - loss: 0.1508 - accuracy: 0.9581\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 58us/sample - loss: 1.5723 - accuracy: 0.5279 - val_loss: 0.5962 - val_accuracy: 0.8366\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.5170 - accuracy: 0.8449 - val_loss: 0.3683 - val_accuracy: 0.8930\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 44us/sample - loss: 0.3852 - accuracy: 0.8849 - val_loss: 0.2904 - val_accuracy: 0.9170\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 48us/sample - loss: 0.3136 - accuracy: 0.9065 - val_loss: 0.2665 - val_accuracy: 0.9215\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.2705 - accuracy: 0.9194 - val_loss: 0.2166 - val_accuracy: 0.9379\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.2372 - accuracy: 0.9299 - val_loss: 0.1981 - val_accuracy: 0.9406\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.2128 - accuracy: 0.9368 - val_loss: 0.1816 - val_accuracy: 0.9469\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.1959 - accuracy: 0.9421 - val_loss: 0.1753 - val_accuracy: 0.9491\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.1780 - accuracy: 0.9467 - val_loss: 0.1643 - val_accuracy: 0.9534\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.1661 - accuracy: 0.9504 - val_loss: 0.1582 - val_accuracy: 0.9531\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.1555 - accuracy: 0.9532 - val_loss: 0.1584 - val_accuracy: 0.9534\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.1458 - accuracy: 0.9570 - val_loss: 0.1431 - val_accuracy: 0.9586\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.1362 - accuracy: 0.9596 - val_loss: 0.1415 - val_accuracy: 0.9578\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1287 - accuracy: 0.9626 - val_loss: 0.1344 - val_accuracy: 0.9609\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.1219 - accuracy: 0.9630 - val_loss: 0.1313 - val_accuracy: 0.9617\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 0.1144 - accuracy: 0.9651 - val_loss: 0.1414 - val_accuracy: 0.9588\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 45us/sample - loss: 0.1076 - accuracy: 0.9676 - val_loss: 0.1302 - val_accuracy: 0.9615\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.1037 - accuracy: 0.9698 - val_loss: 0.1313 - val_accuracy: 0.9614\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0971 - accuracy: 0.9714 - val_loss: 0.1290 - val_accuracy: 0.9622\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0915 - accuracy: 0.9735 - val_loss: 0.1229 - val_accuracy: 0.9651\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0877 - accuracy: 0.9745 - val_loss: 0.1221 - val_accuracy: 0.9635\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0828 - accuracy: 0.9759 - val_loss: 0.1224 - val_accuracy: 0.9656\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0786 - accuracy: 0.9772 - val_loss: 0.1224 - val_accuracy: 0.9650\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0739 - accuracy: 0.9789 - val_loss: 0.1115 - val_accuracy: 0.9688\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0705 - accuracy: 0.9789 - val_loss: 0.1130 - val_accuracy: 0.9678\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0668 - accuracy: 0.9806 - val_loss: 0.1196 - val_accuracy: 0.9675\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0631 - accuracy: 0.9815 - val_loss: 0.1132 - val_accuracy: 0.9669\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0596 - accuracy: 0.9831 - val_loss: 0.1154 - val_accuracy: 0.9680\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0551 - accuracy: 0.9845 - val_loss: 0.1164 - val_accuracy: 0.9675\n",
      "20000/20000 [==============================] - 1s 55us/sample - loss: 0.1269 - accuracy: 0.9617\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 1s 43us/sample - loss: 1.8281 - accuracy: 0.4498 - val_loss: 0.7240 - val_accuracy: 0.7993\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.5217 - accuracy: 0.8480 - val_loss: 0.3614 - val_accuracy: 0.8947\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3555 - accuracy: 0.8957 - val_loss: 0.2992 - val_accuracy: 0.9155\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2913 - accuracy: 0.9151 - val_loss: 0.2406 - val_accuracy: 0.9300\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 36us/sample - loss: 0.2486 - accuracy: 0.9274 - val_loss: 0.2096 - val_accuracy: 0.9406\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.2197 - accuracy: 0.9361 - val_loss: 0.1927 - val_accuracy: 0.9444\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.1940 - accuracy: 0.9418 - val_loss: 0.1771 - val_accuracy: 0.9486\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1765 - accuracy: 0.9483 - val_loss: 0.1668 - val_accuracy: 0.9506\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1604 - accuracy: 0.9527 - val_loss: 0.1543 - val_accuracy: 0.9548\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.1482 - accuracy: 0.9560 - val_loss: 0.1554 - val_accuracy: 0.9570\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1374 - accuracy: 0.9588 - val_loss: 0.1464 - val_accuracy: 0.9582\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1268 - accuracy: 0.9617 - val_loss: 0.1384 - val_accuracy: 0.9628\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1176 - accuracy: 0.9637 - val_loss: 0.1325 - val_accuracy: 0.9609\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1097 - accuracy: 0.9673 - val_loss: 0.1329 - val_accuracy: 0.9629\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1028 - accuracy: 0.9691 - val_loss: 0.1330 - val_accuracy: 0.9625\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0958 - accuracy: 0.9716 - val_loss: 0.1322 - val_accuracy: 0.9639\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0899 - accuracy: 0.9730 - val_loss: 0.1352 - val_accuracy: 0.9625\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0844 - accuracy: 0.9748 - val_loss: 0.1288 - val_accuracy: 0.9655\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0801 - accuracy: 0.9756 - val_loss: 0.1345 - val_accuracy: 0.9629\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0754 - accuracy: 0.9764 - val_loss: 0.1189 - val_accuracy: 0.9681\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0709 - accuracy: 0.9792 - val_loss: 0.1224 - val_accuracy: 0.9669\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0660 - accuracy: 0.9799 - val_loss: 0.1364 - val_accuracy: 0.9626\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0620 - accuracy: 0.9816 - val_loss: 0.1187 - val_accuracy: 0.9689\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0586 - accuracy: 0.9825 - val_loss: 0.1170 - val_accuracy: 0.9686\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0545 - accuracy: 0.9837 - val_loss: 0.1204 - val_accuracy: 0.9693\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0523 - accuracy: 0.9846 - val_loss: 0.1216 - val_accuracy: 0.9680\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.0492 - accuracy: 0.9860 - val_loss: 0.1200 - val_accuracy: 0.9688\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0453 - accuracy: 0.9871 - val_loss: 0.1283 - val_accuracy: 0.9684\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.0444 - accuracy: 0.9869 - val_loss: 0.1185 - val_accuracy: 0.9712\n",
      "20000/20000 [==============================] - 1s 55us/sample - loss: 0.1397 - accuracy: 0.9614\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 72us/sample - loss: 1.7007 - accuracy: 0.4815 - val_loss: 0.7513 - val_accuracy: 0.7379\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.5750 - accuracy: 0.8194 - val_loss: 0.4559 - val_accuracy: 0.8564\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.4058 - accuracy: 0.8808 - val_loss: 0.3825 - val_accuracy: 0.8806\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.3312 - accuracy: 0.9030 - val_loss: 0.3013 - val_accuracy: 0.9122\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.2850 - accuracy: 0.9169 - val_loss: 0.2754 - val_accuracy: 0.9184\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 1s 31us/sample - loss: 0.2476 - accuracy: 0.9287 - val_loss: 0.2405 - val_accuracy: 0.9309\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.2211 - accuracy: 0.9358 - val_loss: 0.2282 - val_accuracy: 0.9348\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1976 - accuracy: 0.9426 - val_loss: 0.2205 - val_accuracy: 0.9351\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1802 - accuracy: 0.9468 - val_loss: 0.2070 - val_accuracy: 0.9390\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1649 - accuracy: 0.9516 - val_loss: 0.2019 - val_accuracy: 0.9404\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1523 - accuracy: 0.9553 - val_loss: 0.1792 - val_accuracy: 0.9479\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1408 - accuracy: 0.9580 - val_loss: 0.1737 - val_accuracy: 0.9511\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1317 - accuracy: 0.9615 - val_loss: 0.1685 - val_accuracy: 0.9514\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.1209 - accuracy: 0.9649 - val_loss: 0.1664 - val_accuracy: 0.9501\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.1133 - accuracy: 0.9653 - val_loss: 0.1822 - val_accuracy: 0.9470\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1063 - accuracy: 0.9682 - val_loss: 0.1549 - val_accuracy: 0.9539\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 1s 32us/sample - loss: 0.1002 - accuracy: 0.9706 - val_loss: 0.1630 - val_accuracy: 0.9517\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0942 - accuracy: 0.9724 - val_loss: 0.1537 - val_accuracy: 0.9554\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0891 - accuracy: 0.9737 - val_loss: 0.1491 - val_accuracy: 0.9572\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0836 - accuracy: 0.9748 - val_loss: 0.1444 - val_accuracy: 0.9607\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0783 - accuracy: 0.9767 - val_loss: 0.1526 - val_accuracy: 0.9553\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 1s 41us/sample - loss: 0.0749 - accuracy: 0.9780 - val_loss: 0.1966 - val_accuracy: 0.9431\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.0688 - accuracy: 0.9800 - val_loss: 0.1456 - val_accuracy: 0.9600\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 1s 34us/sample - loss: 0.0647 - accuracy: 0.9808 - val_loss: 0.1528 - val_accuracy: 0.9574\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 1s 35us/sample - loss: 0.0608 - accuracy: 0.9828 - val_loss: 0.1431 - val_accuracy: 0.9603\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 1s 33us/sample - loss: 0.0579 - accuracy: 0.9835 - val_loss: 0.1502 - val_accuracy: 0.9584\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 1s 39us/sample - loss: 0.0543 - accuracy: 0.9847 - val_loss: 0.1442 - val_accuracy: 0.9617\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.0507 - accuracy: 0.9853 - val_loss: 0.1435 - val_accuracy: 0.9617\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 1s 42us/sample - loss: 0.0470 - accuracy: 0.9873 - val_loss: 0.1494 - val_accuracy: 0.9600\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 1s 40us/sample - loss: 0.0447 - accuracy: 0.9877 - val_loss: 0.1517 - val_accuracy: 0.9599\n",
      "20000/20000 [==============================] - 2s 75us/sample - loss: 0.1400 - accuracy: 0.9608\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x0000022692675DC8>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-ff787e4c6704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb_best_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                         \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                         batch_size = 100)\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m \u001b[1;33m,\u001b[0m  \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x0000022692675DC8>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "# Using a RandomizedSearchCV method to find the optimal parameter of the neural network\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_distribution = {\n",
    "    \"n_layers\" : [1, 2, 3, 4, 5],\n",
    "    \"n_neurons\" : np.arange(30,100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_classfier, param_distribution, n_iter=10,\n",
    "                                         cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train,\n",
    "                        epochs=100,\n",
    "                        callbacks=[checkpoint_cb_best_model, early_stopping_cb],\n",
    "                        validation_split = 0.2,\n",
    "                        batch_size = 100)\n",
    "rnd_search_cv.best_params_ ,  rnd_search_cv.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T02:34:45.189309Z",
     "start_time": "2020-09-15T02:34:45.185314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.01835493714990727, 'n_layers': 5, 'n_neurons': 77},\n",
       " 0.9612833460172018)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_ ,  rnd_search_cv.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T03:00:52.857093Z",
     "start_time": "2020-09-15T02:59:07.080122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/300\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.6838 - accuracy: 0.7890 - val_loss: 0.2526 - val_accuracy: 0.9247\n",
      "Epoch 2/300\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.2260 - accuracy: 0.9330 - val_loss: 0.1791 - val_accuracy: 0.9507\n",
      "Epoch 3/300\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.1619 - accuracy: 0.9511 - val_loss: 0.1599 - val_accuracy: 0.9513\n",
      "Epoch 4/300\n",
      "48000/48000 [==============================] - 5s 100us/sample - loss: 0.1274 - accuracy: 0.9618 - val_loss: 0.1391 - val_accuracy: 0.9584\n",
      "Epoch 5/300\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.1058 - accuracy: 0.9683 - val_loss: 0.1254 - val_accuracy: 0.9632\n",
      "Epoch 6/300\n",
      "48000/48000 [==============================] - 5s 107us/sample - loss: 0.0906 - accuracy: 0.9723 - val_loss: 0.1134 - val_accuracy: 0.9666\n",
      "Epoch 7/300\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.1154 - val_accuracy: 0.9663\n",
      "Epoch 8/300\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0684 - accuracy: 0.9789 - val_loss: 0.1119 - val_accuracy: 0.9673\n",
      "Epoch 9/300\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.0601 - accuracy: 0.9816 - val_loss: 0.1156 - val_accuracy: 0.9658\n",
      "Epoch 10/300\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0522 - accuracy: 0.9835 - val_loss: 0.1169 - val_accuracy: 0.9682\n",
      "Epoch 11/300\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.0488 - accuracy: 0.9845 - val_loss: 0.1082 - val_accuracy: 0.9700\n",
      "Epoch 12/300\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0426 - accuracy: 0.9872 - val_loss: 0.1129 - val_accuracy: 0.9693\n",
      "Epoch 13/300\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.1093 - val_accuracy: 0.9703\n",
      "Epoch 14/300\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0317 - accuracy: 0.9904 - val_loss: 0.1150 - val_accuracy: 0.9693\n",
      "Epoch 15/300\n",
      "48000/48000 [==============================] - 5s 102us/sample - loss: 0.0303 - accuracy: 0.9907 - val_loss: 0.1089 - val_accuracy: 0.9716\n",
      "Epoch 16/300\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.1161 - val_accuracy: 0.9701\n",
      "Epoch 17/300\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.1141 - val_accuracy: 0.9701\n",
      "Epoch 18/300\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.1267 - val_accuracy: 0.9687\n",
      "Epoch 19/300\n",
      "48000/48000 [==============================] - 5s 105us/sample - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.1159 - val_accuracy: 0.9723\n",
      "Epoch 20/300\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.1232 - val_accuracy: 0.9722\n",
      "Epoch 21/300\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.1308 - val_accuracy: 0.9710\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the best model from the randomized searchCV and training it with more epochs to get better accuracy\n",
    "# Now calling the build function to build the model with the best parameter\n",
    "\n",
    "checkpoint_cb_best_model = keras.callbacks.ModelCheckpoint('Digits_Sequantial_API.h5',\n",
    "                                                              save_best_only=True)\n",
    "\n",
    "# Early stopping the model , if validation accuracy does not see any improvement \n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                 restore_best_weights=True)\n",
    "\n",
    "model_final = build_model(n_layers = 5, n_neurons=77 , \n",
    "                learning_rate = 0.01835493714990727 ) \n",
    "history_final = model_final.fit(X_train, y_train,\n",
    "                   epochs=300,\n",
    "                   callbacks=[checkpoint_cb_best_model, early_stopping_cb],\n",
    "                   validation_split=0.33,\n",
    "                   batch_size=32)\n",
    "\n",
    "plot_loss_analysis(history_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T03:01:46.099688Z",
     "start_time": "2020-09-15T03:01:44.951162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0993 - accuracy: 0.9724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09930142889148556, 0.9724]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model on the test set\n",
    "model_final.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T03:02:54.211541Z",
     "start_time": "2020-09-15T03:02:53.921733Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using the model to make prediction\n",
    "X_new = X_test[:3]\n",
    "y_proba = model_final.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T03:02:56.347821Z",
     "start_time": "2020-09-15T03:02:56.343826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see the for each instance the model estimates one probability per class from 0 to 9\n",
    "# ex. in the second case its prob is 100% on index 2 meaning the value is 2 \n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T03:02:58.699061Z",
     "start_time": "2020-09-15T03:02:58.662020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['seven', 'two', 'one'], dtype='<U5')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find the classes with the highest probability use predict_classes\n",
    "y_pred = model_final.predict_classes(X_new)\n",
    "y_pred\n",
    "y_pred_string = np.array(class_names)[y_pred]\n",
    "y_pred_string               # to use y_pred as index to the class_name list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T03:03:03.827399Z",
     "start_time": "2020-09-15T03:03:03.820369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the actual values of the images using the test set\n",
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T03:03:08.526461Z",
     "start_time": "2020-09-15T03:03:08.241469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we can see the image with the value it has predicted\n",
    "fig, ax = plt.subplots(1,3,figsize=(12,6))\n",
    "for axs,j,k in zip(ax.flat,X_new[:3],[0,1,2]):\n",
    "    axs.imshow(j)\n",
    "    axs.grid(False,)\n",
    "    axs.set_title(f'Predicted: {y_pred_string[k]}',color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T03:03:13.965776Z",
     "start_time": "2020-09-15T03:03:13.957737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now lets create a function which will ask for a random number pixel in the test dataset\n",
    "# and will return its test_data pixel image and the value predicted for it\n",
    "def get_image(model, X_test, class_names):\n",
    "    inp = input(f'Input a random index value from the test dataset less than  {len(X_test)} : ' )\n",
    "    try:\n",
    "        inp = int(inp)\n",
    "    except :\n",
    "        print('The value given is not an integer ')\n",
    "    if inp > 100000:\n",
    "        print('The number is greater than 100000')\n",
    "    else:\n",
    "        X_new = X_test[inp:inp+1]\n",
    "        y_pred = model.predict_classes(X_new)\n",
    "        y_pred_string = np.array(class_names)[y_pred]\n",
    "        plt.imshow(X_new[0])\n",
    "        plt.grid(False,)\n",
    "        plt.title(f'Predicted: {y_pred_string}',color='red')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T03:03:18.639815Z",
     "start_time": "2020-09-15T03:03:15.095617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input a random index value from the test dataset less than  10000 : 4565\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the function for different with inputting different values of index \n",
    "get_image(model, X_test, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T14:51:47.622725Z",
     "start_time": "2020-09-13T14:51:47.618723Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
